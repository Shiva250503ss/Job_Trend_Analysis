{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data gathered using ampify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to 'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\combined_job_listings.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "df_analyst = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_analyst.csv')\n",
    "df_engineer = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_engineer.csv')\n",
    "df_scientist = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_scientist.csv')\n",
    "\n",
    "# Add a 'job_category' column to each DataFrame\n",
    "df_analyst['job_category'] = 'Data Analyst'\n",
    "df_engineer['job_category'] = 'Data Engineer'\n",
    "df_scientist['job_category'] = 'Data Scientist'\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "combined_df = pd.concat([df_analyst, df_engineer, df_scientist], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_df.to_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\combined_job_listings.csv', index=False)\n",
    "print(\"Combined data saved to 'C:\\\\Users\\\\shiva\\\\OneDrive\\\\Documents\\\\Github\\\\Job_Trend_Analysis\\\\datasets\\\\combined_job_listings.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('datasets/combined_job_listings.csv')\n",
    "\n",
    "# Function to categorize job titles using regex\n",
    "def categorize_job_title(title):\n",
    "    title = title.lower()\n",
    "    # Regex patterns to match titles\n",
    "    if re.search(r'\\bdata\\s+scientist\\b', title):\n",
    "        return 'Data Scientist'\n",
    "    elif re.search(r'\\bdata\\s+engineer\\b', title):\n",
    "        return 'Data Engineer'\n",
    "    elif re.search(r'\\bdata\\s+analyst\\b', title):\n",
    "        return 'Data Analyst'\n",
    "    else:\n",
    "        return 'Other'  # Return 'Other' if no specific category is matched\n",
    "\n",
    "# Apply the function to the job_title column\n",
    "df['job_category'] = df['title'].apply(categorize_job_title)\n",
    "\n",
    "# Drop rows categorized as 'Other' to keep only the three specified categories\n",
    "df = df[df['job_category'] != 'Other']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Analyst', 'Data Scientist', 'Data Engineer'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df['job_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_salary'] = df[['min_amount', 'max_amount']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['avg_salary'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>currency</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>emails</th>\n",
       "      <th>interval</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>job_function</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_url</th>\n",
       "      <th>job_url_direct</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>location</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>min_amount</th>\n",
       "      <th>title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVS Health</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.738368e+12</td>\n",
       "      <td>Bring your heart to CVS Health. Every one of u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yearly</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://jobs.cvshealth.com/us/en/job/R0486462/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>158620.0</td>\n",
       "      <td>72100.0</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>115360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass General Brigham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738282e+12</td>\n",
       "      <td>Site: The General Hospital Corporation\\r\\n\\r\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://jobs.mehi.masstech.org/companies/mass-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pitchbook</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.738195e+12</td>\n",
       "      <td>At PitchBook, we are always looking forward. W...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yearly</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://careers.pitchbook.com/global/en/job/44...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>72650.0</td>\n",
       "      <td>Associate Data Analyst, Leveraged Loans</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>79525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738195e+12</td>\n",
       "      <td>Basic qualifications for an Supply Chain Data ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=c3b830ca1a25...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Reading, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supply Chain Data Analyst, AR NPI - STL</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SnapX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738109e+12</td>\n",
       "      <td>**Required:**\\r\\nâ€¢ *10+ yrs exp Data Analyst/E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://snapx.ai/view-job/data-analyst-enginee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst/Engineer</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company currency   date_posted  \\\n",
       "0               CVS Health      USD  1.738368e+12   \n",
       "2     Mass General Brigham      NaN  1.738282e+12   \n",
       "4                Pitchbook      USD  1.738195e+12   \n",
       "5  Amazon.com Services LLC      NaN  1.738195e+12   \n",
       "7                    SnapX      NaN  1.738109e+12   \n",
       "\n",
       "                                         description emails interval  \\\n",
       "0  Bring your heart to CVS Health. Every one of u...    NaN   yearly   \n",
       "2  Site: The General Hospital Corporation\\r\\n\\r\\n...    NaN      NaN   \n",
       "4  At PitchBook, we are always looking forward. W...    NaN   yearly   \n",
       "5  Basic qualifications for an Supply Chain Data ...    NaN      NaN   \n",
       "7  **Required:**\\r\\nâ€¢ *10+ yrs exp Data Analyst/E...    NaN      NaN   \n",
       "\n",
       "   is_remote  job_function  job_level  job_type  \\\n",
       "0      False           NaN        NaN  fulltime   \n",
       "2       True           NaN        NaN  fulltime   \n",
       "4       True           NaN        NaN  fulltime   \n",
       "5      False           NaN        NaN  fulltime   \n",
       "7      False           NaN        NaN  fulltime   \n",
       "\n",
       "                                             job_url  job_url_direct  \\\n",
       "0  https://jobs.cvshealth.com/us/en/job/R0486462/...             NaN   \n",
       "2  https://jobs.mehi.masstech.org/companies/mass-...             NaN   \n",
       "4  https://careers.pitchbook.com/global/en/job/44...             NaN   \n",
       "5  https://www.indeed.com/viewjob?jk=c3b830ca1a25...             NaN   \n",
       "7  https://snapx.ai/view-job/data-analyst-enginee...             NaN   \n",
       "\n",
       "   listing_type           location  max_amount  min_amount  \\\n",
       "0           NaN       Hartford, CT    158620.0     72100.0   \n",
       "2           NaN         Boston, MA         NaN         NaN   \n",
       "4           NaN       New York, NY     86400.0     72650.0   \n",
       "5           NaN  North Reading, MA         NaN         NaN   \n",
       "7           NaN       New York, NY         NaN         NaN   \n",
       "\n",
       "                                     title  job_category  avg_salary  \n",
       "0                      Senior Data Analyst  Data Analyst    115360.0  \n",
       "2                           Data Analyst I  Data Analyst         NaN  \n",
       "4  Associate Data Analyst, Leveraged Loans  Data Analyst     79525.0  \n",
       "5  Supply Chain Data Analyst, AR NPI - STL  Data Analyst         NaN  \n",
       "7                    Data Analyst/Engineer  Data Analyst         NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    'currency','date_posted', 'description', 'emails', 'interval', 'is_remote', 'job_function', 'job_level', 'job_type', 'job_url', 'job_url_direct',\n",
    "    'listing_type', 'max_amount', 'min_amount'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'datasets/combined_job_listings_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('datasets/combined_job_listings_cleaned.csv', index=False)\n",
    "print(\"Cleaned data saved to 'datasets/combined_job_listings_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Kaggle API Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\shiva\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOther\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Titles not matching the above categories will be labeled 'Other'\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Apply the function to the 'title' column\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_new\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(categorize_job_title)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Optionally, remove rows where the category is 'Other' to focus on the specified categories\u001b[39;00m\n\u001b[0;32m     23\u001b[0m df_new \u001b[38;5;241m=\u001b[39m df_new[df_new[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjob_category\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOther\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\shiva\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\shiva\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load the new dataset\n",
    "df_new = pd.read_csv('datasets/Glassdoor_Salary_Cleaned_Version.csv')  # Ensure this is the correct path for the new dataset\n",
    "\n",
    "# Function to categorize job titles using regex\n",
    "def categorize_job_title(title):\n",
    "    title = title.lower()\n",
    "    if re.search(r'\\bdata\\s+scientist\\b', title):\n",
    "        return 'Data Scientist'\n",
    "    elif re.search(r'\\bdata\\s+engineer\\b', title):\n",
    "        return 'Data Engineer'\n",
    "    elif re.search(r'\\bdata\\s+analyst\\b', title) or re.search(r'\\banalyst\\b', title):\n",
    "        return 'Data Analyst'\n",
    "    else:\n",
    "        return 'Other'  # Titles not matching the above categories will be labeled 'Other'\n",
    "\n",
    "# Apply the function to the 'title' column\n",
    "df_new['job_category'] = df_new['title'].apply(categorize_job_title)\n",
    "\n",
    "# Optionally, remove rows where the category is 'Other' to focus on the specified categories\n",
    "df_new = df_new[df_new['job_category'] != 'Other']\n",
    "\n",
    "# Save the updated data to a new CSV file\n",
    "df_new.to_csv('datasets', index=False)\n",
    "print(\"Categorized data saved to '/mnt/data/combined_job_listings_categorized.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data from kaggle api and apify api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
