{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data gathered using ampify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to 'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\combined_job_listings.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df_analyst = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_analyst.csv')\n",
    "df_engineer = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_engineer.csv')\n",
    "df_scientist = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_scientist.csv')\n",
    "\n",
    "df_analyst['job_category'] = 'Data Analyst'\n",
    "df_engineer['job_category'] = 'Data Engineer'\n",
    "df_scientist['job_category'] = 'Data Scientist'\n",
    "\n",
    "combined_df = pd.concat([df_analyst, df_engineer, df_scientist], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\combined_job_listings.csv', index=False)\n",
    "print(\"Combined data saved to 'C:\\\\Users\\\\shiva\\\\OneDrive\\\\Documents\\\\Github\\\\Job_Trend_Analysis\\\\datasets\\\\combined_job_listings.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/combined_job_listings.csv')\n",
    "\n",
    "def categorize_job_title(title):\n",
    "    title = title.lower()\n",
    "    if re.search(r'\\bdata\\s+scientist\\b', title):\n",
    "        return 'Data Scientist'\n",
    "    elif re.search(r'\\bdata\\s+engineer\\b', title):\n",
    "        return 'Data Engineer'\n",
    "    elif re.search(r'\\bdata\\s+analyst\\b', title):\n",
    "        return 'Data Analyst'\n",
    "    else:\n",
    "        return 'Data Scientist' \n",
    "\n",
    "df['job_category'] = df['title'].apply(categorize_job_title)\n",
    "\n",
    "df = df[df['job_category'] != 'Other']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Analyst', 'Data Scientist'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df['job_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_salary'] = df[['min_amount', 'max_amount']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['avg_salary'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>currency</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>emails</th>\n",
       "      <th>interval</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>job_function</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_url</th>\n",
       "      <th>job_url_direct</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>location</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>min_amount</th>\n",
       "      <th>title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843045256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738368e+12</td>\n",
       "      <td>Benefits:\\n• 401(k)\\n• 401(k) matching\\n• Comp...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=a710335d092d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pomona, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sunbit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738368e+12</td>\n",
       "      <td>JOB TITLE: Fraud Data Analyst\\n\\nLOCATION: Rem...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/fraud-data-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fraud Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SynergisticIT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738368e+12</td>\n",
       "      <td>Are you passionate about coding or technology ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/python-prog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Python Programmer (Remote)/ Data Analyst (Remote)</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>University Medical Center of Southern Nevada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738368e+12</td>\n",
       "      <td>EMPLOYER-PAID PENSION PLAN (NEVADA PERS)\\nCOMP...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://www.governmentjobs.com/careers/umcsn/j...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Las Vegas, NV</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Epic Analyst - Core Clinical</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zest AI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738282e+12</td>\n",
       "      <td>At Zest AI, we excel at tackling complex chall...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-analys...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Burbank, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        company currency   date_posted  \\\n",
       "0                                     843045256      NaN  1.738368e+12   \n",
       "1                                        Sunbit      NaN  1.738368e+12   \n",
       "2                                 SynergisticIT      NaN  1.738368e+12   \n",
       "3  University Medical Center of Southern Nevada      NaN  1.738368e+12   \n",
       "4                                       Zest AI      NaN  1.738282e+12   \n",
       "\n",
       "                                         description emails interval  \\\n",
       "0  Benefits:\\n• 401(k)\\n• 401(k) matching\\n• Comp...    NaN      NaN   \n",
       "1  JOB TITLE: Fraud Data Analyst\\n\\nLOCATION: Rem...    NaN      NaN   \n",
       "2  Are you passionate about coding or technology ...    NaN      NaN   \n",
       "3  EMPLOYER-PAID PENSION PLAN (NEVADA PERS)\\nCOMP...    NaN      NaN   \n",
       "4  At Zest AI, we excel at tackling complex chall...    NaN      NaN   \n",
       "\n",
       "   is_remote  job_function  job_level  job_type  \\\n",
       "0      False           NaN        NaN  fulltime   \n",
       "1       True           NaN        NaN  fulltime   \n",
       "2      False           NaN        NaN  fulltime   \n",
       "3       True           NaN        NaN  fulltime   \n",
       "4      False           NaN        NaN  fulltime   \n",
       "\n",
       "                                             job_url  job_url_direct  \\\n",
       "0  https://www.indeed.com/viewjob?jk=a710335d092d...             NaN   \n",
       "1  https://www.linkedin.com/jobs/view/fraud-data-...             NaN   \n",
       "2  https://www.linkedin.com/jobs/view/python-prog...             NaN   \n",
       "3  https://www.governmentjobs.com/careers/umcsn/j...             NaN   \n",
       "4  https://www.linkedin.com/jobs/view/data-analys...             NaN   \n",
       "\n",
       "   listing_type         location  max_amount  min_amount  \\\n",
       "0           NaN       Pomona, CA         NaN         NaN   \n",
       "1           NaN  Los Angeles, CA         NaN         NaN   \n",
       "2           NaN    Las Vegas, NV         NaN         NaN   \n",
       "3           NaN    Las Vegas, NV         NaN         NaN   \n",
       "4           NaN      Burbank, CA         NaN         NaN   \n",
       "\n",
       "                                               title    job_category  \\\n",
       "0                                       Data Analyst    Data Analyst   \n",
       "1                                 Fraud Data Analyst    Data Analyst   \n",
       "2  Python Programmer (Remote)/ Data Analyst (Remote)    Data Analyst   \n",
       "3                       Epic Analyst - Core Clinical  Data Scientist   \n",
       "4                                       Data Analyst    Data Analyst   \n",
       "\n",
       "   avg_salary  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    'currency','date_posted', 'description', 'emails', 'interval', 'is_remote', 'job_function', 'job_level', 'job_type', 'job_url', 'job_url_direct',\n",
    "    'listing_type', 'max_amount', 'min_amount'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'datasets/combined_job_listings_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('datasets/combined_job_listings_cleaned.csv', index=False)\n",
    "print(\"Cleaned data saved to 'datasets/combined_job_listings_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Kaggle API Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to 'datasets/Glassdoor_Salary_Cleaned_Version_Reduced.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_new = pd.read_csv('datasets/Glassdoor_Salary_Cleaned_Version.csv') \n",
    "\n",
    "def categorize_job_title(title):\n",
    "    title = title.lower()\n",
    "    if re.search(r'data\\s+scientist', title):\n",
    "        return 'Data Scientist'\n",
    "    elif re.search(r'data\\s+engineer', title):\n",
    "        return 'Data Engineer'\n",
    "    elif re.search(r'data\\s+analyst', title):\n",
    "        return 'Data Analyst'\n",
    "    else:\n",
    "        return 'Data Scientist '  \n",
    "\n",
    "df_new['job_category'] = df_new['Job Title'].apply(categorize_job_title)\n",
    "\n",
    "df_new = df_new[df_new['job_category'] != 'Other']\n",
    "\n",
    "\n",
    "\n",
    "columns_to_remove = [\n",
    "    'Salary Estimate', 'Job Description', 'Rating', 'Headquarters', 'Size', 'Founded',\n",
    "    'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors', 'hourly',\n",
    "    'employer_provided', 'min_salary', 'max_salary', 'company_txt', 'job_state',\n",
    "    'same_state', 'age'\n",
    "]\n",
    "\n",
    "df_new = df_new.drop(columns=columns_to_remove)\n",
    "\n",
    "df_new.to_csv('datasets/Glassdoor_Salary_Cleaned_Version_Reduced.csv', index=False)\n",
    "print(\"Updated data saved to 'datasets/Glassdoor_Salary_Cleaned_Version_Reduced.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data from kaggle api and apify api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete merged data saved to 'datasets/combined_final_data.csv'\n"
     ]
    }
   ],
   "source": [
    "df_job_listings = pd.read_csv('datasets/combined_job_listings_cleaned.csv')\n",
    "df_glassdoor_salary = pd.read_csv('datasets/Glassdoor_Salary_Cleaned_Version_Reduced.csv')\n",
    "\n",
    "df_job_listings.rename(columns={'company': 'Company Name', 'location': 'Location', 'title': 'Job Title'}, inplace=True)\n",
    "\n",
    "df_job_listings['Company Name'] = df_job_listings['Company Name'].str.strip().str.lower()\n",
    "df_glassdoor_salary['Company Name'] = df_glassdoor_salary['Company Name'].str.strip().str.lower()\n",
    "\n",
    "df_job_listings['Location'] = df_job_listings['Location'].str.strip().str.lower()\n",
    "df_glassdoor_salary['Location'] = df_glassdoor_salary['Location'].str.strip().str.lower()\n",
    "\n",
    "df_job_listings['Job Title'] = df_job_listings['Job Title'].str.strip().str.lower()\n",
    "df_glassdoor_salary['Job Title'] = df_glassdoor_salary['Job Title'].str.strip().str.lower()\n",
    "\n",
    "df_final = pd.merge(df_job_listings, df_glassdoor_salary, \n",
    "                              on=['Job Title', 'Company Name', 'Location', 'job_category'], \n",
    "                              how='outer')\n",
    "\n",
    "df_final.to_csv('datasets/combined_final_data.csv', index=False)\n",
    "print(\"Complete merged data saved to 'datasets/combined_final_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the final Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated and unified salary data saved to 'datasets/combined_final_data_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets/combined_final_data.csv')\n",
    "\n",
    "df.loc[df['avg_salary_y'].notna(), 'avg_salary_y'] = df['avg_salary_y'] * 2080\n",
    "\n",
    "df['avg_salary'] = df['avg_salary_x'].fillna(df['avg_salary_y'])\n",
    "\n",
    "df.drop(['avg_salary_x', 'avg_salary_y'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>python_yn</th>\n",
       "      <th>R_yn</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>excel</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>disability solutions</td>\n",
       "      <td>glendale, ca</td>\n",
       "      <td>advanced data analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>disability solutions</td>\n",
       "      <td>glendale, ca</td>\n",
       "      <td>advanced data analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>belmont university</td>\n",
       "      <td>nashville, tn</td>\n",
       "      <td>advancement services - temporary data analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>belmont university</td>\n",
       "      <td>nashville, tn</td>\n",
       "      <td>advancement services – temporary data analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beck's hybrids\\n4.6</td>\n",
       "      <td>atlanta, in</td>\n",
       "      <td>ag data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>167440.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Company Name       Location  \\\n",
       "0  disability solutions   glendale, ca   \n",
       "1  disability solutions   glendale, ca   \n",
       "2    belmont university  nashville, tn   \n",
       "3    belmont university  nashville, tn   \n",
       "4   beck's hybrids\\n4.6    atlanta, in   \n",
       "\n",
       "                                       Job Title    job_category  python_yn  \\\n",
       "0                          advanced data analyst    Data Analyst        NaN   \n",
       "1                          advanced data analyst    Data Analyst        NaN   \n",
       "2  advancement services - temporary data analyst    Data Analyst        NaN   \n",
       "3  advancement services – temporary data analyst    Data Analyst        NaN   \n",
       "4                              ag data scientist  Data Scientist        0.0   \n",
       "\n",
       "   R_yn  spark  aws  excel  avg_salary  \n",
       "0   NaN    NaN  NaN    NaN         NaN  \n",
       "1   NaN    NaN  NaN    NaN         NaN  \n",
       "2   NaN    NaN  NaN    NaN         NaN  \n",
       "3   NaN    NaN  NaN    NaN         NaN  \n",
       "4   0.0    0.0  0.0    0.0    167440.0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['avg_salary'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>python_yn</th>\n",
       "      <th>R_yn</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>excel</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>742.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.225067</td>\n",
       "      <td>0.237197</td>\n",
       "      <td>0.522911</td>\n",
       "      <td>200046.097666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499535</td>\n",
       "      <td>0.051882</td>\n",
       "      <td>0.417908</td>\n",
       "      <td>0.425651</td>\n",
       "      <td>0.499812</td>\n",
       "      <td>83301.462104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>138580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>192400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>249600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>528320.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        python_yn        R_yn       spark         aws       excel  \\\n",
       "count  742.000000  742.000000  742.000000  742.000000  742.000000   \n",
       "mean     0.528302    0.002695    0.225067    0.237197    0.522911   \n",
       "std      0.499535    0.051882    0.417908    0.425651    0.499812   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%      1.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          avg_salary  \n",
       "count     814.000000  \n",
       "mean   200046.097666  \n",
       "std     83301.462104  \n",
       "min     28080.000000  \n",
       "25%    138580.000000  \n",
       "50%    192400.000000  \n",
       "75%    249600.000000  \n",
       "max    528320.000000  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1145 entries, 0 to 1144\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Company Name  1145 non-null   object \n",
      " 1   Location      1145 non-null   object \n",
      " 2   Job Title     1145 non-null   object \n",
      " 3   job_category  1145 non-null   object \n",
      " 4   python_yn     742 non-null    float64\n",
      " 5   R_yn          742 non-null    float64\n",
      " 6   spark         742 non-null    float64\n",
      " 7   aws           742 non-null    float64\n",
      " 8   excel         742 non-null    float64\n",
      " 9   avg_salary    814 non-null    float64\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 89.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['job_category'] = df['job_category'].str.strip()\n",
    "\n",
    "categorical_columns = ['python_yn', 'R_yn', 'spark', 'aws', 'excel']\n",
    "for column in categorical_columns:\n",
    "    df[column] = df.groupby('job_category')[column].transform(lambda x: x.fillna(x.mode()[0]))\n",
    "\n",
    "df['avg_salary'] = df.groupby('job_category')['avg_salary'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1145 entries, 0 to 1144\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Company Name  1145 non-null   object \n",
      " 1   Location      1145 non-null   object \n",
      " 2   Job Title     1145 non-null   object \n",
      " 3   job_category  1145 non-null   object \n",
      " 4   python_yn     1145 non-null   float64\n",
      " 5   R_yn          1145 non-null   float64\n",
      " 6   spark         1145 non-null   float64\n",
      " 7   aws           1145 non-null   float64\n",
      " 8   excel         1145 non-null   float64\n",
      " 9   avg_salary    1145 non-null   float64\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 89.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete merged data saved to 'datasets/final_cleaned_data.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('datasets/final_cleaned_data.csv', index=False)\n",
    "print(\"Complete merged data saved to 'datasets/final_cleaned_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
