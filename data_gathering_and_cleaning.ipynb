{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining data gathered using ampify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to 'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\combined_job_listings.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "df_analyst = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_analyst.csv')\n",
    "df_engineer = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_engineer.csv')\n",
    "df_scientist = pd.read_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\job_listings_data_scientist.csv')\n",
    "\n",
    "df_analyst['job_category'] = 'Data Analyst'\n",
    "df_engineer['job_category'] = 'Data Engineer'\n",
    "df_scientist['job_category'] = 'Data Scientist'\n",
    "\n",
    "combined_df = pd.concat([df_analyst, df_engineer, df_scientist], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(r'C:\\Users\\shiva\\OneDrive\\Documents\\Github\\Job_Trend_Analysis\\datasets\\combined_job_listings.csv', index=False)\n",
    "print(\"Combined data saved to 'C:\\\\Users\\\\shiva\\\\OneDrive\\\\Documents\\\\Github\\\\Job_Trend_Analysis\\\\datasets\\\\combined_job_listings.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/combined_job_listings.csv')\n",
    "\n",
    "def categorize_job_title(title):\n",
    "    title = title.lower()\n",
    "    if re.search(r'\\bdata\\s+scientist\\b', title):\n",
    "        return 'Data Scientist'\n",
    "    elif re.search(r'\\bdata\\s+engineer\\b', title):\n",
    "        return 'Data Engineer'\n",
    "    elif re.search(r'\\bdata\\s+analyst\\b', title):\n",
    "        return 'Data Analyst'\n",
    "    else:\n",
    "        return 'Other' \n",
    "\n",
    "df['job_category'] = df['title'].apply(categorize_job_title)\n",
    "\n",
    "df = df[df['job_category'] != 'Other']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Data Analyst', 'Data Scientist', 'Data Engineer'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " df['job_category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_salary'] = df[['min_amount', 'max_amount']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['avg_salary'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>currency</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>description</th>\n",
       "      <th>emails</th>\n",
       "      <th>interval</th>\n",
       "      <th>is_remote</th>\n",
       "      <th>job_function</th>\n",
       "      <th>job_level</th>\n",
       "      <th>job_type</th>\n",
       "      <th>job_url</th>\n",
       "      <th>job_url_direct</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>location</th>\n",
       "      <th>max_amount</th>\n",
       "      <th>min_amount</th>\n",
       "      <th>title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVS Health</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.738368e+12</td>\n",
       "      <td>Bring your heart to CVS Health. Every one of u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yearly</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://jobs.cvshealth.com/us/en/job/R0486462/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hartford, CT</td>\n",
       "      <td>158620.0</td>\n",
       "      <td>72100.0</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>115360.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass General Brigham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738282e+12</td>\n",
       "      <td>Site: The General Hospital Corporation\\r\\n\\r\\n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://jobs.mehi.masstech.org/companies/mass-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst I</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pitchbook</td>\n",
       "      <td>USD</td>\n",
       "      <td>1.738195e+12</td>\n",
       "      <td>At PitchBook, we are always looking forward. W...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yearly</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://careers.pitchbook.com/global/en/job/44...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>86400.0</td>\n",
       "      <td>72650.0</td>\n",
       "      <td>Associate Data Analyst, Leveraged Loans</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>79525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Amazon.com Services LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738195e+12</td>\n",
       "      <td>Basic qualifications for an Supply Chain Data ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://www.indeed.com/viewjob?jk=c3b830ca1a25...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North Reading, MA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Supply Chain Data Analyst, AR NPI - STL</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SnapX</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.738109e+12</td>\n",
       "      <td>**Required:**\\r\\n• *10+ yrs exp Data Analyst/E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fulltime</td>\n",
       "      <td>https://snapx.ai/view-job/data-analyst-enginee...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data Analyst/Engineer</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company currency   date_posted  \\\n",
       "0               CVS Health      USD  1.738368e+12   \n",
       "2     Mass General Brigham      NaN  1.738282e+12   \n",
       "4                Pitchbook      USD  1.738195e+12   \n",
       "5  Amazon.com Services LLC      NaN  1.738195e+12   \n",
       "7                    SnapX      NaN  1.738109e+12   \n",
       "\n",
       "                                         description emails interval  \\\n",
       "0  Bring your heart to CVS Health. Every one of u...    NaN   yearly   \n",
       "2  Site: The General Hospital Corporation\\r\\n\\r\\n...    NaN      NaN   \n",
       "4  At PitchBook, we are always looking forward. W...    NaN   yearly   \n",
       "5  Basic qualifications for an Supply Chain Data ...    NaN      NaN   \n",
       "7  **Required:**\\r\\n• *10+ yrs exp Data Analyst/E...    NaN      NaN   \n",
       "\n",
       "   is_remote  job_function  job_level  job_type  \\\n",
       "0      False           NaN        NaN  fulltime   \n",
       "2       True           NaN        NaN  fulltime   \n",
       "4       True           NaN        NaN  fulltime   \n",
       "5      False           NaN        NaN  fulltime   \n",
       "7      False           NaN        NaN  fulltime   \n",
       "\n",
       "                                             job_url  job_url_direct  \\\n",
       "0  https://jobs.cvshealth.com/us/en/job/R0486462/...             NaN   \n",
       "2  https://jobs.mehi.masstech.org/companies/mass-...             NaN   \n",
       "4  https://careers.pitchbook.com/global/en/job/44...             NaN   \n",
       "5  https://www.indeed.com/viewjob?jk=c3b830ca1a25...             NaN   \n",
       "7  https://snapx.ai/view-job/data-analyst-enginee...             NaN   \n",
       "\n",
       "   listing_type           location  max_amount  min_amount  \\\n",
       "0           NaN       Hartford, CT    158620.0     72100.0   \n",
       "2           NaN         Boston, MA         NaN         NaN   \n",
       "4           NaN       New York, NY     86400.0     72650.0   \n",
       "5           NaN  North Reading, MA         NaN         NaN   \n",
       "7           NaN       New York, NY         NaN         NaN   \n",
       "\n",
       "                                     title  job_category  avg_salary  \n",
       "0                      Senior Data Analyst  Data Analyst    115360.0  \n",
       "2                           Data Analyst I  Data Analyst         NaN  \n",
       "4  Associate Data Analyst, Leveraged Loans  Data Analyst     79525.0  \n",
       "5  Supply Chain Data Analyst, AR NPI - STL  Data Analyst         NaN  \n",
       "7                    Data Analyst/Engineer  Data Analyst         NaN  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    'currency','date_posted', 'description', 'emails', 'interval', 'is_remote', 'job_function', 'job_level', 'job_type', 'job_url', 'job_url_direct',\n",
    "    'listing_type', 'max_amount', 'min_amount'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data saved to 'datasets/combined_job_listings_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('datasets/combined_job_listings_cleaned.csv', index=False)\n",
    "print(\"Cleaned data saved to 'datasets/combined_job_listings_cleaned.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Kaggle API Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated data saved to 'datasets/Glassdoor_Salary_Cleaned_Version_Reduced.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_new = pd.read_csv('datasets/Glassdoor_Salary_Cleaned_Version.csv') \n",
    "\n",
    "def categorize_job_title(title):\n",
    "    title = title.lower()\n",
    "    if re.search(r'data\\s+scientist', title):\n",
    "        return 'Data Scientist'\n",
    "    elif re.search(r'data\\s+engineer', title):\n",
    "        return 'Data Engineer'\n",
    "    elif re.search(r'data\\s+analyst', title):\n",
    "        return 'Data Analyst'\n",
    "    else:\n",
    "        return 'Other'  \n",
    "\n",
    "df_new['job_category'] = df_new['Job Title'].apply(categorize_job_title)\n",
    "\n",
    "df_new = df_new[df_new['job_category'] != 'Other']\n",
    "\n",
    "\n",
    "\n",
    "columns_to_remove = [\n",
    "    'Salary Estimate', 'Job Description', 'Rating', 'Headquarters', 'Size', 'Founded',\n",
    "    'Type of ownership', 'Industry', 'Sector', 'Revenue', 'Competitors', 'hourly',\n",
    "    'employer_provided', 'min_salary', 'max_salary', 'company_txt', 'job_state',\n",
    "    'same_state', 'age'\n",
    "]\n",
    "\n",
    "df_new = df_new.drop(columns=columns_to_remove)\n",
    "\n",
    "df_new.to_csv('datasets/Glassdoor_Salary_Cleaned_Version_Reduced.csv', index=False)\n",
    "print(\"Updated data saved to 'datasets/Glassdoor_Salary_Cleaned_Version_Reduced.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data from kaggle api and apify api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete merged data saved to 'datasets/combined_final_data.csv'\n"
     ]
    }
   ],
   "source": [
    "df_job_listings = pd.read_csv('datasets/combined_job_listings_cleaned.csv')\n",
    "df_glassdoor_salary = pd.read_csv('datasets/Glassdoor_Salary_Cleaned_Version_Reduced.csv')\n",
    "\n",
    "df_job_listings.rename(columns={'company': 'Company Name', 'location': 'Location', 'title': 'Job Title'}, inplace=True)\n",
    "\n",
    "df_job_listings['Company Name'] = df_job_listings['Company Name'].str.strip().str.lower()\n",
    "df_glassdoor_salary['Company Name'] = df_glassdoor_salary['Company Name'].str.strip().str.lower()\n",
    "\n",
    "df_job_listings['Location'] = df_job_listings['Location'].str.strip().str.lower()\n",
    "df_glassdoor_salary['Location'] = df_glassdoor_salary['Location'].str.strip().str.lower()\n",
    "\n",
    "df_job_listings['Job Title'] = df_job_listings['Job Title'].str.strip().str.lower()\n",
    "df_glassdoor_salary['Job Title'] = df_glassdoor_salary['Job Title'].str.strip().str.lower()\n",
    "\n",
    "df_final = pd.merge(df_job_listings, df_glassdoor_salary, \n",
    "                              on=['Job Title', 'Company Name', 'Location', 'job_category'], \n",
    "                              how='outer')\n",
    "\n",
    "df_final.to_csv('datasets/combined_final_data.csv', index=False)\n",
    "print(\"Complete merged data saved to 'datasets/combined_final_data.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the final Combined Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated and unified salary data saved to 'datasets/combined_final_data_cleaned.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('datasets/combined_final_data.csv')\n",
    "\n",
    "df.loc[df['avg_salary_y'].notna(), 'avg_salary_y'] = df['avg_salary_y'] * 2080\n",
    "\n",
    "df['avg_salary'] = df['avg_salary_x'].fillna(df['avg_salary_y'])\n",
    "\n",
    "df.drop(['avg_salary_x', 'avg_salary_y'], axis=1, inplace=True)\n",
    "\n",
    "df.to_csv('datasets/combined_final_data_cleaned.csv', index=False)\n",
    "print(\"Updated and unified salary data saved to 'datasets/combined_final_data_cleaned.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>job_category</th>\n",
       "      <th>python_yn</th>\n",
       "      <th>R_yn</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>excel</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bits</td>\n",
       "      <td>london</td>\n",
       "      <td>(senior) data engineer (ml, big data)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>walmart</td>\n",
       "      <td>germantown, md</td>\n",
       "      <td>(usa) principal, data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>walmart</td>\n",
       "      <td>reston, va</td>\n",
       "      <td>(usa) principal, data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>walmart</td>\n",
       "      <td>germantown, md</td>\n",
       "      <td>(usa) staff, data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>walmart</td>\n",
       "      <td>reston, va</td>\n",
       "      <td>(usa) staff, data scientist</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company Name        Location                              Job Title  \\\n",
       "0         bits          london  (senior) data engineer (ml, big data)   \n",
       "1      walmart  germantown, md        (usa) principal, data scientist   \n",
       "2      walmart      reston, va        (usa) principal, data scientist   \n",
       "3      walmart  germantown, md            (usa) staff, data scientist   \n",
       "4      walmart      reston, va            (usa) staff, data scientist   \n",
       "\n",
       "     job_category  python_yn  R_yn  spark  aws  excel  avg_salary  \n",
       "0   Data Engineer        NaN   NaN    NaN  NaN    NaN         NaN  \n",
       "1  Data Scientist        NaN   NaN    NaN  NaN    NaN    198000.0  \n",
       "2  Data Scientist        NaN   NaN    NaN  NaN    NaN    198000.0  \n",
       "3  Data Scientist        NaN   NaN    NaN  NaN    NaN    198000.0  \n",
       "4  Data Scientist        NaN   NaN    NaN  NaN    NaN    198000.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['avg_salary'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>python_yn</th>\n",
       "      <th>R_yn</th>\n",
       "      <th>spark</th>\n",
       "      <th>aws</th>\n",
       "      <th>excel</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.649899</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.307847</td>\n",
       "      <td>0.291751</td>\n",
       "      <td>0.539235</td>\n",
       "      <td>207741.151079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.477482</td>\n",
       "      <td>0.063372</td>\n",
       "      <td>0.462068</td>\n",
       "      <td>0.455026</td>\n",
       "      <td>0.498960</td>\n",
       "      <td>76330.908422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28080.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151840.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>203840.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>251940.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>494000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        python_yn        R_yn       spark         aws       excel  \\\n",
       "count  497.000000  497.000000  497.000000  497.000000  497.000000   \n",
       "mean     0.649899    0.004024    0.307847    0.291751    0.539235   \n",
       "std      0.477482    0.063372    0.462068    0.455026    0.498960   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      1.000000    0.000000    0.000000    0.000000    1.000000   \n",
       "75%      1.000000    0.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "          avg_salary  \n",
       "count     556.000000  \n",
       "mean   207741.151079  \n",
       "std     76330.908422  \n",
       "min     28080.000000  \n",
       "25%    151840.000000  \n",
       "50%    203840.000000  \n",
       "75%    251940.000000  \n",
       "max    494000.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 864 entries, 0 to 863\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Company Name  864 non-null    object \n",
      " 1   Location      858 non-null    object \n",
      " 2   Job Title     864 non-null    object \n",
      " 3   job_category  864 non-null    object \n",
      " 4   python_yn     497 non-null    float64\n",
      " 5   R_yn          497 non-null    float64\n",
      " 6   spark         497 non-null    float64\n",
      " 7   aws           497 non-null    float64\n",
      " 8   excel         497 non-null    float64\n",
      " 9   avg_salary    556 non-null    float64\n",
      "dtypes: float64(6), object(4)\n",
      "memory usage: 67.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
