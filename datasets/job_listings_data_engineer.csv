company,currency,date_posted,description,emails,interval,is_remote,job_function,job_level,job_type,job_url,job_url_direct,listing_type,location,max_amount,min_amount,title
Akkodis,,1738368000000,"BI Data Engineer - MS Dynamics 365 F&O £70,000 - £85,000 depending on experience Remote working, UK based candidates only Permanent Role Overview: My client is looking for an experience BI Data Engineer to join a newly established Data Services Team. A large chunk of the roles will involve supporting Finance Business Intelligence and working with a number of different workstreams including BI analysts, MS D365FO consultants, and more to understand the key reporting requirements and how data will be used. The rest of your time will be used to help grow the clients BI and Data Services capabilities across the wider business, delivering and supporting BI reporting when needed. Key Responsibilities: Design and develop scalable data warehousing solutions using Snowflake. Create robust ETL pipelines with tools like Azure Data Factory and LogicApps. Develop PowerBI data models and dashboards to meet reporting needs. Collaborate with Finance SMEs, BI analysts, and D365 consultants to deliver Finance BI solutions. Monitor and optimise the performance of data pipelines and reporting solutions. Ensure the Data Warehouse is operating efficiently and effectively, reflective of the business requirements Ensure BI and data solutions adhere to security, regulatory, and audit standards, including ISO27001 and SOC2-Type2. Required Experience: Proficient in Snowflake, PowerBI, Azure Data Factory, SQL, and DAX. Experience with MS DF&O, Power Platform, Azure LogicApps, and Data Lake. Skilled in extracting and transforming data from RESTful APIs and formats including JSON, CSV, and Parquet. Familiarity with Azure Cloud, Power Platform, Dynamics 365 F&O, and Cognitive Services. Strong ability to translate business needs into technical solutions. Expertise in data mapping, architecture, and transformation. Desired Experience: SnowPro Certification (Data Engineer, Administrator, or Architect). Microsoft DP-203 (Azure Data Engineer) or DP-600 (Fabric Analytics Engineer).Modis International Ltd acts as an employment agency for permanent recruitment and an employment business for the supply of temporary workers in the UK. Modis Europe Ltd provide a variety of international solutions that connect clients to the best talent in the world. For all positions based in Switzerland, Modis Europe Ltd works with its licensed Swiss partner Accurity GmbH to ensure that candidate applications are handled in accordance with Swiss law. Both Modis International Ltd and Modis Europe Ltd are Equal Opportunities Employers. By applying for this role your details will be submitted to Modis International Ltd and/ or Modis Europe Ltd. Our Candidate Privacy Information Statement which explains how we will use your information is available on the Modis website",,,True,,,fulltime,https://talents.studysmarter.co.uk/companies/akkodis/bi-data-engineer-ms-dynamics-365-fo-930913/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Newcastle upon Tyne,,,BI Data Engineer – MS Dynamics 365 F&O
Noir,,1738368000000,"Data Engineer - FinTech Company - Newcastle

(Tech Stack: Data Engineer, Databricks, Python, Azure, Power BI, AWS QuickSight, AWS, TSQL, ETL, Agile Methodologies)

I’m working with a leading Software House in the FinTech industry, based in Newcastle, who are looking to hire a talented Data Engineer. This is a fantastic opportunity to join a forward-thinking company where you’ll play a key role in developing and optimising their data platform.

The Role:

As a Data Engineer, you’ll be working closely with the front office to understand data needs and help shape the company’s data capabilities. You’ll be responsible for building and optimising data pipelines, automating data processes, and ensuring high data quality and governance.

Key Responsibilities:
• Collaborate with the front office to scope and understand data requirements.
• Build and maintain the data platform using in-house and third-party tools.
• Automate data processes to improve efficiency and scalability.
• Develop robust data pipelines to ingest and transform data from multiple providers.
• Curate both external and internal datasets to meet business needs.
• Design and implement best-practice data architecture and governance strategies.
• Establish and maintain data quality standards and validation rules.

What They’re Looking For:
• Experience in a data-focused role, with a strong passion for working with data and delivering value to stakeholders.
• Strong proficiency in SQL, Python, and Apache Spark, with hands-on experience using these technologies in a production environment.
• Experience with Databricks and Microsoft Azure is highly desirable.
• Financial Services experience is a plus but not essential.
• Excellent communication skills, with the ability to explain complex data concepts in a clear and concise manner.
• Ability to work autonomously and take ownership of tasks while maintaining high standards.
• Strong problem-solving skills, with a focus on creating scalable, high-quality solutions.
• Detail-oriented, with a keen eye for spotting data inconsistencies.
• A genuine interest in understanding and solving business challenges through data.
• A 2:1 or higher degree in Computer Science or a related field, ideally from a top-tier university.

Why Join?

This is a great opportunity to work with cutting-edge technology in a thriving FinTech environment. You’ll be part of a talented and collaborative team, with plenty of opportunities for growth and career development.

If you’re a Data Engineer looking for your next challenge, I’d love to hear from you!

Location: Newcastle, UK

Salary: Competitive + Bonus + Pension + Benefits

Applicants must be based in the UK and have the right to work in the UK even though remote work is available.

To apply for this position please send your CV to Matt Jones at Noir.

NOIRUKTECHREC

NOIRUKREC

NC/RG/DE",,,True,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-newcastle-at-noir-4140115003?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Newcastle upon Tyne,,,Data Engineer - Newcastle
Sky,,1738368000000,"What you'll do Continually integrate existing and new data sources across the AdTech Domain Craft and build scalable batch processing and ETL pipelines for data analytics using SQL and SSIS.

Recommend on tools, technologies on standards and good practice.

Build phenomenal software on DotNet Core or Java.

Work side by side with our customers and partners in an agile environment to build great outcomes.

Support during testing and transition into live use.

Work with Application Engineers to share this data across Sky.

Continuously improve and optimise the performance and cost efficiency of our data platform.

Champion TDD, BDD and Clean Code practices across the team What you'll bring Strong programming background with solid DotNet Core or Java or Python and SQL skills.

DBT is a bonus.

Commercial experience with ETL and corresponding tooling either with a 3rd party tool or from one of the public cloud vendors.

Data Engineering in a public cloud environment including cost optimisation.

Extra points for having Google Cloud Platform experience.

Knowledge of orchestration tools and Cloud monitoring systems like Prisma or ELK.

Experience of applying CI/CD and Infrastructure as Code principles to Data Engineering Team overview Sky Advertising Technology provides innovative solutions to Sky's Advertising opportunities including the industry leading AdSmart
- that allows our clients to accurately target their adverts to relevant households.

You'll be helping to build and manage those systems and be part of the migration of AdTech systems into the Cloud! Content technology and innovation Our Content Technology and Innovation team delivers high-quality content to homes, customer devices, businesses and commercial partners across our European markets.

With over 2500 colleagues from around the world, we combine our strategic insights, engineering know-how and operational excellence to use the most innovative technologies to create and distribute our award-winning content! The rewards There's one thing people can't stop talking about when it comes to #LifeAtSky :

the perks.

Here's a taster:

Sky Q, for the TV you love all in one place The magic of Sky Glass at an exclusive rate A generous pension package Private healthcare Discounted mobile and broadband A wide range of Sky VIP rewards and experiences Inclusion & how you'll work Recognised by The Times and Stonewall, we take pride in our approach to diversity and inclusion.

Investing in society, fighting racial injustice and setting ambitious targets for representation at Sky.

We've embraced hybrid working and split our time between unique office spaces and the convenience of working from home.

You'll find out more about what hybrid working looks like for your role later on in the recruitment process.

Your office space Osterley Our Osterley Campus is a 10-minute walk from Syon Lane train station.

Or you can hop on one of our free shuttle buses that run to and from Osterley, Gunnersbury, Ealing Broadway and South Ealing tube stations.

There are also plenty of bike shelters and showers.

On campus, you'll find 13 subsidised restaurants, cafes, and a Waitrose.

You can keep in shape at our subsidised gym, catch the latest shows and movies at our cinema, get your car washed, and even get pampered at our beauty salon.

We'd love to hear from you Inventive, forward-thinking minds come together to work in Tech, Product and Data at Sky.

It's a place where you can explore what if, how far, and what next.

But better doesn't stop at what we do, it's how we do it, too.

We embrace each other's differences.

We support our community and contribute to a sustainable future for our business and the planet.

If you believe in better, we'll back you all the way.

Just so you know:

if your application is successful, we'll ask you to complete a criminal record check.

And depending on the role you have applied for and the nature of any convictions you may have, we might have to withdraw the offer.
Sky
Isleworth England",,,False,,,fulltime,https://uk.joboolo.com/uk/job-data+architect/intuk22656856?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Isleworth,,,Lead Data Engineer > Joboolo UK
Elanco,,1738368000000,"Education : EQUIVALENTEXPERIENCE

At Elanco (NYSE: ELAN) – it all starts with animals!

As a global leader in animal health, we are dedicated to innovation and delivering products and services to prevent and treat disease in farm animals and pets. We’re driven by our vision of ‘Food and Companionship Enriching Life’ and our approach to sustainability – the Elanco Healthy Purpose™ – to advance the health of animals, people, the planet and our enterprise.

At Elanco, we pride ourselves on fostering a diverse and inclusive work environment. We believe that diversity is the driving force behind innovation, creativity, and overall business success. Here, you’ll be part of a company that values and champions new ways of thinking, work with dynamic individuals, and acquire new skills and experiences that will propel your career to new heights.

Making animals’ lives better makes life better – join our team today!

Location: Hook, UK (Hybrid)

Data Engineering at Elanco is growing across ingestion, integration, transformation, consumption, and governance capabilities to deliver data products that will transform how the organization leverages data. The Data Engineering and Platforms organization is seeking an experienced Data Governance Engineer to provide technical leadership to both internal and partner teams working within our Enterprise Data environment. This is a broad role which will include coaching and leading junior engineers in their domain, as well as partnering with engineering and product leadership to deliver on the data strategy.

To be successful in an engineering role at Elanco requires a highly motivated individual with an innovative mindset and willingness to drive tangible outcomes. The individual must be able to articulate complex technical topics, collaborate with internal and external partners, and ensure quality delivery of the required data products.

Reporting to the Associate Director - Data Platforms, the Lead Data Governance Engineer will manage all technical aspects of the Collibra Data Intelligence Platform ecosystem, including platform administration, release management, security, system integrations, and optimization of core components (Console, DIC, Edge, Lineage Harvester, and DQ&O). This role requires expertise in cloud computing, data management, and platform automation, with specific knowledge of Databricks, MS Azure, Terraform, and API integration. As part of a global, cross-functional team of technology and data experts, this role collaborates globally to ensure the platform's successful implementation and adoption.

Responsibilities

Platform Administration
• Administer and maintain the Collibra Data Governance platform including Collibra Console, Collibra DIC, Edge, Lineage Harvester and Collibra Data quality & observability.
• Working in terminals with Shell commands to manage the platform and VMs.
• Work with data engineers to facilitate data integration to systems such as Databricks, Azure Synapse, Power BI, & GCP Big query.
• Configure and manage Collibra communities/domain, workflows, data lineage, and business glossaries.
• Work with business SMEs and identified project partners to develop requirements (functional/non-functional/operational/data quality) for Data Governance, Metadata, Data Quality and translate them into technical solutions.
• Collaborate with data stewards, data owners, and IT teams to ensure data governance policies and standards are effectively implemented.
• Manage licenses and users including role-based access control.
• Responsible for user/ user group onboarding on Collibra with correct privileges, including advising on right privileges to manage security and license cost optimization.
• Develop training materials, use case and asset model documentation, as well as implementation specification.
• Provide recommendations for leveraging full functionality of Collibra platform (workflow, lineage diagrams, UI, dashboards, views, etc.).
• Manage server configurations, monitor system performance, and troubleshoot issues.
• Work closely with Data governance product owner, the Enterprise data office, IT, and data engineering teams to understand requirements, gather feedback, and continuously improve platform performance and user experience.

DevOps and Automation
• Integrate Collibra with other enterprise systems, infrastructure automation, and tools using APIs, Kubernetes, Terraform, and Ansible for CI/CD and IaC.

Continuous Learning
• Provide technical support and training to users on the Collibra platform and related tools.
• Stay ahead of Collibra updates, big data technologies, automation tools, and cloud services.
• Recommend and implement best practices for data governance, automation, and platform management.

Qualifications
• Bachelor’s Degree in Computer Science, Software Engineering, or equivalent professional experience.
• 4+ years of experience engineering and delivering enterprise scale data solutions, with examples in the cloud (especially Databricks, Azure, and GCP) strongly preferred.
• 4+ years of experience administering a Data governance platform, ideally Collibra.

Additional Skills/Preferences
• Collibra Ranger or Solution Architect certification.
• Ability to translate complex business needs into technical requirements.
• Experience with Infrastructure automation and application techniques and technologies such as Terraform, Kubernetes, and Ansible.
• Strong proficiency in administration, configuration, functional & technical architecture of Collibra across Collibra Data intelligence Cloud, Lineage Harvester, Collibra Edge and Collibra Data Quality & Observability.
• Experience with ETL tools and processes, ensuring proper data lineage and data quality.
• Experience with APIs for system integration and process automation.
• Experience with Collibra Data Quality tools for data profiling and data quality rule implementation.
• Familiarity with data tools and cloud platforms such as Power BI, Azure, Databricks, GCP, and Big Query.
• Experience configuring and customizing workflows in Collibra using Business Process Model and Notation (BPMN).
• Solid understanding of data governance principles, lineage, and metadata management.
• Exceptional problem-solving, proactiveness, and attention to detail.
• Strong communication, collaboration, and the ability to work effectively across teams.
• Experience working in complex enterprise landscapes (business, technology, regulatory, partners, providers, geographies, etc.).

Other Information: Occasional travel may be required.

Direct Reports: 0

Elanco is an EEO/Affirmative Action Employer and does not discriminate on the basis of age, race, color, religion, gender, sexual orientation, gender identity, gender expression, national origin, protected veteran status, disability or any other legally protected status",,,False,,,fulltime,https://www.simplyhired.co.uk/job/1vtYc-B-bdu7XA9f-W_2nh_ZfYdfXu65UalKMoY_WXBWRxGLJfvkqw?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,England,,,Lead Data Governance Engineer
Virgin Media O2,,1738281600000,"We are looking for an experienced Data Engineer who will use innovative GCP technology and Cloud Spanner at scale to develop a unified identification service that connects millions of Virgin Media and O2 customers together.

This is a varied role where you will collaborate with highly skilled Architects, DevOps and Analytic Engineering teams to achieve key results for our stakeholders as well as playing an instrumental role in identifying areas for improvement, proposing innovative ideas, and contributing to the overall growth and success of our data team.

Who we are

The UK’s fastest broadband network. The nation’s best-loved mobile brand. And, one of the UK's biggest companies too.

Diverse, high performing teams - jam packed with serious talent. Together, we offer the UK more choice and better value, through our boundary-pushing, customer-championing values and ambitions.

Together, we are Virgin Media O2, and we can't wait to see what you can do.

Accessible, inclusive and equitable for all

Virgin Media O2 is an equal opportunities employer and we're working hard to remove bias and barriers for our people and candidates. So, we build equity and inclusion into everything we do, from the policies we craft to the relationships we shape. We support and encourage you to be your authentic self throughout your application journey with us.

The must haves

In order to be considered, you must have the following experience;
• Have strong SQL skills including analytic functions and ensuring data quality.
• Demonstrable production experience working on a cloud environment, preferably GCP.
• Have experience of using a data warehouse engine such as BigQuery or Redshift .
• Have strong proficiency in Python with proven Data Engineering experience.

The other stuff we are looking for

We'd also love you to bring;
• An understanding of DevOps best practices including IaC and CI/CD
• Hands on experience of Apache Beam on Cloud Dataflow

What's in it for you

Our goal is to celebrate our people, their lives and everything in-between. We aim to create a culture that empowers everyone to bring the best versions of themselves to work each and every day. We believe the most inclusive and diverse culture makes for a better business and a brighter world.

Working at Virgin Media O2, you get a bumper reward package bursting with benefits, and loads of extras you can add if you’d like to. These are designed to support both you and your loved ones, making sure that you’re covered no matter what life throws your way.

Next steps

If we feel like a place where you can belong, we'd love to learn more about you as a person and your experience to date. Once you've submitted an application the next steps of the process, if successful, are likely to include a take home technical exercise and two stage interview.

When you apply, you'll be asked about any adjustments you might need to support the recruitment process. Let us know, and we'll be sure to discuss it with you.

Please note: Applications will be reviewed, and interviews conducted throughout the duration of this advert, therefore we may bring the closing date forward. We encourage all interested applicants to apply as soon as possible. Thanks for your patience and for showing an interest in joining the Virgin Media O2 family.

#LI-PS1",,,False,,,fulltime,https://flexa.careers/jobs/virginmediao2digital-data-engineer-679cbc823c291ae6da44c9ef?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Spennymoor,,,Data Engineer
Barclays,,1738281600000,"Join Barclays as an R&D Software and Data Engineer where you'll spearhead the evolution of our digital landscape, driving innovation and excellence. In this role, you will be an integral part of our Cyber Fraud Fusion Centre, delivering scalable CFFC services to disrupt and prevent upstream economic crime.

To be successful as an R&D Software and Data Engineer, you will need the following: ​
• Experience working within Financial Service teams responsible for cyber fraud, financial crime or security (web/app).
• Experience with industry fraud and security signals, including any such as digital identity, device, voice, biometrics, and behavioural profiling technologies.
• Knowledge of malicious attack vectors used by cyber fraud adversaries to target the financial sector including but not limited to Device Spoofing, Location Manipulation, Identity Fraud, Account Takeover and False documentation.
• Hands on practical experience using AWS, Python, Relational databases (Postgres, MS SQL, Oracle, Mysql, etc.), SAS PROC SQL, Hue Database Assistant, Teradata, and non-rational Hadoop.

Some other highly valued skills may include: ​
• Knowledge of Enterprise security frameworks such as NIST Cybersecurity Framework and Cyber-attack phases (e.g. Cyber Kill Chain and/or Mitre Att&ck Framework).
• Previous advanced experience using analytical tools and platforms such as SQL/SAS/Hue/Hive Basic, Quantexa, Elastic Search, SAS and MI tools like Tableau and Power BI.
• Advanced knowledge of malicious attack vectors used by cyber fraud adversaries.
• Knowledge of security network architectures (e.g. Proxies, VPN, DNS, web and mail servers) and the principles of network security.
• ICA Certificate/Diploma in Financial Crime Prevention, CAMS Certification, CFE Certification, or equivalent.​

You may be assessed on the key critical skills relevant for success in role, such as risk and controls, change and transformation, business acumen strategic thinking and digital and technology, as well as job-specific technical skills.

The successful candidate can either be based in Knutsford or Northampton.

Purpose of the role

To design, develop and improve software, utilising various engineering methodologies, that provides business, platform, and technology capabilities for our customers and colleagues.

Accountabilities
• Development and delivery of high-quality software solutions by using industry aligned programming languages, frameworks, and tools. Ensuring that code is scalable, maintainable, and optimized for performance.
• Cross-functional collaboration with product managers, designers, and other engineers to define software requirements, devise solution strategies, and ensure seamless integration and alignment with business objectives.
• Collaboration with peers, participate in code reviews, and promote a culture of code quality and knowledge sharing.
• Stay informed of industry technology trends and innovations and actively contribute to the organization’s technology communities to foster a culture of technical excellence and growth.
• Adherence to secure coding practices to mitigate vulnerabilities, protect sensitive data, and ensure secure software solutions.
• Implementation of effective unit testing practices to ensure proper code design, readability, and reliability.

Analyst Expectations
• Will have an impact on the work of related teams within the area.
• Partner with other functions and business areas.
• Take responsibility for end results of a team’s operational processing and activities.
• Escalate breaches of policies/procedure appropriately.
• Take responsibility for embedding new policies/ procedures adopted due to risk mitigation.
• Advise and influence decision making within own area of expertise.
• Take ownership for managing risk and strengthening controls in relation to the work you own or contribute to. Deliver your work and areas of responsibility in line with relevant rules, regulation and codes of conduct.
• Maintain and continually build an understanding of how own sub-function integrates with function, alongside knowledge of the organisations products, services and processes within the function.
• Demonstrate understanding of how areas coordinate and contribute to the achievement of the objectives of the organisation sub-function.
• Make evaluative judgements based on the analysis of factual information, paying attention to detail.
• Resolve problems by identifying and selecting solutions through the application of acquired technical experience and will be guided by precedents.
• Guide and persuade team members and communicate complex / sensitive information.
• Act as contact point for stakeholders outside of the immediate function, while building a network of contacts outside team and external to the organisation.

All colleagues will be expected to demonstrate the Barclays Values of Respect, Integrity, Service, Excellence and Stewardship – our moral compass, helping us do what we believe is right. They will also be expected to demonstrate the Barclays Mindset – to Empower, Challenge and Drive – the operating manual for how we behave.",,,False,,,fulltime,https://search.jobs.barclays/job/knutsford/r-and-d-software-and-data-engineer/13015/71359186688?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Northampton,,,R&D Software and Data Engineer
iO Associates,,1738281600000,"Role: Lead Data Engineer (Hands-on) Rate: £425.00 - £470.00 Inside Ir35 Clearance: SC Cleared (actice, used within last 12 months) Location: Hybrid/London (once every month) Start date: ASAP Company Overview: Recruiting for a leading cloud solutions provider specialising in digital transformation and data engineering services. The mission is to empower organisations to unlock their data's full potential through innovative cloud solutions. Seeking a Lead Data Engineer to support the data engineering team in designing and implementing solutions for complex migration projects. Job Overview: The Lead Data Engineer will oversee the design and implementation of data engineering solutions, leading a team in migrating Legacy Oracle databases to AWS managed databases. Expertise in AWS services like AWS Glue, AWS Managed Flink, S3, AWS RDS, and Lambda is essential for mentoring, troubleshooting, and optimizing data solutions. Key Responsibilities: Lead ETL processes using AWS Glue to migrate data from Legacy Oracle databases to AWS managed databases, document databases, and data lakes. Oversee development and maintenance of scalable data pipelines. Provide technical leadership and mentorship to Data Engineers. Collaborate with solution architects, data scientists, and stakeholders. Optimize data workflows using AWS services. Ensure adherence to data quality, security, and governance standards. Automate and monitor data pipelines with proactive alerting mechanisms. Drive continuous improvement and stay updated with emerging AWS services. Lead technical discussions and ensure alignment on design and implementation. Provide regular updates on project status and challenges to senior leadership. Qualifications: Proven expertise in designing and developing ETL processes using AWS Glue. Experience migrating Legacy Oracle databases to AWS managed databases. Strong knowledge of AWS services (S3, AWS Managed Flink, Lambda, CloudWatch). Expertise in building and maintaining data lakes, document databases, and relational databases. Hands-on experience with data pipeline architecture and development. Proficiency in SQL and Python. Strong understanding of data governance, quality, and security. Desirable - AWS certifications (AWS Certified Data Analytics, AWS Certified Solutions Architect). Preferred Skills: Experience with big data processing technologies (Apache Spark, PySpark). Knowledge of DevOps practices and tools. Familiarity with data warehousing, dimensional modelling, and data architecture best practices. JBRP1_UKTJ",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/io-associates/lead-data-engineer-aws-903817/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Leeds,,,Lead Data Engineer (AWS)
Homes England,,1738281600000,"Head of Data Engineering and Platform

Application closing date: 16/02/25 at 23:59

Location: Birmingham, Liverpool or Newcastle

A bit about the role…

As the Head of Data Engineering and Data Platform, you will lead the design, development, and management of our cloud-based data environment, ensuring it meets the organisation's current and future needs. You will drive the growth and evolution of the Platform, identifying opportunities to adopt new technologies and enhance capabilities to support the Agency. This is a critical role within the Data & Analytics directorate, where you will oversee the end-to-end engineering of data pipelines, ensuring the efficient ingestion, transformation, and accessibility of trusted data across the agency. Your work will underpin the agency’s data-driven decision-making, enabling advanced analytics, AI, and innovation.

You will provide strategic leadership to the data platform team, driving the adoption of emerging technologies and ensuring that the platform is secure, scalable, and aligned with organisational objectives. As Head of Profession for data engineers, you will ensure that the agency has the right skills, capacity and flexibility to meet its aspirations. By collaborating with data governance, architecture, and analytics teams, you will create a robust, well-structured data ecosystem that supports efficient data operations and enhances user experience. In this role, you will balance strategic oversight with practical delivery, ensuring delivery of a reliable, high-performing data platform.

This is an exciting opportunity to shape the future of data engineering at Homes England. Through your leadership, the agency will develop cutting-edge capabilities to streamline operations, support innovation, and deliver measurable value. You will work closely with stakeholders across the organisation, ensuring the data platform is aligned with business priorities and contributes directly to the agency’s mission in housing and regeneration.

A bit about you…

You are a visionary leader with a proven track record in designing and managing cloud-based data platforms at an enterprise level. With significant experience in data engineering and a deep understanding of data management principles, you are adept at translating complex technical concepts into strategies that support organisational goals. Your hands-on approach, paired with a strategic mindset, ensures the delivery of impactful solutions that drive measurable results.

As an experienced leader, you excel at building and leading high-performing teams, fostering an environment of collaboration, innovation, and continuous improvement. You have strong interpersonal and communication skills, enabling you to engage effectively with stakeholders across the organisation, aligning data initiatives with business needs, and advocating for a data-driven culture. Your ability to identify and adopt emerging technologies further demonstrates your commitment to advancing the organisation’s data capabilities.

Adaptable and flexible, you thrive in a fast-paced environment and view challenges as opportunities for growth. With a focus on operational excellence, you are dedicated to ensuring that data is accessible, secure, and well-managed. Your leadership and passion for driving positive change make you a key figure in enabling the organisation to achieve its ambitions through the power of data.

Who are we?

Homes England: The Housing and Regeneration Agency

We believe that affordable, quality homes in well-designed places are key to improving people’s lives. As the government’s housing and regeneration agency, we create thriving new places and transform urban areas, combining the full breadth of our powers, expertise, land, capital and influence to bring investment to communities and get more homes built.

How? We form long-term partnerships that bridge the gap between the public and private sector to meet local needs and aspirations. We use our influence to champion the creation of sustainable homes, communities and places that are brilliantly designed for the people that live there now, and in the future. And we use our funding and support to build a more resilient, diverse and innovative housing sector, helping new entrants in the market, encouraging modern methods of construction and design, and promoting the utmost attention to building safety.

Together with our partners, we’re accelerating the pace of house building, remediation and regeneration across the country, as we seek to deliver ever more affordable homes in places people are proud to call home for generations to come.

What we offer...

As well as a competitive salary and 33 days annual leave, we are committed to 50/50 hybrid working. We’ll support you, wherever possible, so that you don’t miss out on what matters to you.

Membership of the Homes and Communities Agency Pension Scheme, which is a contributory defined benefit scheme with the amount you receive on retirement based on your salary and years worked at the Agency.

Internal applicants: please note that if you are successful, the salary you are offered will be in accordance with our pay controls and pay policy. You can find details on the HR Hub SharePoint site.

If you ever need a bit of extra help, we have a great employee assistance programme, financial wellbeing support and access to many great discounts with leading high street names.

Our range of network groups are also there to support you to be yourself at work and play a key role in helping shape our future.

If you are a member of a professional body, we’ll pay for your membership and once you get your digital kit, you’ll be good to go.

Homes England are a geographically diverse community. We work to a 50/50 office/ home based model. Moving back into our office environments has enabled us to utilise our space and time together in the most collaborative way.

We would encourage all applicants to apply as soon as possible as we may close vacancies early should we receive a high number of applications.

We also encourage you to apply using the full application option as opposed to quick apply, this is especially important if you would like to indicate to us that you would like to be considered under the disability confident scheme.

If your application is shortlisted to interview we will require you to provide proof of your right to work in the UK at this stage.",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/head-of-data-engineering-and-platform-at-homes-england-4139144924?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Newcastle upon Tyne,,,Head of Data Engineering and Platform
Corecom Consulting,,1738281600000,"• *Job Summary (50 words)**

We are seeking an experienced IMAC Engineer to support installations, upgrades, and maintenance across data centres in the Northern region. This is a dynamic, client-facing role that's critical to ensuring seamless IT infrastructure deployment and top-tier customer service.
Job Description

Key Responsibilities:
• Perform installations, upgrades, and maintenance tasks for client data centres.
• Set up hardware, including racking, stacking, powering, and connectivity testing.
• Manage small-scale projects and multi-day deployments, ensuring timely delivery.
• Valid UK driving license.
• Eligibility to obtain Security Check (SC) clearance.
• Proven experience with installing/upgrading data centre infrastructure.

Requirements:
• A professional, customer-first mindset.
• The adaptability to handle a range of tasks—from quick setups to complex deployments.
What We Offer

• Competitive salary: £32,000 - £35,000 per annum, flexible for highly experienced candidates.

• Approximately £4,800 annual car allowance.

• Travel expenses for all client site visits.

• Professional development opportunities and career growth.
Application Process

Stage 1: Virtual interview via Teams.

Stage 2: Face-to-face interview at the York office.",,,False,,,fulltime,https://gb.bebee.com/job/e26a5dfb30cad9c5b153d638663aca43?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Birmingham,,,Remote Data Engineer
Selby Jennings,,1738195200000,"Our client, a top-tier hedge fund with a strong focus on technology, is seeking a Data Integration Specialist / Data Engineer to join their London-based team. In this role, you’ll be responsible for building and managing multiple datasets that power their research and trading platforms, as well as developing automated ETL pipelines to accelerate data onboarding. You'll also contribute to the design and implementation of the data framework, playing a key part in shaping their data infrastructure. Develop automated ETL pipelines to onboard data efficiently Contribute to the design and implementation of the data framework Monitor data health and fetching processes to ensure reliability Build data quality checks to ensure accuracy and completeness 1-4 years’ experience in a similar data-focused role ~ Strong knowledge of Python, with experience in additional programming languages preferred ~ Solid understanding of AWS services ~ Experience with datalakes and databases is a plus ~",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/selby-jennings/data-engineer-aws-specialist-873980/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer (AWS Specialist)
Deerfoot Recruitment Solutions Limited,,1738195200000,"Palantir Data Engineer

Hybrid remote/ must be sc clearance eligible
Overview

We are seeking a passionate and experienced Palantir Data Engineer to join our clients Cloud Data Platforms team. As part of the Insights and Data Global Practice, you will play a key role in driving our customers' digital and data transformation journey using modern cloud platforms. This is a remote/hybrid position, offering flexibility across our UK offices, with a negotiable salary and benefits package.
Responsibilities
• Design and build data engineering solutions, and support the planning and implementation of data solutions
• Collaborate with clients and local teams to deliver modern data products and build relationships
• Utilize Palantir Data focused Reference Architecture to design and build data solutions
• Analyze current business practices, processes, and procedures to identify opportunities for leveraging Palantir services and implement effective metrics and monitoring processes
• Translate business problems into operational improvements and end user solutions in collaboration with internal and external stakeholders
• Work with large scale, complex datasets to solve business problems and drive insight at pace
Qualifications
• Experience in developing enterprise-grade data pipelines and applying Data Engineering best practices
• Strong knowledge and experience with Palantir Data Engineering features such as Code Repo, Code Workbook, Pipeline Builder, migration techniques, Data Connection, and Security setup
• Proficiency in developing data integration pipelines, transformations, pipeline scheduling, Ontology, and applications in Palantir Foundry
• Excellent skills in PySpark and Spark SQL for data transformations
• Experience in designing and building interactive data applications and developing parameterized, interactive dashboards in Quiver
• Desirable skills include Palantir Foundry Amplify data engineering certification, experience with CI/CD technologies, and hands-on experience with Python, SQL, and Cloud provisioning tools
Day-to-day

Your day-to-day activities will involve collaborating with Solution Architects, Product Owners, and Business users to understand requirements and lead the delivery of data solutions in Palantir. You will also work on designing and building interactive data applications, developing parameterized, interactive dashboards, and deploying Palantir data solutions to Cloud platforms.
Benefits
• Remote/hybrid working options across UK offices
• Negotiable salary and benefits package
• Opportunity to work on diverse projects and sectors
• Professional development and training opportunities
• Collaborative and inclusive work environment

If you are passionate about Cloud technology and have a strong background in Palantir Data Engineering, we encourage you to apply for this exciting opportunity.

Please note that Security Check (SC) clearance is a requirement for this role, and applicants must have resided continuously within the United Kingdom for the last 5 years.

To apply, please submit your CV and cover letter detailing your relevant experience and skills.

Deerfoot Recruitment Solutions Ltd is one of the longest-established independent technology recruitment consultancies in the UK.

Each time Deerfoot sends a CV to a recruiting client, we donate £1 to The Born Free Foundation ((phone number removed)). Deerfoot is a Climate Action Workforce in partnership with Ecologi.

If this role isn't the right fit for you, we have a fantastic candidate referral reward program in place. We offer payouts at both interview and placement milestones. For further details, please visit our website.

Deerfoot Recruitment Solutions Ltd is acting as an Employment Agency in relation to this vacancy.",,,True,,,fulltime,https://www.cv-library.co.uk/job/222983327/Palantir-Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Palantir Data Engineer
Rimes,,1738195200000,"About Rimes

Rimes provides enterprise data management solutions to the global investment community. Driven by our passion for solving the most complex data problems, we provide our clients with investment intelligence that powers more than US$75 trillion in assets under management annually. The world's leading institutional investors, asset managers and service providers rely on Rimes to help them make better investment decisions using accurate information and industry-leading technology.

The Opportunity:

Data Team in Rimes work globally to offer hundreds of cloud-based financial databases across multiple asset classes to meet the fast-growing data requirements from global institutional clients.

Data Developers at Rimes build new data acquisition tools, processing information from incoming financial data feeds and loading it onto the Rimes platform. They also participate in the analysis of client data requirements and develop customized reporting processes.

Data Developers are expected to be knowledgeable about global financial market data and be able to work collaboratively with other teams worldwide. Rimes' hand-off management style encourages developers to take initiative to complete projects, manage multiple tasks, and to set their own individual day-to-day priorities.

What you will do:
• Building robust data pipelines for finance data ETL
• Building and operating data acquisition tools, custom analytics and reporting processes
• Working closely with 300+ global data partners
• Performing sophisticated data analysis in multiple asset classes
• Conducting advanced calculations to meet a large variety of data needs from institutional clients

Who you are:
• Excellent programming skills in Python
• Bachelor's or Master's degree in science or engineering or related fields
• 3+ years related work/project experience
• Knowledge of SQL, XML, REST API will be considered as an advantage
• Knowledge of financial markets and financial data will be considered as an advantage
• Working experience with Microsoft Excel will be considered as an advantage
• Solid programming skills in Perl will be considered as an advantage
• CFA level 2 candidates or above will be considered as an advantage
• Results driven and detail oriented
• Flexible and efficient at multitasking assignments
• Strong verbal and written communication skills in English
• Flexible, enthusiastic and display a positive attitude
• Able to multi-task, prioritize and meet deadlines
• Happy to work on your own initiative
• Interested in technology, but also aware of the need for appropriate processes and procedures
• Attentive to detail, but also able to demonstrate a wide degree of creativity
• A confident communicator with exceptional interpersonal skills

Rimes is committed to promote the values of diversity and inclusion throughout the business. Whether it's through recruitment, retention, career progression or training and development, we are committed to improving opportunities for people regardless of their background or circumstances.

Visit our Careers page to see our complete listings.",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-developer-at-rimes-4137894206?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Developer
Future Talent Group,,1738195200000,"Junior Data Engineer (Python / GIS Data / AWS) – Remote-Based

Location - Bristol/Remote Role

Salary - £35,000 + Shares + Benefits

We are conducting an exciting search for a fast-growing SaaS business that is revolutionising its sector by making complex processes faster and easier for everyone. With a cutting-edge, data-driven platform, this company is streamlining access to essential information, enabling users to complete tasks in minutes instead of weeks.

The business is thriving, generating strong revenue, and expanding its technical team to support ongoing growth and innovation.

Junior Data Engineer – This role is ideal for a junior engineer or graduate with at least one year of commercial experience, preferably with GIS data sets. You'll have the chance to work alongside an experienced Senior Data Engineer, tackling the product backlog and contributing to exciting new projects.

Tech stack:
• Python
• Amazon Web Services (AWS)
• Git
• PostgreSQL
• SQL
• Terraform / Docker
• Experience with GIS data sets is a bonus

#SaaS #TechGrowth #Python #PostgreSQL #DataEngineering",,,True,,,fulltime,https://uk.linkedin.com/jobs/view/junior-data-engineer-python-gis-data-aws-%E2%80%93-remote-based-at-future-talent-group-4138242681?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Bristol,,,Junior Data Engineer (Python / GIS Data / AWS) – Remote-Based
TechYard Recruitment,,1738195200000,"Job Opportunity: Data Engineer (Databricks Specialist)
Manchester | Employment Type : Full-time.

Are you a passionate Data & AI expert with a strong Databricks background? A leading consulting firm is seeking a person skilled in Data Engineering to join their growing team. In this senior role, you’ll work with clients to design and implement scalable, high-performance Databricks-based platforms that drive impactful business outcomes

As a Data Engineer, you will be responsible for designing, implementing, and optimizing data workflows that drive critical insights across the business. You'll work with cutting-edge technologies to build scalable, high-performance data solutions that meet the evolving needs of our clients.
Data Pipeline Development: Data Integration: Develop scalable data ingestion processes from multiple sources and integrate them into Delta Lake or data lakes for unified storage and analysis.
Partner closely with data architects, data scientists, and business analysts to understand requirements and deliver data solutions that align with business objectives and enhance analytics capabilities.
Performance Optimization: Optimize Databricks workflows for performance, scalability, and cost efficiency, including Spark tuning and cluster management .
Build cloud-native data engineering solutions on leading cloud platforms like Azure, AWS, or GCP to ensure seamless, secure, and efficient data management.
Governance & Quality: Implement and maintain data governance best practices, ensuring data consistency, quality, and security across the organization.
Automation: Automate repetitive tasks, develop robust CI/CD pipelines, and streamline data workflows to improve operational efficiency and reduce manual effort.
3+ years of experience in data engineering , with hands-on expertise in Databricks .
• Proven ability to deliver large-scale data pipelines in consulting or enterprise environments.
• Strong programming skills in Python and SQL , with optional experience in Scala .
• Experience with cloud platforms such as Azure (preferred), AWS , or GCP .
• Strong understanding of relational and non-relational databases , data lakes , and real-time data processing .
• Experience with tools like MLflow or other AI/ML frameworks .

Familiarity with data visualization tools such as Power BI or Tableau .
Azure Data Engineer Associate ).
Experience in automation and CI/CD practices for data engineering pipelines.

Challenging Projects: Work on diverse and impactful projects for clients across various industries, contributing to real-world data solutions.
Growth Opportunities: Gain exposure to cutting-edge technologies and continue developing your technical expertise within a fast-paced, innovative environment.
We offer an attractive salary, comprehensive benefits, and flexible working options, including remote work opportunities.
If you're passionate about data engineering , enjoy tackling complex challenges, and want to be part of a forward-thinking team, we want to hear from you!",,,True,,,fulltime,https://uk.jooble.org/rjdp/2603653037530368120?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Manchester,,,Data Engineer SQL - Remote (m/w/d)
Daintta,,1738108800000,"Daintta are a rapidly growing, values-driven team of specialists who work with government clients across Cyber, Telecommunications and Data. We are seeking a talented and motivated Data Engineer to join our team and contribute to our mission of protecting the UK through data-driven insights and solutions. As a Data Engineer, you will work closely with our public sector clients and project teams to develop and implement data engineering pipelines to support data science and business/mission intelligence use cases.

Key Responsibilities
• Assessing your clients' technical needs and understanding how their needs are different to wants and managing clients' stakeholders relationship appropriately
• Identifying data sources, data extraction, transformation, and loading (ETL/ELT) concepts and methods
• Designing, evaluating, and implementing on-premise, cloud-based and hybrid data engineering solutions (including providing review and guidance on testing aspects related to data engineering, identification of risks and proposing and implementing their mitigations)
• Modelling, structuring and storing data along with their data flows for uses including but not limited to analytics, machine learning, data mining, compliance, business intelligence, sharing with applications and organisations
• Harvesting and ingesting structured and unstructured data in different formats and standards
• Integrating, consolidating and cleansing data
• Migrating and converting data
• Applying ethical principles in handling data
• Ensuring appropriate storage of data in line with relevant legislation
• Building in security, compliance, scalability, efficiency, reliability, fidelity, flexibility and portability
• Accurately delivering high quality work to agreed timelines and taking the initiative and knowing how to jump straight in'
• Supporting client engagements, including pitches and presentations
• Helping to support & grow Daintta by actively inputting into the company strategy and helping to shape our future
• Representing us and our core values: Transparent, fair and daring

Skills/Knowledge
• You have 2+ years of degree level industry experience in data engineering, preferably in a consultancy or industry setting
• You have worked in client delivery across a range of projects, including data analysis, extraction, transformation, and loading, data intelligence, data security and proven experience in their technologies (e.g. Spark, cloud-based ETL services, Python, Kafka, SQL, Airflow)
• You have experience in assessing the relevant data quality issues based on data sources & uses cases, and can integrate the relevant data quality checks into data pipelines
• You have experience in designing schemas for data warehouses/data marts to support the relevant ingest and queries
• You have experience working on cloud-based infrastructure (e.g. AWS, Azure, GCP)
• You have demonstrable continuous personal development with relevant data certifications and accreditations
• You have strong interpersonal skills
• You are security cleared or capable and willing to undergo security clearance
• You have experience with using CI/CD tooling to analyse, build, test and deploy your pipelines and proven experience in their technologies
• You have experience in database technologies including writing complex queries against their (relational and non-relational) data stores (e.g. Postgres, Hadoop, Elasticsearch, Graph databases), and designing the database schemas to support those queries
• You have a good understanding of coding best practices and design patterns and experience with code and data versioning, dependency management, code quality and optimisation, error handling, logging, monitoring, validation and alerting

Location?

Hybrid, with 2-3 days working from Daintta office (London or Cheltenham) or on client site as required.

What's in it for you?

You will be joining the company at Daintta ""Consultant"" grade. In addition to being rewarded fairly for your contribution to the business, you get to work in a dynamic organisation that is agile and responsive. A business that is growing fast and where you get to drive and shape the future. A place where you are respected by everyone and your voice is important. Somewhere where you can be innovative and creative. A place where you have the opportunity to learn about all aspects of business from marketing to sales, to delivery and business operations.

Security Information

Due to the nature of this position, you must be willing and eligible to achieve a minimum of SC clearance. To qualify, you must be a British Citizen and have resided in the UK for the last 5 years. For more information about clearance eligibility, please see https://www.gov.uk/government/organisations/united-kingdom-security-vetting",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-consultant-at-daintta-4138520557?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Cheltenham,,,Data Engineer Consultant
Concept Resourcing,,1738108800000,"Job Title: Lead Data Engineer

Role Type: Permanent

Location: Birmingham (Hybrid)

Our client is seeking an experienced Lead Data Engineer or a Data Engineer aspiring to step into a lead position.

Role Overview

As the Data Engineer, you will be responsible for a team of data engineers, analysts and leveraging your expertise in Microsoft BI tools and cloud-based technologies to drive their data initiatives. You will play an integral role in guiding the team, developing curated business models, and utilising Azure services to optimise our data infrastructure.

Key Responsibilities
• Provide leadership, guidance, and support to team members, ensuring the successful execution of projects and tasks.
• Mentor and support the wider business, including Business Intelligence teams, to leverage data for decision-making using PowerBI and other Microsoft tools.
• Collaborate with cross-functional teams to achieve common business goals.
• Develop and maintain curated business models to support accurate and insightful decision-making.
• Ensure data security, compliance, and best practices are followed in Azure cloud environments.

Essential Skills
• Expertise in the Microsoft BI stack, including SSRS, SSAS, and SSIS.
• Hands-on experience with Azure Synapse, Azure Data Factory, and other Azure cloud services.
• Strong analytical and problem-solving skills, with the ability to turn complex data into actionable insights.
• Excellent communication and interpersonal skills, with the ability to collaborate effectively with diverse teams.
• Demonstrated ability to design and implement curated business models for reporting and analysis.

If you are a skilled Lead Data Engineer or a Data Engineer aspiring to become a lead, we would like to hear from you. Apply now!",,,False,,,fulltime,https://www.totaljobs.com/job/lead-data-engineer/concept-resourcing-job104226318?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,West Midlands,,,Lead Data Engineer
Tenth Revolution Group,,1738108800000,"My client is based in the London area are currently looking to recruit for an experienced Senior Data Engineer to join their Cloud & Infrastructure team. They are a specialist insurance organisation, that are at the forefront of engineering practices. They are currently going through a period of growth and are looking for an experienced Senior Data Engineer to join their team. They only recruit the ""best"" talent and have a diverse workforce. Your role will include: Implementing a new Snowflake Data warehouse Building pipelines, doing migrations, integration's with external systems. Solving simple and complex problems. Liaising with stakeholders across the business as an internal consultant. My client is providing access to; Hybrid 2-3 days in office, Bonus of up to 10%, 29 Holidays, Flexible Working, Private Health Care, And More...For this role, you will need to aid the implementation of a brand new Snowflake Data Warehouse . They are looking for a candidate that has experience in… AWS Data Platform, Strong knowledge of S3, Lambada, Snowflake DWH, Data Modelling, DevOps Practices, Ariflow, DBT, Data Vault, Snowflake experience, Strong SQL/Python. This role is an urgent requirement, there are limited interview slots left, if interested send an up to date CV to Shoaib Khan - (url removed) or call (phone number removed) for a catch up in complete confidence. TRG's Data Teams offer more opportunities across the UK than any other recruiter We're the proud sponsor and supporter of SQLBits, AWS RE:Invent, Power Platform World Tour, the London Power BI User Group, Newcastle Power BI User Group and Newcastle Data Platform and Cloud User Group",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/tenth-revolution-group/senior-data-engineer-role-london-hybrid-85000-10-bonus-846939/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,"Senior Data Engineer Role – London/Hybrid – £85,000 + 10% Bonus"
Tenth Revolution Group,,1738108800000,"Senior Data Engineer - Sheffield - Hybrid - £70k - £75k My client is currently recruiting for a Senior Data Engineer to join their team on a permanent basis. This role will require expertise in Azure, Databricks and SQL, with experience in senior positions with mentorship responsibilities. Salary and Benefits 25 days annual leave Hybrid working - 2 days per week in office (Sheffield) Development access to LinkedIn Learning, a management development programme and training Wellness 24/7 Confidential employee assistance programme Social - office parties, pizza Friday and commitment to charitable causes Pension Salary Exchange Scheme with 4% employer contribution and 5% employee contribution Discretionary Company Bonus based on company and individual performance Life Assurance of 4 times base salary Private Medical Insurance which is non-contributory (spouse and dependants included) Worldwide Travel Insurance which is non-contributory (spouse and dependants included) Benefits Platform offering various retail and leisure discountsRole & Responsibilities Designing, implementing, and managing data solutions on Microsoft Azure Developing and maintaining data architecture, migrating data acquired through M&A, ensuring data quality, and enabling advanced analytics capabilities to support business decision-making Reporting to the Group Head of Infrastructure & Security, you will oversee the performance and maintenance of the Azure Data Warehouse Manage the regular data migration of acquired firms' back office system data into our proprietary Gateway SQL database Be highly skilled in implementing and managing data integration solutions using Azure Data Factory, Azure Databricks, Azure Data Lake, and Azure Synapse Analytics Strong SQL experience Develop scripts and automation using PowerShell, Python, or other relevant languages Strong communication skills to provide technical guidance and mentorship to other team members and build and maintain relationships with other IT teamsWhat do I need to apply for the role Strong Azure experience - Azure Data Factory, Azure Databricks, Azure Data Lake, and Azure Synapse Analytics Strong SQL experience Python/Powershell - Scripting and automation skills MS Fabric (desirable) Experience in senior or lead data engineering positionsMy client have limited interview slots and they are looking to fill this vacancy within the coming weeks. I have limited slots for 1st stage interviews next week so if you're interest, get in touch ASAP with a copy of your most up to date CV and email me at or call me on (phone number removed). Please Note: This is a permanent role for UK residents only. This role does not offer Sponsorship. You must have the right to work in the UK with no restrictions. Some of our roles may be subject to successful background checks including a DBS and Credit Check. Nigel Frank are the go-to recruiter for Power BI and Azure Data Platform roles in the UK, offering more opportunities across the country than any other. We're the proud sponsor and supporter of SQLBits, Power Platform World Tour, the London Power BI User Group, Newcastle Power BI User Group and Newcastle Data Platform and Cloud User Group. To find out more and speak confidentially about your job search or hiring needs, please contact me directly at",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/tenth-revolution-group/senior-data-engineer-sheffield-hybrid-70k-75k-846185/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Sheffield,,,Senior Data Engineer – Sheffield – Hybrid – £70k – £75k
TN United Kingdom,,1738108800000,"Job Description

Legal and General Retail’s Data Operations team are currently hiring three Lead Data Engineers following the merger of internal divisions resulting in them expanding into a new area. These positions are to focus on the retirements side of the Retail division and will build out new data pipelines utilising tools such as Synapse, DBT, Azure Devops and Snowflake. This role will see you responsible for designing, building, and implementing a variety of data solutions using modern ETL techniques and tools and you will be driving projects forward while serving as a mentor and coach to junior members of the team.

What you will be doing
• Ensuring the solutions developed and deployed are fit for purpose and GDPR compliant, meeting the business requirements, adhering to quality standards, and delivering the intended value.
• Ensuring all developments delivered follow the agreed standards and release management processes.
• Taking responsibility for evolving these standards in an environment of continuous change facilitating team sessions that seek to improve them and keep them current & compliant.
• Identifying issues and risks with the solutions created and leading their resolution while providing support to colleagues in your team as required.
• Providing input into team and project planning activities and work within an agile delivery framework as part of a Scrum team.
• Facilitating the refinement of the tasks in the Product Backlog and guide and support your team as you break deliveries down into technical data engineering components.
• Converting user stories into technical, quality, testing and documentation tasks in the chosen work-flow management tool.
• Liaising with the end customers, Architect & Product Owner to translate business goals into compliant specifications that facilitate the delivery of the technical solution and can be used by any engineer.
• Participating in high level epic refinement sessions with the Scrum Team, ensuring that they are understood and achievable by the engineering team.
• Provide mentorship and support to junior and mid-level data engineers in your team and acting as a role model to colleagues across the Data Ops function.

Qualifications
• Relevant professional qualifications in Data Engineering or related specialism.
• Industry recognised badges/certificates on any of the following tools: Snowflake, Azure Synapse/Data Factory, DBTCloud, Azure DevOps.
• Industry recognised badges/certificates on any of the following methodologies: Scrum/Kanban, DevOps/DataOps, Dimensional Data Modelling (Kimball).

Additional Information

The brand with the brolly is choosing today to change tomorrow. Since 1836, we’ve grown to become one of the world's largest asset managers, homebuilders, pension providers and insurance brands. We’re all here to improve the lives of our customers, build a better society for the long term, and create value for our shareholders - helping to shape a better future for society and the planet. We need people who share our ambitions, agility and entrepreneurial spirit to help us do it. At L&G, you’ll find a balance that helps you be your best. Empowered by hybrid working, we’re supported by technology and workplaces that enable us to work effectively wherever we are. We come together in offices to collaborate and connect, and use time at home for individual, focused activities. And, when we achieve great things, we celebrate our success and reward strong performance. Today, there’s over 10,000 of us, working towards our mission, with plenty of opportunities to grow your career as we grow L&G. Will you join us?

Great minds don’t have to think alike, so we welcome voices from all backgrounds. Bringing together people with different life experiences helps us build empathy with our customers and drive innovation. We don’t just talk about it, we actively promote diversity and equitable opportunities for all. That means our employment decisions are made without regard to race, colour, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability or protected veteran status. In fact, we embrace every dimension of diversity to reflect the customers and communities we serve. We think it’s important to create an inclusive environment where we can all belong, contribute and drive progress, where you can develop and grow, and be empowered. We want you to use your voice to help us build a better tomorrow. We all work differently, and have different needs, which is why we’re always open to discussing flexible working arrangements. Likewise, we’re committed to finding reasonable accommodations for candidates with specific needs during our recruiting process. So whoever you are, wherever you are, whatever your story, we'd love to hear from you.

Please note that if you are NOT a passport holder of the country for the vacancy you might need a work permit. Check our Blog for more information.

Bank or payment details should not be provided when applying for a job. Eurojobs.com is not responsible for any external website content. All applications should be made via the 'Apply now' button.

Created on 22/01/2025 by TN United Kingdom
#J-18808-Ljbffr",,,False,,,fulltime,https://www.recruit.net/job/data-engineer-cardiff-jobs/45035384850C60E2?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Cardiff,,,"Lead Data Engineer, Cardiff"
Machine Learning Jobs,,1738022400000,"Data Engineer | £60,000 - £65,000 | UK/Remote |

Power BI | Synapse | Azure Data Bricks | ADF | SQL | Data Engineer | Reporting | Data Sets | Fabric |

Are you a Data Engineer who enjoys getting involved with the architecture side of the role? Or maybe you want to join a company and have autonomy? If so I have a role for you.

I am looking for an experienced Data Engineer to join a company that support the automotive industry covering a range of aspects from theft prevention to fleet management. They have grown impressively over the last year and are now looking to invest in people.

They have recently gone through an Azure Migration and are looking for a Data Engineer to join a small team to architect data sets, push them into Power BI and move them export to data lake to fabric link.

They are using a great tech stack which includes –Azure ADF, Data Lakes, Synapse, Power BI, Fabric, Logic Apps, SQL.

You will also be working closely with BI and SQL Developers with building dashboards and reports which will be going out to various customers.

Benefits include –
• 5% company pension
• Remote working
• Salary up to £65,000
• Private healthcare
• Learning and Development budget
• Perkbox
• Life Assurance
• Wellbeing options

Even though this is a remote position you need to be a full time UK resident and sponsorship isn’t available.

This a brilliant opportunity for someone looking to grow their career. They have a fantastic tech stack and have brilliant progression routes.

Power BI | Synapse | Azure Data Bricks | ADF | SQL | Data Engineer | Reporting | Data Sets | Fabric |",,,True,,,fulltime,https://machinelearningjobs.co.uk/view-job/data-engineer-ps60000-ps65000-ukremote-162db5fdb765?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Newcastle upon Tyne,,,"Data Engineer | £60,000 - £65,000 | UK/Remote |"
BAE Systems,,1738022400000,"Data Driven Solutions

...and/or Big Data approaches to deliver data-driven solutions

Programming Languages

Coding in one or more relevant programming languages, e.g. SQL, Python, Scala etc...

Data Storage Solutions

Having an understanding of one or more relevant data storage solutions, e.g. Oracle, SQL Server, PostgreSQL, MySQL, Elastic,...",,,False,,,fulltime,https://functional.works-hub.com/jobs/data-engineer-d79?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer in London - BAE Systems
Allianz UK,,1738022400000,"Location: Guildford/hybrid (at least 1 day per week in the office)

Salary: c£50,000 dep on exp + bonus + benefits

Datalab is a small and fast-moving team of data scientists and engineers; delivering advanced analytics, geospatial and machine learning-powered data products to the Allianz Commercial business. As one of the largest general insurers in the UK we have unparalleled access to data. Whilst we have our fair share of legacy IT, we are rapidly transforming and modernising our data stack, in particular building in the public cloud (Azure). We create meaningful business value, using the latest data tools and methods, our vast pools of data, combined with deep industry expertise. s

65328 | Data & Analytics | Professional | Allianz UK | Full-Time | Permanent

We’re looking for individuals who have an appetite to learn, innovate and collaborate on dynamic and challenging initiatives as part of a specialised and close-knit team. If you enjoy developing data engineering solutions and have a passion for the geospatial domain, please read on!

Today, the Geospatial squad provide services that enable the business to visualise and manage insured locations, assess peril and accumulation risk, analyse and engineer predictive features, respond to weather events, quantify catastrophe scenarios, and streamline business operations. The team is progressing an ambitious agenda to modernise our core products and infrastructure, and establish new and enhanced analytical capabilities.

Key responsibilities

Working as part of an innovative datalab team, under the direction of the Head of Data Science, you day-to-day work on strategic location data projects and development of enhanced geospatial capabilities will comprise a wide range of activities, including:
• Leveraging data analytics and spatial methods in Python and related programming tools to generate and deliver enhanced geospatial insight at scale;
• Establishing coherent database infrastructures and applying DevOps practices to build and deploy modular geospatial services – notably web applications and APIs – to the cloud;
• Developing and automating scalable geospatial analytics workflows and data pipelines;
• Understanding Allianz’s cloud infrastructure, and staying up-to-date with emerging trends, tools, and technologies in the fields of geospatial data and engineering to recommend potential enhancements to infrastructure, data, and processes;
• Documenting and communicating engineering processes, best practices, and guidelines to facilitate knowledge-sharing and ensure the reproducibility and ongoing refinement of workflows;
• Engaging with the wider Allianz Data team and Group peers to explore and understand new spatial data, methods, tooling and infrastructure;
• Applying agile ways of working as part of a highly dynamic and motivated team - driving successful collaboration, solution development and engagement with core business customers.

You will have an incredible opportunity to hone your skills and will be able to make a significant contribution to driving technical excellence in respect of geospatial data and analytics at Allianz.

Join us and work alongside data scientists, geospatial experts and other data specialists in developing, deploying and running data products that deliver tangible insight to the business to help understand, quantify and manage geographic risk.

About you

Required
• A passion for geospatial data & data engineering, and strong appetite for continuous learning;
• Great inter-personal skills, a highly collaborative team player and a self-starter;
• A degree in a technical subject (e.g. Computer Science, Software Engineering, Data Science, Physics). We will also consider equivalent experience;
• Programming experience, ideally in Python;
• Experience working with spatial data and databases;
• Experience working with container-based app deployments and in cloud environments;
• Understanding of CICD practices;
• Knowledge of statistical concepts and data science methodologies useful but not essential;
• Knowledge of insurance useful but not essential.

Tools and technology we use

Here are some of the technologies we work with. We don’t expect you to be familiar with them all, and will provide opportunity and support to learn those that become most relevant to your role. This is not a mandatory checklist, but represents different topics relevant to our work. We are looking for candidates who have experience in some of these areas and, most importantly, a desire to learn more of them.
• Python libraries for spatial analysis and mapping (e.g. geopandas, folium, rasterio, gdal)
• Relational databases and spatial databases (e.g. postgres / postgis)
• GIS tools and web mapping environments (e.g. QGIS)
• Container orchestration (e.g. Docker, Kubernetes, Helm)
• Cloud computing & analytics (e.g. Azure Synapse Analytics, Azure ML)
• Big data processing (e.g. Apache Spark, Apache Sedona, Dask, Dask geopandas)
• Graph databases (e.g. Neo4j)
• Rapid prototyping tools and web app development (e.g. Streamlit, Dash, FastAPI, Flask, Django)
• API concepts and technologies (e.g. REST, GraphQL, Apigee)
• DevOps: Github, CI/CD, test automation, monitoring and alerting

What we will offer you

Recognised and rewarded for a job well done, we have a range of flexible benefits for you to choose from- so you can pick a package that’s perfect for you. We also offer flexible working options, global career opportunities across the wider Allianz Group, and fantastic career development and training. That’s on top of enjoying all the benefits you’d expect from the world’s number one insurance brand, including:
• Annual bonus scheme
• 25 days holiday plus bank holidays
• Contributory pension scheme
• Life cover
• Group Income Protection
• Flexible buy/sell holiday options
• Flexible working arrangements
• A discount up to 50% on a range of insurance products including car, home and pet
• Retail discounts

Our ways of working

Do you need some flexibility with the hours you work? Let us know as part of your application and if it’s right for our customers, our business and for you, then we’ll do everything we can to make it happen.

Here at Allianz, we are signatories of the ABIs flexible working charter. We believe in supporting hybrid work patterns, which balance the needs of our customers, with your personal circumstances and our business requirements. Our aim with this is to help innovation, creativity, and you to thrive - Your work life balance is important to us.

Our Purpose and Values

We secure your future

Be Brave | With Heart | Everyone Counts | Inspiring Trust

Our purpose and values are more than just words on a website - they are the why and how of Allianz. They influence everything we do and guide us how to do it. Created by our people, for our people, they shape our culture, bring us together, and inspire us to be the best. Building an inclusive culture for us all to succeed.

Diversity & Inclusion

At Allianz, we value diversity and inclusion and back this up with our accreditations. Allianz is EDGE certified for gender inclusion, members of the Women in Finance Charter, members of the Stonewall Diversity Champion programme, signatories of Business in the Community’s Race at Work Charter, and an Armed Forces Covenant gold standard employer.

We have a range of employee networks focusing on gender inclusion, cultural diversity, LGBTQIA+, disability and long term health conditions (including neurodiversity), intergenerational and life stages, parents and carers, mental wellbeing, menopause support and armed forces and veterans, all supporting you to bring your best and authentic self to work.

Accessible Application for All

As part of the Disability Confident Scheme, we support candidates with disabilities or long-term health conditions through the Offer an Interview Scheme, for those meeting the essential skills for the role.

Contact our Resourcing team to opt into this scheme or for assistance with your application, including larger text, hard copies, or spoken applications.

Hr-recruitment@allianz.co.uk

resourcingteam@allianz.co.uk

Join us - Let’s Care for Tomorrow

Job Level:
Professional

Location:
Guildford, ENG, GB, GU1 1DB

Area of Expertise:
Data & Analytics

Unit:
Allianz UK

Employing Entity:
Allianz Management Services Ltd

Job Type:
Full-Time

Remote Job:
Hybrid working

Employment Type:
Permanent

ID:
65328

Position Cluster:
Non-Executive","Hr-recruitment@allianz.co.uk, resourcingteam@allianz.co.uk",,True,,,fulltime,"https://www.glassdoor.co.uk/job-listing/geospatial-data-engineer-allianz-uk-JV_IC3294630_KO0,24_KE25,35.htm?jl=1009614937121&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",,,Guildford,,,Geospatial Data Engineer
IBM,,1738022400000,"Introduction

In this role, you’ll work in one of our IBM Consulting Client Innovation Centres (Delivery Centres), where we deliver deep technical and industry expertise to a wide range of public and private sector clients around the world. Our delivery centers offer our clients locally based skills and technical expertise to drive innovation and adoption of new technology.

A career in IBM CIC is rooted by long-term relationships and close collaboration with clients across the globe.

You’ll work with visionaries across multiple industries to improve the hybrid cloud and AI journey for the most innovative and valuable companies in the world. Your ability to accelerate impact and make meaningful change for your clients is enabled by our strategic partner ecosystem and our robust technology platforms across the IBM portfolio; including Software and Red Hat.

Curiosity and a constant quest for knowledge serve as the foundation to success in IBM Consulting. In your role, you’ll be encouraged to challenge the norm, investigate ideas outside of your role, and come up with creative solutions resulting in ground breaking impact for a wide network of clients. Our culture of evolution and empathy centers on long-term career growth and development opportunities in an environment that embraces your unique skills and experience.

Your Role and Responsibilities

A career in IBM CIC means you’ll be part of a team that transforms our customer’s challenges into solutions.

Seeking new possibilities and always staying curious, we are a team dedicated to creating the world’s leading AI-powered, cloud-native software solutions for our customers. Our renowned legacy creates endless global opportunities for our IBMers, so the door is always open for those who want to grow their career.

IBM’s product and technology landscape includes Research, Software, and Infrastructure. Entering this domain positions you at the heart of IBM, where growth and innovation thrive

The Data Engineer role requires a highly analytical individual proficient in Python programming, database management, and data methodologies. You’ll focus on extracting insights from data, developing and implementing machine learning models, managing big data infrastructure, and supporting AI-driven product development.

Key Responsibilities
• Data Collection and Cleansing: Collect and cleanse data from diverse sources to ensure high-quality datasets for decision-making.
• Data Exploration and Visualization: Explore and visualize data using advanced techniques to uncover insights and trends.
• Statistical Analysis: Apply statistical and mathematical techniques to provide robust analytical foundations for predictive modeling.
• Machine Learning and Deep Learning: Develop and implement machine learning and deep learning models to address business challenges.
• ML-Ops / AI-Ops: Demonstrate expertise in ML-Ops / AI-Ops practices to ensure efficient model deployment and management.
• Big Data Management: Manage big data infrastructure and execute data engineering tasks for efficient data processing.
• Version Control and Collaboration: Utilize version control systems like Git for maintaining codebase integrity and fostering collaboration.
• AI-Driven Product Development: Design, create, and support AI-driven products to deliver impactful solutions aligned with user needs and business objectives.

Required Technical and Professional Expertise
• Develops applications on Big Data technologies including API development.
• Expected to have traditional Application Development background along with knowledge of Analytics libraries, open-source Natural Language Processing, statistical and big data computing libraries.
• Strong technical abilities to understand, design, write and debug complex code

As an equal opportunities’ employer, we welcome applications from individuals of all backgrounds. However, for you to be eligible for this role, you must have the valid right to work in the UK. Unfortunately, we do not offer visa sponsorship and have no future plans to do so. You must be a resident in the UK and have been living continuously in the UK for the last 5/10 years. You must be able to hold or gain a UK government security clearance.

Preferred Technical And Professional Expertise
• AWS (Lambda S3 DynamoDB etc)
• Cloudformation
• JavaScript
• Cypress testing
• Openshift containers",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-at-ibm-4136615402?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Hursley,,,Data Engineer
Tenth Revolution Group,,1738022400000,"Snowflake Data Engineer - London - £115,000 plus bonus

I am looking for a Snowflake Data Engineer to join an financial services company to deliver on a variety of data driven projects. The business is looking for someone to add a level of expertise to their team of Data E...",,,False,,,fulltime,https://uk.jooble.org/rjdp/8189642230171914182?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Financial data engineer
Tenth Revolution Group,,1738022400000,"Senior Data Engineer - Snowflake - £85,000 (+10% Bonus) - London - Hybrid Company Overview: My client is a global leader in the insurance industry, serving millions of customers worldwide. With strong financial foundations established over decades, their commitment to utilising innovative solutions and cutting-edge technologies is a key pillar of their recent success. They are also dedicated to ensuring the well-being and happiness of their employees through very flexible hybrid working patterns, as well as other amazing benefits, and a great company culture - over 4 out of 5 employees would recommend working here. Role Overview: As a Senior Data Engineer you'll be responsible for building and deploying full solutions from scratch, while maintaining security and data best practices. Duties will include product-based work as well as migration tasks. Due to your seniority you will also be tasked with mentoring junior engineers. You will be joining a close-knit team of 6 Data Engineers, as well as 30 Engineers in the businesses data arm. Requirements: 3+ Years data engineering experience Snowflake experience Proficiency across an AWS tech stack DevOps experience building and deploying using Terraform Nice to Have: DBT Data Modelling Data Vault Apache Airflow Benefits: Up to 10% Bonus Up to 14% Pensions Contribution 29 Days Annual Leave + Bank Holidays Free Company Shares Interviews ongoing don't miss your chance to secure a role working with cutting edge technology while maintaining exceptional work-life balance. Contact me @ (url removed) or on (phone number removed). Data Engineer, Snowflake, Cloud, ETL, Analytics, SQL, Python, AWS, Terraform, DevOps, end-to,end",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/tenth-revolution-group/senior-data-engineer-snowflake-85000-london-hybrid-833822/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,"Senior Data Engineer – Snowflake – £85,000 – London – Hybrid"
Sanderson Recruitment Plc,,1738022400000,"Platform/Data Engineer - Snowflake

Rate - £650 - Inside IR35 (total to umbrella)

Duration - 6 months initial

Location - London/Norwich (50% on site)

A client of ours within the Financial Services sector is looking for a Snowflake SME/Data Engineer to join a Oracle Cloud migration to Snowflake and to complete some BAU work.

Desired skills
• SME Snowflake knowledge end to end understanding - Setting up (roles, access), RBAC management, performance optimisation, account management (database) - access management, network security management.
• Snowflake skills from an operational standpoint
• Terraform/infrastructure as code - CI/CD management
• Python, SQL, DBT Admin
• Azure (ADU)
• Migration - experience migrating into Snowflake.
• Stakeholder management - Across teams, 3rd parties (Translation tech to business talk)

Apply on the link attached for more information",,,False,,,fulltime,"https://www.jobserve.com/gb/en/search-jobs-in-London,-London,-United-Kingdom/PLATFORM-DATA-ENGINEER-SNOWFLAKE-30C0DD0D403729F71C/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",,,London,,,Platform/Data Engineer - Snowflake
Next,,1738022400000,"Job Description

While you'll have heard our name, there's a lot you probably don't know about NEXT. Like how we create most of our systems ourselves - whether it's a website, mobile app or application. What's more, we're growing. Fast. And it's the kind of growth and investment that is exciting for everyone in our business.

This is an excellent opportunity to join a rapidly expanding Business Intelligence Systems team working with a great mix of experience both inside Next and across the industry. BIS is transforming from a traditional SQL team to a modern hybrid cloud platform bringing together the best data, analytical and reporting tools to deliver new and enhance existing products and support our users.

About the team

Business Intelligence works with Finance, Product, Warehouse, Marketing, the Brand teams, almost everyone to design and build the data solutions that NEXT relies on to measure, report and analyse the performance of the business and its operations. We are SQL at heart but embracing new tech to modernise the platform and really are leading the charge toward platform modernisation.

This position is within the BIS Product Workstream, where our primary responsibility is to complete projects to support Retail and Product Operations.Our focus lies in technologies such as Azure, Databricks, Power BI, and ADF. We actively explore and adopt new technologies to innovate and enhance our processes.We are a growing team of 80+ developers, analysts and product managers responsible for providing the business with data solutions.

About the role

In this role you will be working in a product team developing solutions to help fulfil the business' needs, which can include providing new data for them to access that we obtain from a variety of sources or enhancing the way we work to deliver better results.

BIS supports over 70 BI products today and we are always building more. We work with the business / product owners to define the product development roadmap eventually decommissioning old solutions and replacing them with newer more performant and scalable solutions that will meet the growing needs of the business for years to come.

While our legacy platform is SQL which will play a huge part in our product base for years to come, we are also rapidly expanding our modern data platform so we are seeking developers who have experience in tools such as DataBricks (Spark), Data Factory, Data Lake, PowerBI and Synapse.

We are looking for people who want to learn new skills, get hands-on experience with the latest technologies and become very knowledgeable of BIS systems. Successful candidates will join a great team with a real mix of experience, knowledge and skills. There are great opportunities to learn and a real potential to advance your career.

Criteria

Essential
• DataBricks or similar and Azure Data Factory
• Languages: SQL, Python
• Data Platform: Azure data lake and SQL Server RDBMS
• ETL: SQL Server Integration Services and ADF
• Able to speak, read and write English at a level that enables you to complete your role, for example, to understand instructions and communicate effectively with stakeholders and/or other team members
• Experienced in effectively working in a collaborative manner in a large scale, fast paced environment within a multifunctional technical team

Desirable
• Languages: PySQL, C#, R
• Reporting: PowerBI or similar
• Modelling: SQL Server SSAS Tabular (DAX) / Dimensional Modelling / Data Warehousing
• Development Management: Azure DevOps
• SQL MI / DB
• ETL: Active Batch, API, Event Hub, Kafka
• AI / ML

#LI-LE1 #LI-Hybrid

About Us

You know Next, but did you know we're a FTSE-100 retail company employing over 35,000 people across the UK and Ireland. We're the UK's 2nd largest fashion retailer and for Kidswear we're the market leader. At the last count we have over 500 stores, plus the Next Online and it's now possible to buy on-line from over 70 countries around the world! So we've gone global!

About the Team
• 25% off most NEXT, MADE*, Lipsy*, Gap* and Victoria's Secret* products (*when purchased through NEXT)
• Company performance based bonus
• Sharesave scheme
• On-site Nursery available; OFSTED outstanding in all areas
• 10% off most partner brands & up to 15% off Branded Beauty
• Early VIP access to sale stock
• Access to fantastic discounts at our Staff Shops
• Restaurants with great food at amazing prices
• Access a digital GP and other free health and wellbeing services
• Free on-site parking
• Financial Wellbeing - Save, track and enhance your financial wellbeing
• Apprenticeship - Grow and develop on the job whilst gaining a qualification
• Direct to Work - Discount online and instore, collect your items the next day for free from your place of work or local store
• Support Networks - Access to Network Groups to empower and celebrate each other
• Wellhub - Discounted flexible monthly gym memberships, with apps, PT sessions and more

Conditions apply to all benefits. These benefits are discretionary and subject to change.

We aim to support all candidates during the application process and are happy to provide workplace adjustments when necessary. Should you need support with your application due to a disability or long-term condition, feel free to get in touch with us by email headoffice_careers@next.co.uk (please include 'Workplace Adjustments' in the subject line), or call us on 0116 284 2486 and leave a voicemail.",headoffice_careers@next.co.uk,,False,,,fulltime,https://www.breakroom.cc/en-gb/jobs/listing/72993775-next-developer-senior-lead-data-engineer-business?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Enderby,,,Developer / Data Engineer - Business Intelligence Systems
Experis UK,,1737936000000,"CDTI Data Engineer - Pre-Digital

Eligible for SC - 5 years residency, with no more than 6 months outside UK

Hybrid Working - Remote / Telford

£450 - £470 per day - Umbrella

Would you like to join a global leader in consulting, technology services and digital transformation?

Our client is at the forefront of innovation to address the entire breadth of opportunities in the evolving world of cloud, digital and platforms.

Role purpose / skills
• In this crucial role, you'll be focused on the complexities of Corporate Data Transformation and Integration(CDTI) across the client's estate and investigating and fixing Live issues, a solid background in Linux/UNIX shell scripting and PL/SQL scripting, and SQL database knowledge would be ideal, with knowledge of Cloud technologies also.
• Motivated, collaborative and determined, you'll need to validate new versions of our scripts, also making use of SQL Loader, Maestro/IBM Workload Scheduler batch jobs, and ensuring all changes are fully controlled in GitLab.
• With a collaborative ethos, you'll work with Architects looking at the wider picture to consider the risks and consequences of changes.

The CDTI Team is looking for a Data Engineer to work with a team of 4 other engineers to support and maintain the complexities of Corporate Data Transformation and Integration across the estate and investigate and fix live issues.

As technology advances, we need to validate new versions of our scripts, making use of SQL Loader, Maestro/IBM Workload Scheduler batch jobs, and ensuring all changes are fully controlled in GitLab so that we can quickly respond to Service requests to provide more efficient solutions. We often work with Architects looking at the wider picture to consider the risks and consequences of changes.

Collaboration / Innovation
• As a vital part of our business unit, you'll contribute to first-class end-to-end solutions in your assignments. You will play an active role in defining our practices, standards and ways of working, and apply them to your role. Be open to working across organisation and team boundaries to ensure we bring the best to our customers.
• The Corporate Data Transformation and Integration handles data from critical head of duty systems across the client's estate.
• The service is currently subject modernisation being moved to cloud infrastructure, so this is an exciting time to join the team.
• Work is varied between Project work such as moving services to new infrastructure along with the accompanying scripts or maintaining/troubleshooting existing scripts for services when issues/changes arise.
• Due to the criticality of corporate data transformation and integration across the estate this is fast paced area of expertise, collaborating across technology landscapes, management levels and organisational boundaries.
• On the job / external training will be available for the right candidate as well as the opportunity for overtime and on-call.
• The team are predominantly Telford based and we have team days each week in the office to meet the Capgemini Hybrid Working standards.

Essentials:
• A solid background in Linux/Unix
• PL/SQL Scripting experience
• SQL Database knowledge

Nice to have:
• Knowledge of Amazon Web Services (AWS)
• Knowledge of IBM Workload Scheduler
• Knowledge of GitLab
• Development Experience
• Knowledge of Atlassian tooling (for example Jira, confluence, Bitbucket/Bamboo)

All profiles will be reviewed against the required skills and experience. Due to the high number of applications we will only be able to respond to successful applicants in the first instance. We thank you for your interest and the time taken to apply!",,,True,,,fulltime,https://www.experis.co.uk/job/data-engineer-pre-digital?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Telford,,,Data Engineer - Pre-Digital
Sanderson Plc,,1737936000000,"Senior Data Engineer – Matillion / Snowflake

Rate – Circa £600 Inside IR35

Duration – 6 months

Location – Gloucester twice a week

Financial Services client is looking for a Senior Data Engineer proficient in Matillion and Snowflake to join a historic service review project. Your role will entail designing pipelines, delivering solutions and reporting.

Skills
• Snowflake
• Matillion
• SQL
• DevOps / software development lifecycle

Single stage interview process",,,False,,,fulltime,https://www.sandersonplc.com/job/senior-data-engineer-matillion-and-snowflake-msda_1737994411/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Bristol,,,Senior Data Engineer - Matillion and Snowflake
Buzz Group,,1737936000000,"Data Engineer - Hybrid / Nottingham

Full-time, Permanent | Remote

Salary: £50,000.00 to £60,000.00 per Annum

We are currently seeking a highly skilled Data Engineer to join our team on a Hybrid basis with occassional requirement to visit our head office in Nottingham. As a Data Engineer, you will play a pivotal role in our company's success by developing, testing, and maintaining our data infrastructure and systems. You will work closely with our product managers, software developers, data analysts, and other stakeholders to ensure efficient data flow across multiple systems that meet our Customers' requirements and expectations.

Your tasks and responsibilities

Data Pipeline Development: Design, build, and maintain scalable ETL (Extract, Transform, Load) processes to facilitate data ingestion and transformation from various sources.
Data Modeling: Create and maintain data models that support analytics and reporting needs. Ensure data integrity and consistency across various data systems.
Database Management: Administer and optimize relational and NoSQL databases to ensure efficient storage, retrieval, and processing of large datasets.
Collaboration: Work closely with data scientists and analysts to understand their data needs and provide solutions that enable efficient data analysis.
Data Quality Assurance: Implement data quality checks and monitoring processes to ensure the accuracy and reliability of data.
Documentation: Maintain comprehensive documentation of data systems, pipelines, and processes to support knowledge sharing within the team.
Performance Tuning: Analyse and optimize existing data workflows for performance improvements and cost efficiency.
Stay Current: Keep up-to-date with industry trends and emerging technologies to continuously enhance our data engineering practices

Bachelor’s degree in Computer Science, Engineering, Information Technology, or a related field; Master’s degree is a plus.
Proven experience as a Data Engineer or in a similar role, with a strong understanding of data warehousing and data modeling principles.
Proficiency in programming languages such as C#, Python, Java, or Scala.
Experience with ETL tools (e.g., Apache NiFi, Talend, or equivalent) and data pipeline orchestration tools (e.g., Apache Airflow).
Strong knowledge of SQL and experience with relational databases (e.g., MSSQL, PostgreSQL, MySQL) as well as NoSQL databases (e.g., MongoDB, Cassandra).
Experience with building and maintaining SSIS packages, SSAS, Azure Data Factory.
Familiarity with cloud platforms (e.g., AWS, Azure, Google Cloud) and data services (e.g., Redshift, BigQuery, Snowflake).
Understanding of data security best practices and experience implementing security measures.
Excellent problem-solving skills and the ability to work collaboratively in a team environment.
Knowledge and experience of working with data visualisation tools (e.g., Tableau, Power BI) and experience working with business intelligence teams to create and modify business reports.
Experience with CI/CD pipelines and version control (e.g., Git).
Familiarity with data governance and GDPR compliance.
Motivated and enthusiastic individual with a positive ‘can do’ attitude.
Ability to thrive in a fast-paced, dynamic environment and manage multiple priorities effectively.
Hold a full clean driving license as travel between group sites will be required.
Experience working in retail/hospitality and gaming/gambling sectors is a plus.

Hit the Jackpot with Our Benefits

In return for everything you bring, we offer an exciting role in a dynamic business and a great rewards package. We’ll help you build your skills and career as you work with us in a business that never stands still. So, in addition to the salary range of £50,000.00 to £60,000.00 per Annum, we offer a comprehensive benefits package, including:

Help@Hand – a physical and mental wellbeing app for you and your family giving you fast remote access to a GP for advice and more
Thrive App – for your mental wellbeing approved by the NHS
My Eva – an online financial expert to help with any money-related matters
Buzz Brights Apprenticeships at management level
Buzz Learning, our digital learning platform with access to 100s of online courses
Access to Trained Mental Health Advocates for advice on your mental wellbeing
Staff discount 50% off bingo tickets, food & soft drinks
Refer a Friend Scheme
Pension Scheme

#BB1",,,True,,,fulltime,https://findajob.dwp.gov.uk/details/15953743?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Nottingham,,,Data Engineer
Direct Line Group,,1737936000000,"Analytics Engineer
Leeds - Hybrid (2 days a week in the office)
Full Time, Permanent Position

Let’s make the most of your talent

Join us as an Analytics Engineer, where you'll drive business success and make an impact on our journey towards data-driven excellence.

About us

At Direct Line Group, insurance is just the start. Combining decades of industry experience with talented people in every field from data, technology, customer care and auto repair, to HR, finance, and procurement, we’re a customer-obsessed market powerhouse. And we all work together to be brilliant for customers, every single day.

It always feels good, helping people when they need it most. Taking calls, helping customers with queries, finding the right insurance product for their lifestyle. Helping to keep people safe on the roadside when their vehicle breaks down. Being a reassuring presence when someone needs to make a claim. Our contact centre teams give customers all kinds of support. It can get busy, but the culture, training and friendly teams are great here.

What you'll be doing

In 2023, DLG spent c.£2.4 billion on claims. This important role is accountable for the development and presentation of data that will help us understand, interpret and analyse this ongoing spend – the frequency of claims, the types of claims and the severity of claims. You will need to be well-versed in data methodologies, but it’s also about being able to provide and present data in a manner that can be used to drive business performance. Other duties include:
• Develop, enhance, document and maintain processes that cleanse and transform large volumes of complex data for use in analytical workflows following best practice and development standards
• Design and build data products that enable analysts and business teams to drive commercial value
• Analyse existing code and processes and make suggestions for improvement
• Perform unit testing, system testing and UAT
• Provide technical support to analysts within the team and other areas of DLG
• Liaise and collaborate with colleagues to understand and translate requirements into data products
• Provide expertise, data and analytics to successfully deliver on projects, both within Claims and the wider business
• Use your experience to help us be innovative, dynamic and continuously curious
• Focus on costs, process improvements and efficiencies to contribute to the profitability of Direct Line Group

What we're looking for
• Technical expertise in data cleansing, transformation and manipulation, with experience in delivering reliable, robust data products
• The ability to gain an understanding of internal and external data sources, to gather and understand requirements and to use that knowledge and understanding to build data sets, data models and reports
• Excellent level of knowledge and experience of SQL
• The ability to investigate problems and make recommendations for business improvements
• An innovative mindset and the ability to challenge ways of working to generate new insights and ways of doing things
• Programming experience in any language (e.g. SAS, Python, R)
• A good understanding of data architecture and management together with coding and development methodologies
• Exposure to reporting services and visualisation tools (e.g. Tableau, Qlik Sense, Alteryx or Power BI)
• An understanding of cloud-based platforms is beneficial (e.g. AWS, Azure, GCP)
• A proficient user of Microsoft applications

What we offer in return
We wouldn’t be where we are today without our people and the wide variety of perspectives and life experiences they bring. That’s why we offer excellent benefits to suit your lifestyle and a flexible working model combining the best parts of home and office-working, varying with the nature of your role. Core benefits include:
• Generous 9% employer pension contribution
• Annual company bonus of up to 10%
• 25 days holiday allowance (plus the option to buy or sell up to 5 days each year)
• 50% off home, motor and pet insurance
• Free travel insurance and Green Flag breakdown cover
• Additional optional Health and Dental insurance
• Plus, many more

Ways of Working
Our hybrid model way of working offers a 'best of both worlds' approach combining the best parts of home and office-working, offering flexibility for everyone. When you'll be in the office depends on your role, but most colleagues are in 2 days a week, and we'll consider the flexible working options that work best for you.

Read our flexible working approach here

Difference makes us who we are. We believe everyone should feel comfortable to bring their whole selves to work – that’s why we champion diverse voices, build workplaces that work for people, and invest in the things that matter. From senior leadership to inclusivity networks, adaptive working to inclusion training, we’ve made it our mission to give you everything you need to be authentically you. Discover more at directlinegroupcareers.com

Together, we're one of a kind

Salary Range: £30,000 to £50,000

Hours: 35 hours (Monday to Friday - shift patterns can be discussed)

Closing Date: Monday 10 February

#LI-Hybrid

#LI-CL2",,,False,,,fulltime,https://www.directlinegroupcareers.com/job/leeds/analytics-engineer/38736/76582737552?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Leeds,,,Analytics Engineer
Legal And General Group,,1737936000000,"Company Description

Legal & General looks after around 700,000 institutional customers who have their retirement benefits secured with us. Operating continuously in the UK market from our entrance in 1987, we are the UK’s longest-running insurer.

Our Institutional Retirement division provides pension risk transfer (PRT) solutions for UK and US defined benefit (DB) schemes, and reinsurance solutions from our global hub in Bermuda. We work with companies, DB pension schemes and their advisors to help them secure and protect scheme members’ retirement benefits.

Joining us means you’ll support customers’ financial security in retirement; help companies to settle their pension liabilities and focus on growing their businesses; and enable investment for the long term to back our pension promises.

Job Description

Are you ready to support the monitoring and evolution of modern data solutions? We are looking for a proactive Junior Support Data Engineer to join our innovative Data Ops team. This role is key to ensuring the reliability and performance of our data estate through effective monitoring and issue resolution.

As an essential member of the team, you will collaborate closely with cross-functional teams, including data engineering, data delivery, and governance, to ensure the reliability and performance of our data solutions. You will execute processes and controls in line with the data strategy and contribute to its continuous improvement.

What you'll be doing:

• Monitoring the productionised data solutions and notifying the Support Lead of any issues or failures

• Ensuring all issues are documented for analysis

• Contributing to the Support function’s backlog management and prioritisation

• Communicating issues affecting availability or accuracy to internal customers and external partners

• Engaging with technology providers to escalate specialised issues

• Contributing to the Support documentation and adhering to agreed standards

• Using modern ETL techniques and tools to implement data solutions as needed

• Participating in migration and test activities involving non-core hours

Qualifications

Who we're looking for:

• Background in incident/problem management in a data-driven environment

• Strong communication skills and passion for customer support

• Previous exposure to Agile environments (Scrum/Waterfall)

• Willingness to learn aspects of ELT/ETL, metadata management, and data integration

• Willingness to learn SQL, PowerShell, and Kimball database techniques

• Experience with tools and platforms like Wherescape RED & 3D, Snowflake, Postgres, SQL Server, Pebble, Salesforce, Qlik Replicate, Power BI, and Service Desk tools like ServiceNow

• Strong problem-solving skills and attention to detail

• Ability to work collaboratively in a team environment

Whatever your role, we reward performance and behaviour with a package that looks after all the things that are important to you. Here are some of the benefits we offer:
• The opportunity to participate in our annual, performance-related bonus plan and valuable share schemes
• Generous pension contribution
• Life assurance
• Private medical insurance (permanent employees only)
• At least 25 days holiday, plus public holidays, 26 days after 2 years’ service. There’s also the option to buy and sell holiday
• Competitive family leave
• Participate in our electric car scheme, which offers employees the option to hire a brand-new electric car through tax efficient salary sacrifice
• There are the many discounts we offer – both for our own products and at a range of high street stores and online
• In 2023, some of our workspaces were redesigned. Our offices are great spaces to connect and collaborate and have your wellbeing at the heart

Additional Information

Legal & General is a leading financial services group and major global investor, named Britain’s Most Admired Company in 2023, for the second year running. Rated top in our sector and top for inspirational leadership, we have a strong heritage and an exciting future.

We aim to build a better society for the long term by investing our customers’ money in things that make life better for everyone.

If you join us, you’ll be part of a welcoming culture, with opportunities to collaborate with people of diverse backgrounds, views and experiences. Guided by leaders with integrity who care about your future and wellbeing. Empowered through initiatives which support people to develop their careers and excel.

We strive to be open, mindful and inclusive, so are always willing to discussing flexible working arrangements and reasonable accommodations for candidates with specific needs.

If you’re open to find out more, we'd love to hear from you.",,,False,,,fulltime,https://careers.legalandgeneral.com/job/support-engineer-in-cardiff-jid-3730?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Cardiff,,,Support Engineer
Opus Recruitment Solutions,,1737936000000,"Data Engineer | £60,000 - £65,000 | UK/Remote |

Power BI | Synapse | Azure Data Bricks | ADF | SQL | Data Engineer | Reporting | Data Sets | Fabric |

Are you a Data Engineer who enjoys getting involved with the architecture side of the role? Or maybe you want to join a company and have autonomy? If so I have a role for you.

I am looking for an experienced Data Engineer to join a company that support the automotive industry covering a range of aspects from theft prevention to fleet management. They have grown impressively over the last year and are now looking to invest in people.

They have recently gone through an Azure Migration and are looking for a Data Engineer to join a small team to architect data sets, push them into Power BI and move them export to data lake to fabric link.

They are using a great tech stack which includes – Azure ADF, Data Lakes, Synapse, Power BI, Fabric, Logic Apps, SQL.

You will also be working closely with BI and SQL Developers with building dashboards and reports which will be going out to various customers.

Benefits include –
• 5% company pension
• Remote working
• Salary up to £65,000
• Private healthcare
• Learning and Development budget
• Perkbox
• Life Assurance
• Wellbeing options

Even though this is a remote position you need to be a full time UK resident and sponsorship isn’t available.

This a brilliant opportunity for someone looking to grow their career. They have a fantastic tech stack and have brilliant progression routes.

Power BI | Synapse | Azure Data Bricks | ADF | SQL | Data Engineer | Reporting | Data Sets | Fabric |",,,True,,,fulltime,https://uk.jooble.org/jdp/7157274972493493985?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Leigh,,,"Data Engineer | £60,000 - £65,000 | UK/Remote |"
Accenture,,1737763200000,"Job Title: Data Engineer, Associate Manager CL8

Locations: London/Bristol/Manchester

Salary: Competitive salary and package (Depending on level of experience)

Please Note: Any offer of employment is subject to satisfactory BPSS and SC security clearance which requires 5 years continuous UK address history at the point of application.

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. With our thought leadership and culture of innovation, we apply industry expertise, diverse skill sets and next-generation technology to each business challenge.

We believe in inclusion and diversity and supporting the whole person. Our core values comprise of Stewardship, Best People, Client Value Creation, One Global Network, Respect for the Individual and Integrity. Year after year, Accenture is recognised worldwide not just for business performance but for inclusion and diversity too.

“Across the globe, one thing is universally true of the people of Accenture: We care deeply about what we do and the impact we have with our clients and with the communities in which we work and live. It is personal to all of us.” – Julie Sweet, Accenture CEO

Key responsibilities
• Implement ETL pipelines and orchestrate data flows using batch and streaming technologies based on software engineering best practice
• Define, document and iterate data mappings based on concepts and principles of data modelling
• Re-engineer data pipelines to be scalable, robust, automatable, and repeatable
• Navigate, explore and query large scale datasets
• Build processes supporting data transformation, data structures, metadata, dependency and workload management
• Identify and resolve data issues including data quality, data mapping, database and application issues
• Implement data flows to connect operational systems, data for analytics and business intelligence (BI) systems
• Deliver high quality implementation and documentation for critical functionality
• Deliver code, unit tests, feature tests, stubs and integration tests.
• Operate in an agile environment as part of a scrum team and participate in sprint rituals
• Work with team members to understand designs, functional requirements and triage issue

Qualifications

We have a number of opportunities available from junior to senior level and we are looking for data engineers who have a variety of different skills which include some of the below.
• Strong proficiency in at least one programming language (Python, Java, or Scala)
• Extensive experience with cloud platforms (AWS, GCP, or Azure)
• Experience with:
• Data warehousing and lake architectures
• ETL/ELT pipeline development
• SQL and NoSQL databases
• Distributed computing frameworks (Spark, Kinesis etc)
• Software development best practices including CI/CD, TDD and version control.
• Strong understanding of data modelling and system architecture
• Excellent problem-solving and analytical skills

Whilst having experience in a consultancy is beneficial, demonstrable experience in working with clients/external partners in other settings will always be considered.

What’s in it for you

At Accenture in addition to a competitive basic salary, you will also have an extensive benefits package which includes 25 days’ vacation per year, private medical insurance and 3 extra days leave per year for charitable work of your choice!

Flexibility and mobility are required to deliver this role as there will be requirements to spend time onsite with our clients and partners to enable delivery of the first-class services we are known for.

About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialised capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centres.

With 509,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity, or any other basis as protected by applicable law.

Closing Date for Applications 31st March 2025

Accenture reserves the right to close the role prior to this date should a suitable applicant be found.

About Accenture

Accenture is a leading global professional services company that helps the world’s leading organizations build their digital core, optimize their operations, accelerate revenue growth and enhance services—creating tangible value at speed and scale. We are a talent- and innovation-led company with 774,000 people serving clients in more than 120 countries. Technology is at the core of change today, and we are one of the world’s leaders in helping drive that change, with strong ecosystem relationships. We combine our strength in technology and leadership in cloud, data and AI with unmatched industry experience, functional expertise and global delivery capability. Our broad range of services, solutions and assets across Strategy & Consulting, Technology, Operations, Industry X and Song, together with our culture of shared success and commitment to creating 360° value, enable us to help our clients reinvent and build trusted, lasting relationships. We measure our success by the 360° value we create for our clients, each other, our shareholders, partners and communities.

Visit us at www.accenture.com

Equal Employment Opportunity Statement

All employment decisions shall be made without regard to age, race, creed, colour, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by applicable law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.",,,False,,,fulltime,https://hackajob.com/en-us/job/369b1f11-da5a-11ef-a04e-0a757bd4ac89-data-engineer-associate-manager-manchester?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Manchester,,,"Data Engineer, Associate Manager (Manchester)"
Data Science Jobs,,1737763200000,"x4Data Engineers – Fully Remote Opportunity with a Game-Changing HealthTech Startup!

Areti Group is thrilled to partner with a HealthTech powerhouse revolutionizing health and social care across the UK! With strategic hubs in Bristol, Dorset, Southampton, and Somerset, this is a unique opportunity to join an innovative company that’s reshaping the industry. This fully remote role offers flexibility, with all travel expenses covered for occasional visits to our client’s offices. We are looking for x4 exceptional Azure Data Engineersto join this high-impact team on a permanent basis—become a pivotal part of the digital transformation that’s driving real change!

Role Overview

As a Data Engineer specialising in Data Pipelining, you will play a pivotal role in designing, developing, and maintaining data movement pipelines using Azure Synapse to facilitate the smooth transfer of data across our internal systems. You will collaborate closely with our already well established team and process to ensure the timely and accurate movement of data to support various business operations and analytical initiatives.

Required Experience:
• Proven experience as a Data Engineer with a focus on using Azure Synapse or similar technologies.
• Strong proficiency in SQL and experience with data modelling concepts.
• Hands-on experience with Azure Synapse, including familiarity with Synapse SQL, Apache Spark pools, and data integration capabilities.
• Experience with ETL/ELT processes and tools such as Azure Data Factory.
• Solid understanding of cloud computing principles and experience with Azure services.
• Excellent analytical and problem-solving skills with a keen attention to detail.
• Strong communication and collaboration skills with the ability to work effectively in a cross-functional team environment.
• Experience with Agile development methodologies is a plus.
• Azure certifications related to data engineering or analytics are desirable.

What We Offer You:

Our client provides an environment where your well-being and growth are as important as your contributions. Enjoy a collaborative and supportive culture along with:
• Flexible, Fully Remote Working– Monthly on-site visits covered, with travel, food, and accommodation expenses included.
• Competitive Salary– Up to £70k based on experience.
• Generous Leave– 25 days paid leave + public holidays.
• Comprehensive Benefits:
• Private Medical Insurance
• Group Life Assurance ️
• Dental & Optical Coverage
• Enhanced Maternity Leave
• Financial Security– Pension Contributions
• Employee Assistance Programme
• Birthday Day Off
• Continuous Learning & Development Opportunities– Because your growth matters.

Ready to make an impact in HealthTech? Join a forward-thinking, supportive company that values innovation, teamwork, and excellence. This is your chance to be part of something extraordinary!",,,True,,,fulltime,https://datascience-jobs.co.uk/view-job/x4-data-engineers-fully-remote-opportunity-with-a-game-changing-healthtech-startup-064fb13a3148?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Leigh,,,x4 Data Engineers – Fully Remote Opportunity with a Game-Changing HealthTech Startup!
SR2 | Socially Responsible Recruitment | Certified B Corporation™,,1737763200000,"£80,000 - £100,000 | Lead Data Engineer | Full Time | Bristol | Azure/AWS/GCP | Databricks | Public Sector | Architecture

SR2 have partnered with a consultancy in based in the Brsitol who do a lot of work within the public sector. They have big plans across this year and are kicking these off with a Lead Data Engineer hire. I am looking for a Lead Level Data Engineer who has experience leading on Data Engineering projects on Azure/AWS/GCP projects. Some client site travel may be required depending on the project.
• No consultancy experience required*

Which of your skills will be used?
• Proven experience in a Leadership focused data engineering role.
• You must have hands on experience with AWS, GCP or Azure.
• Experience designing data architecture.
• Strong communication skills, with the ability to translate technical terminology to non-technical stakeholders.
• Strong Python skills for ETL development
• Databricks/Pyspark is highly desirable.
• Public sector experience is desirable.
• You must be SC clearable

Salary:

The salary on offer for this role is £80,000 - £100,000

What next?

There are interview spots booked across the next couple of weeks, so please contact Adam Townsend on 07478213563 or adam@sr2rec.co.uk to find out more information and to be considered.

£80,000 - £100,000 | Lead Data Engineer | Full Time | Bristol | Azure/AWS/GCP | Databricks | Public Sector | Architecture",adam@sr2rec.co.uk,,False,,,fulltime,https://uk.linkedin.com/jobs/view/lead-data-engineer-architect-at-sr2-socially-responsible-recruitment-certified-b-corporation%E2%84%A2-4132893862?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Bristol,,,Lead Data Engineer/Architect
Ventula Consulting,,1737763200000,"Leading eCommerce client are now searching for a Senior Data Engineer to play a pivotal role in delivering their new greenfield data platform.

This role will shape our client’s data function, delivering end to end data requirements and designing data pipelines/warehouses to ensure data is streamlined and enhances overall business success.

The role:
• Design, develop and test an array of data migration processes to streamline the conversation from existing system to a new Snowflake infrastructure.
• Manage the end-to-end data lifecycle, enabling the use of data to influence overall business decisions.
• Streamline our client’s data processes to ensure that customer journeys are personalised.
• Ensure the accuracy and reliability of data.
• Collaborate on business projects, advising on data and data structures.
• Assess the commercial potential of our client’s data and use this to influence decision-makers and business decisions.

Key Requirements:
• Extensive experience leading data strategies and database architecture decisions.
• Solid experience using AWS architecture to design cost effective and scalable cloud data solutions.
• Extensive experience with Python and DBT.
• Strong experience with Snowflake and Data Warehousing.
• Advanced SQL and Data Modelling skills.
• Strong experience developing data pipelines.
• Excellent communication skills with the ability to build and lead a multi-skilled team.

This role is offering a daily rate between £550-£650 per day Inside IR35 for an initial 9 months.

In terms of working structure, this is flexible with one day per week in our clients London office and the rest remote.",,,True,,,fulltime,https://uk.jooble.org/jdp/5533651059413031484?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Senior Data Engineer (AWS/Snowflake/dbt) - £650 Inside IR35 - London
Areti Group | B Corp™,,1737763200000,"Join Our Team of Data Engineers

We are seeking 4 exceptional Data Engineers to join our innovative team, which is reshaping the industry through a digital transformation driving real change.
Key Responsibilities:
• Proven experience as a Data Engineer.
• Proficiency in SQL with knowledge of data modelling concepts.
• Python skills.
Benefits and Perks:
• Flexible, fully remote working with occasional on-site visits covered, including travel, food, and accommodation expenses.
• Competitive salary up to £70k based on experience.
• Generous leave - 25 days paid leave + public holidays.
• Private medical insurance.
• Group life assurance.
• Dental & optical coverage.
• Enhanced maternity leave.
• Financial security - pension contributions.
• Employee assistance programme.
• Birthday day off.
• Continuous learning & development opportunities.
About Us:

Our company has strategic hubs in Bristol, Dorset, Southampton, and Somerset. We are committed to providing a supportive environment that allows our employees to grow and thrive.
What We Offer:

A competitive salary, generous benefits, and opportunities for growth and development make this a unique opportunity to join our team of Data Engineers.",,,True,,,fulltime,https://gb.bebee.com/job/8d670e734fdf8d40c44340586b7b4ea3?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Altrincham,,,Data Engineer
Insight Investment,,1737763200000,"Insight Investment is looking for an experienced Data Engineer to join our growing team building our strategic data platform as we look to adopt best-in-class data governance and democratize data around the business.
The successful candidate will play a pivotal role in shaping and executing our data strategy, leveraging our data assets to the full, elevating our decision-making, streamlining processes, and drive innovation within our organisation.

You will be part of the long-standing Data Platform team using Agile methods to deliver solutions on top of our cloud platform. Lead the design and implementation of a robust and scalable data platform using Azure Databricks and complementary tooling to meet the organisation's needs.
Contribute to and evolve the Insight Data Strategy, communicate outcomes at an executive through to team level Set the firm-wide standards and conventions for ingesting, governing, transforming, persisting, and democratising data.
Enable the adoption of advanced analytics & AI by configuring best-in-class tooling. Align technical designs with internal data, privacy, security and compliance policies.
Stay abreast of industry trends and emerging technologies related to Databricks and big data processing, recommending relevant advancements for consideration.

Stand by software engineering principles around quality and doing things the right way. Experience working in and with Agile teams performing iterative development.
Own mistakes and work with your colleagues to redress them, learn from them and make improvements for the long-term.

Insight is committed to being an inclusive employer and encourages applications from all suitably qualified applicants irrespective of background, circumstances, age, disability, gender identity, ethnicity, religion or belief, sexual orientation or other factors protected by federal, state and/or local laws. If you are a candidate with a disability, or are assisting a candidate with a disability, and require an accommodation to apply for one of our jobs, please email us at View email address on click.appcast.io Insight Investment Insight Investment is a leading asset manager focused on designing investment solutions to meet its clients' needs. Founded in 2002, Insight's collaborative approach has delivered both investment performance and growth in assets under management. Insight manages assets across its core liability-driven investment, risk management, full-spectrum fixed income, currency and absolute return capabilities.

Insight is a global network of operations in the UK, Ireland, Germany, US, Japan and Australia.",,,False,,,fulltime,https://uk.jooble.org/rjdp/-8176695184832712273?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Manchester,,,Senior Data Engineer : Big Data
Greggs,,1737763200000,"We have a fantastic opportunity to join the growing Data Platform team at Greggs as an Azure Data Platform Engineer. You will be part of the team responsible for ensuring high quality data is sourced and curated in our Azure cloud platform and to ensure that this is a foundation for growth for all data, analytic and AI services. This role will play a key part in our current next generation SAP project.

Your involvement will span the entire data lifecycle: from orchestrating data ingestion into our Azure Data Lake, designing and developing sophisticated data models for analytics, to deploying Azure Logic Apps and Function Apps for process automation. With tools like Databricks, Data Factory, Azure SQL Server, and Python you will help formulate a data driven platform and develop data pipelines that convert raw data into actionable insights in line with our strategy.

We can offer you:
• 25 days (5 weeks) annual leave, pro-rated, increasing with service (in addition to bank holidays), plus 1 additional floating day
• Management Bonus Scheme which is worth up to 10% of your salary
• Profit share: We want everyone to share in the success of the business, so we distribute 10% of our profits to all our employees who have at least 6-month service, or more, each year
• Private Medical Insurance which is free for you and subsidised for your dependants
• Permanent Health Insurance which is a replacement income scheme
• You will automatically join our Greggs pension scheme which is a fantastic way to save for your retirement and allows you to benefit from employer contributions and tax advantages
• Defined contribution management pension scheme
• Death in service benefit which provides a lump-sum payment equal to 4 times your year’s salary
• Colleague discount, up to 50% off our own-produced products
• Share save schemes that let you buy discounted Greggs shares, by saving a set amount of money over a fixed time, to have an even bigger share of our profits
• Career progression and learning and development
• Employee Assistance Programme; A free, confidential helpline, offering advice and support with financial, relationship, work-related and wellbeing issues, 24 hours a day, 365 days a year. Including a mobile app providing a range of wellness content on physical, mental, social, and financial wellbeing
• Perks and savings, such as digital gift card discounts, online cashback, in-store and online coupons and lifestyle offers
• Cycle to Work scheme
• A company who cares about our communities; the environment and being a better business! Click here to read about The Greggs Pledge
• Colleague Networks – internal groups where colleagues and their allies can share their own experiences, offer feedback on the way we do things at Greggs, and provide support to one another

About the role
• This is a full-time role, however flexibility in this will be considered
• We know that having a work-life balance is important, so we offer our colleagues as much flexibility as possible in line with the needs of their role
• The base location for this role is Newcastle Upon Tyne. Ideally, you'll live within one hour travel of this location

What you'll do
• Design and maintain robust ETL/ELT processes to integrate data from various sources into Azure data services
• Help to implement DataOps practices to streamline and automate the data lifecycle, ensuring faster delivery and higher quality of data products
• Design and manage CI/CD pipelines for data workflows to facilitate automated testing and deployment
• Ensure data quality, security, and compliance with industry standards and best practices
• Work closely with cross-functional teams, including data scientists, analysts, and business stakeholders, to understand and address their data needs
• Stay current with emerging trends and technologies in the Azure ecosystem, other technologies/methods, and data engineering, helping to drive continuous improvement within the team

About you

You will fit right into this role if you:
• Can demonstrate knowledge of cloud services, preferably the Databricks suite of products. Knowledge of Azure Data Lake, Azure Data Factory, Azure Logic Apps, Azure Function Apps would be advantageous
• Are able to work efficiently in a dynamic environment, with a focus on detail and accuracy and have a keenness to problem solve
• Hold a steadfast commitment to data security and ability to guide others in this area
• Are keen to understand the commercial drivers of the business and can build data solutions to drive growth

About Greggs

Here at Greggs, we love what we do, and we have fun! What makes Greggs so special is our culture – the way we are, the way we behave and the way we support each other. We're hard-working, but above all else we're family; and it doesn't matter who you are, where you're from or what your favourite bake is, we’d love you to join us! We want everyone to feel welcome at Greggs and our colleagues to be able to be themselves at work, whatever their background, preferences, or views.",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/azure-data-engineer-at-greggs-4132865854?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Newcastle upon Tyne,,,Azure Data Engineer
Tenth Revolution Group,,1737763200000,"Data Engineer (AWS) - Sunderland - Hybrid - £60k - £70k

This is a great opportunity for an experienced data engineer with expertise in AWS to join an established company with continual growth year on year who are able to provide stability, L&D, and progression. The Data Engineer position will be a key role within the Data department. This role will report directly into the Lead Data Engineer, and will help build my clients data capability.

55k - £65k (depending on experience)

10% performance related bonus

Hybrid working (2 days in office, 3 from home)

27 days annual leave

Company contributory pension schemeRole & Responsibilities

Designing, building, and maintaining data pipelines to facilitate building data models that provide useful data and insights to key business stakeholders, external stakeholders and regulators

Working with Data Analysts in delivering an efficient data model to be used for analytics and reporting

Collaborating with immediate team and wider teams to support data queries and requests

Working with key business stakeholders and analysts to gather data requirements

Defining and documenting key logical and physical data models

Experience managing and building relationships with internal and external stakeholders

Experience in Cloud Technologies (AWS prefered, Azure or GCP)

Experience in ETL, Orchestrator tools like Airflow, AWS Glue etc.

Understand the concepts and principles of data modelling.

Experience in modern data warehouse technologies like redshift, databricks etc

In depth SQL knowledge.

Some of the tools / technologies we use are Python, git, dbt, Docker, SQL Server, AWS

I have limited slots for 1st stage interviews next week so if you're interest, get in touch ASAP with a copy of your most up to date CV and email me at or call me on (phone number removed).

Please Note: This is a permanent role for UK residents only. Some of our roles may be subject to successful background checks including a DBS and Credit Check.

Nigel Frank are the go-to recruiter for Power BI and Azure Data Platform roles in the UK, offering more opportunities across the country than any other. We're the proud sponsor and supporter of SQLBits, Power Platform World Tour, the London Power BI User Group, Newcastle Power BI User Group and Newcastle Data Platform and Cloud User Group.",,,False,,,fulltime,https://uk.jooble.org/rjdp/432568990877531352?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Sunderland,,,Data Engineers required ASAP
Correla,,1737676800000,"Discipline: Standard

Job type: Permanent

Job ref: 008207

Published: 9 days ago

Correla are looking for a Data Engineer to work as part of the Data Engineering team.

Salary: £57,000

About Us

In March 2021, Correla was created, as an independently owned business to bring in private investment to fuel innovation in the centre of the energy market and beyond.

Correla is derived from correlation, because we’re all about exploring and enhancing relationships between data, people, and processes. Our SaaS products and Managed Service solutions combine to power industry innovation, simplify an increasingly complex market, and deliver cost and operational efficiencies.

Our goal is to support industry transformation, to move to a net-zero future and to positively impact the end-consumer.

About The Role
• Build and optimize scalable ETL/ELT pipelines using Azure Data Factory, Azure Databricks, and Apache Spark
• Create and maintain Azure Data Lake solutions (ADLS2)
• Implement data models leveraging the Kimball methodology
• Monitor, troubleshoot, and optimise data pipelines and systems for performance and cost efficiency
• Work closely with stakeholders, including Data Scientists, Analysts, and Product Managers, to gather requirements and translate them into scalable data engineering solutions.

About You
• You will have hands-on experience with Azure Data Factory, Azure Databricks, Apache Spark, Azure Data Lake (ADLS2), and Microsoft Fabric workloads.
• You will be proficient in Python, PySpark, and SQL
• You will have a solid understanding of dimensional modeling
• You will have knowledge of security, compliance, and best practices
• You will have strong analytical and debugging skills
• You will have strong written and verbal communication skills

What We Offer
• Locate for your day
• Uncapped annual leave
• 6-12% Pension Contribution
• Private Healthcare
• 26 weeks’ full pay equal parent leave
• Wellbeing Services
• And more!

At Correla, we are committed to working towards being a more diverse and inclusive workplace where our people can truly be themselves. We recognise the benefits of having talented people from a range of backgrounds and cultures who bring different perspectives, life experiences and diversity of thinking.

Our aim is to attract and retain the very best diverse talent to help create an exciting, innovative, and successful business that enables us to deliver an exceptional experience for our customers. We would therefore like to encourage applications from people with varied skillsets and experience and from different backgrounds and sectors to help shape our future.

Correla is an Equal Opportunities Employer. We believe in equality of opportunity regardless of race or racial group, ancestry, place of origin, ethnicity, sex, sexual orientation, gender identity, gender expression, gender re-assignment, age, record of offences, marital/civil partnership status, family status, pregnancy, maternity and paternity, religion/belief or disability.    We promise that your opportunity for employment with us depends solely on your qualifications and relevant experience.",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-at-correla-4132534266?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Solihull,,,Data Engineer
Stanford Black Limited,,1737676800000,"Our client, a leading technology-driven quantitative trading firm, is seeking a Senior Software Engineer to design, develop, and optimise high-performance systems. This role focuses on creating scalable, low-latency solutions for demanding real-time environments.

The Role

This is an opportunity to work on cutting-edge systems, collaborating with cross-functional teams to deliver robust and efficient solutions. The successful candidate will lead technical discussions, mentor team members, and contribute to the continuous evolution of the software architecture.

Key Responsibilities
• System Development : Develop and maintain modern C++ applications optimised for performance and scalability.
• Collaboration : Partner with hardware engineers, DevOps specialists, and other software engineers to deliver integrated solutions that meet business needs.
• Optimisation : Implement advanced profiling and performance tuning to achieve low-latency, high-throughput system performance.
• Leadership : Participate in architectural planning and guide the team toward technical excellence.
• Mentorship : Support and mentor junior team members in best practices and advanced techniques.

Your Profile
• C++ Expertise : Proven experience in modern C++ (C++11/14/17/20) development, particularly for Linux-based, performance-critical applications.
• Architecture Knowledge : Strong background in system architecture for real-time environments.
• Optimization Skills : Advanced understanding of low-latency techniques, debugging, and performance analysis tools.
• Collaborative Mindset : Strong communication skills with experience working in cross-functional teams.
• Leadership Ability : Experience mentoring and driving excellence within development teams.
• Desirable : Familiarity with financial systems or trading platforms.",,,False,,,fulltime,https://www.itjobswatch.co.uk/jv/Stanford-Black-Limited/Senior-Market-Data-Engineer-CPlusPlus-Low-Latency-Systems-Hiring-Immediately-Job-London-UK-3h0z1j?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Senior Market Data Engineer (C++) - Low Latency Systems (Hiring Immediately)
Anglian Water,,1737676800000,"Who are we?

Here within the @one Alliance we are a totally collaborative organisation made up of our eight partner companies (Anglian Water, Balfour Beatty, Barhale, Binnies, MMB, MWH Treatment, Skanska and SWECO) and our extended supply chain, delivering over half of Anglian Water's capital investment programme.

We are gearing up for our most exciting and challenging Asset Management Period yet, known as AMP8, this will see us deliver a programme of work larger than we've ever delivered before. We'll be embarking on a new kind of project delivery focusing on nature-based solutions like wetlands and urban drainage schemes.

We are driving change, empowering us to set global benchmarks and build a better environment, with the opportunity to offer enhanced growth and development to our workforce. We're looking to build on our existing teams with an environment built for career progression.

With a variety of challenging and complex projects, it is essential we present and support the most innovative and pro-active digital solutions possible, providing an industry-leading end-to-end digital facility across the @one Alliance. To that end we are seeking a Digital Data Engineer to join our team to help us achieve success!

What will you be doing as our new Digital Data Engineer?

You will play a key role in managing the data requirements for the @one alliance as part of our Alliance Digital Team. You will ensure the Alliance's data exploration's data needs are met by acquiring data from various sources, variable engineering and using data science techniques to add value to the process. Working alongside our suppliers Autodesk, Microsoft, ESRI as well as world class academic institutions you will have an opportunity to make a real difference supporting the capability that delivers hundreds of projects across the region for years to come.

Sound exciting? Then read on:

Key responsibilities:

Digital Implementation:
• Contribute to the successful implementation of new digital platforms and new functionality within existing systems.
• Ensure the outputs of models are made available in the Azure data lake and assist with industrialising the outputs in the data warehouse.
• Manage and administrate our existing APIs to pull and push data between our various platforms and ensuring alignment.
• Create/contribute to case studies for successful trials and implementations.
• Working with other members of the digital team and appropriate stakeholders you will assist in the linking of platforms to ensure that manual intervention is kept to a minimum and data integrity is maximised.

Platform Support:

Our platforms are utilised by a diverse user base including @one, partners, supply chain and AW. As you become an expert in the alliances digital platform you will be expected to:
• Offer end user support.
• Manage calls to the providers Service desks where applicable.
• Assist superusers/platform champions in making sure that everyone is kept up to date in changes to platform functionality, considering the roadmaps created by platform leads.
• Deliver periodic and ad hoc refresher training as the need arises.

Process Improvement
• Become an expert in the alliance's digital platforms you will be best placed, working with the department/function, to look at how business processes can be altered to work in harmony with the system's functionality.
• You will learn to and then implement process changes driven by this functionality, obtaining buy in from users and showing them how it works whilst ensuring that any runbooks are kept up to date.

A little bit about your skills, experience and behaviours....

To be considered for this position, ideally you have exposure/experience in Implementation, particularly in SaaS products and experience in the management and support of business systems. You will come from an environment where exploitation of software solutions to improve business efficiency is key. Although experience in a specific industry is not essential Water Industry experience will be a distinct advantage.

More importantly is your willingness to learn systems and config, and interest in the project life cycle. You'll use your technical, commercial and customer facing skills to grow in this position, and your willingness to support end users will ensure you are the go-to person for support. Your positive team working attitude and good communication skills and focus on process improvement will ensure you stand out in a crowd!

If this position excites you and most importantly you have the aptitude to make a difference apply today!

Our vision

A collaborative alliance, driving change. Empowering us to set global benchmarks and building a better environment for our customers. We strive to:

Empower our people; Delight our Customers; Embrace digital transformation; Deliver brilliance.

Our Values

To bring environmental and social prosperity to the region we serve through our commitment to Love Every Drop we:

Build trust; Do the right thing; Are always exploring

The Anglian Water @one Alliance. Eight partners, endless opportunities.

Location: Hybrid, Peterborough",,,False,,,fulltime,https://www.breakroom.cc/en-gb/jobs/listing/75706078-anglian-water-group-digital-data-engineer-peterborough?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Peterborough,,,Digital Data Engineer
VBeyond Corporation,,1737676800000,"Job Description:

As a Data Engineer with Iceberg experience, you will play a crucial role in the design, development, and maintenance of our data infrastructure. Your work will empower data-driven decision-making and contribute to the success of our data-driven initiatives.

Key Responsibilities:
• Data Integration: Develop and maintain data pipelines to extract, transform, and load (ETL) data from various sources into AWS data stores for both batch and streaming data ingestion.
• AWS Expertise: Utilize your expertise in AWS services such as Amazon EMR , S3, AWS Glue, Amazon Redshift, AWS Lambda, and more to build and optimize data solutions.
• Data Modeling: Design and implement data models to support analytical and reporting needs, ensuring data accuracy and performance.
• Data Quality: Implement data quality and data governance best practices to maintain data integrity.
• Performance Optimization: Identify and resolve performance bottlenecks in data pipelines and storage solutions to ensure optimal performance.
• Documentation: Create and maintain comprehensive documentation for data pipelines, architecture, and best practices.
• Collaboration: Collaborate with cross-functional teams, including data scientists and analysts, to understand data requirements and deliver high-quality data solutions.
• Automation: Implement automation processes and best practices to streamline data workflows and reduce manual interventions.
• Experience working with bigdata ACID file formats to build delta lake, particularly with Iceberg file formats and loading methods of Iceberg.
• Good knowledge on Iceberg functionalities to use the delta features to identify the changed records, optimization and housekeeping on Iceberg tables in the data lake.

Must have: AWS, ETL, EMR, GLUE, Spark/Scala, Java, Python,

Good to have: Cloudera – Spark, Hive, Impala, HDFS, Informatica PowerCenter, Informatica DQ/DG, Snowflake Erwin",,,False,,,fulltime,https://uk.jooble.org/jdp/8909548066774140659?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Milton Keynes,,,Data Engineer (Hiring Immediately)
NBCUniversal,,1737676800000,"Company Description

We create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.

As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.

Job Description

Our Direct-to-Consumer (DTC) portfolio is a powerhouse collection of consumer-first brands, supported by media industry leaders, Comcast, NBCUniversal and Sky. When you join our team, you’ll work across our dynamic portfolio including Peacock, NOW, Fandango, SkyShowtime, Showmax, and TV Everywhere, powering streaming across more than 70 countries globally. And the evolution doesn’t stop there. With unequalled scale, our teams make the most out of every opportunity to collaborate and learn from one another. We’re always looking for ways to innovate faster, accelerate our growth and consistently offer the very best in consumer experience. But most of all, we’re backed by a culture of respect. We embrace authenticity and inspire people to thrive.

As part of the Direct-to-Consumer Decision Sciences team, the Lead Data Engineer will be responsible for creating a connected data ecosystem that unleashes the power of our streaming data. We gather data from across all customer/prospect journeys in near real-time, to allow fast feedback loops across territories; combined with our strategic data platform, this data ecosystem is at the core of being able to make intelligent customer and business decisions.

In this role, the Data Engineer will share responsibilities in the development and maintenance of optimized and highly available data pipelines that facilitate deeper analysis and reporting by the business, as well as support ongoing operations related to the Direct-to-Consumer data ecosystem.

Responsibilities Include, But Are Not Limited To
• Develop and maintain batch and streaming data pipelines according to business and technical requirements.
• Deliver observable, reliable and secure software, embracing “you build it you run it” mentality, and focus on automation.
• Continually work on improving the codebase and have active participation in all aspects of the team, including agile ceremonies.
• Take an active role in story definition, assisting business stakeholders with acceptance criteria.
• Work with Principal Engineers and Architects to share and contribute to the broader technical vision.
• Practice and champion best practices, striving towards excellence and raising the bar within the department.
• Operationalize data processing systems (DevOps) and system observability (SRE)

Qualifications
• 1+ years relevant experience in Data Engineering
• Experience of near Real Time & Batch Data Pipeline development in a similar Big Data Engineering role.
• Programming skills with an OOP language (e.g., Java, Python)
• Proficient with SQL
• Experience working in a cloud environment such as Google Cloud Platform or AWS
• Hands on programming experience of the following (or similar) technologies:
• Kubernetes, Docker
• Apache Beam, Apache Flink, Apache Spark
• Google BigQuery, Snowflake
• Google BigTable
• Google Pub/Sub, Kafka
• Apache Airflow
• Experience implementing observability around data pipelines using SRE best practices.
• Experience in processing structured and unstructured data into a form suitable for analysis and reporting with integration with a variety of data metric providers ranging from advertising, web analytics, and consumer devices.
• Bachelors’ degree with a specialization in Computer Science, Engineering, Physics, other quantitative field or equivalent industry experience.

Desired Characteristics
• Strong Test-Driven Development background, with understanding of levels of testing required to continuously deliver value to production.
• Experience with large-scale video assets
• Ability to work effectively across functions, disciplines, and levels
• Team-oriented and collaborative approach with a demonstrated aptitude, enthusiasm and willingness to learn new methods, tools, practices and skills
• Ability to recognize discordant views and take part in constructive dialogue to resolve them
• Pride and ownership in your work and confident representation of your team to other parts of

Additional Information

As part of our selection process, external candidates may be required to attend an in-person interview with an NBCUniversal employee at one of our locations prior to a hiring decision. NBCUniversal's policy is to provide equal employment opportunities to all applicants and employees without regard to race, color, religion, creed, gender, gender identity or expression, age, national origin or ancestry, citizenship, disability, sexual orientation, marital status, pregnancy, veteran status, membership in the uniformed services, genetic information, or any other basis protected by applicable law.

If you are a qualified individual with a disability or a disabled veteran and require support throughout the application and/or recruitment process as a result of your disability, you have the right to request a reasonable accommodation. You can submit your request to AccessibilitySupport@nbcuni.com.",AccessibilitySupport@nbcuni.com,,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-at-nbcuniversal-4133593893?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Brentford,,,Data Engineer
Nigel Frank,,1737676800000,"ML / AI Engineer - £60,000 - Remote

Company Overview:

Our client is a Microsoft-partnered consultancy that excels in delivering exceptional data and AI solutions to a diverse array of clients. Their expertise includes advanced data analytics, artificial intelligence, and custom finance solutions, ensuring tailored support for each unique business need. Recognising the importance of work-life balance, the company fosters a culture that values employee well-being, significantly boosting morale and productivity. Consequently, the role is designed to be almost entirely remote, offering flexibility and a supportive work environment.

Client has large plans to massively grow out their Data & AI team, and with VC backing the sky is the limit!

Role Overview:

The client is looking for a talented Data / ML engineer to come in as a consultant to work on a large variety of projects across multiple industries. The role will utilise all the latest AI tech including Gen-AI, ML and Open AI.

As a consultant you will be working directly with clients to understand business needs and implement industry best AI solutions accordingly.

Requirements:
• Strong Python experience, particularly for AI/ML use
• Experience with cloud technology, Azure preferred
• Data Science, Machine Learning and AI tech experience

Benefits:
• 10% Bonus
• Remote Working
• 25 Days Annual Leave + Bank Holidays
• Annual Salary Review
• + Much more

This is an unmissable chance to hone your skills and grow your career working for a top Microsoft partner, interviews are already underway so don't miss your chance. Apply Now!

Contact - j.shaw-bollands@tenthrevolution.com // 01913386641

ML, Machine Learning, AI, Artificial Intelligence, Data Science, Azure, ADF, Data Engineer, Azure Data Factory, Data Consultant, Consultancy, Microsoft, API, D365, Data Architect, Pre-Sales, Consultant",j.shaw-bollands@tenthrevolution.com,,True,,,fulltime,https://www.nigelfrank.com/job/a0M1i00000X3juA.17_1737736322/ml---ai-engineer-python-gbp60000-remote?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Bristol,,,"ML / AI Engineer - Python - GBP60,000 - Remote"
Future Talent Group,,1737676800000,"Senior Ruby Engineer - (SaaS / Tech4Good / GIS Data) - Remote-First Team

Salary: £80,000 - £85,000

Location: Remote, with team meet-ups in the UK several times per year

Industry: GIS Data and PropTech

Would you like to join a growing scale-up that is not only disrupting an entire industry in a positive way but also creating real benefits for its platform users? You’ll work alongside leading specialists in GIS data, Data Engineering, and SaaS to build cutting-edge solutions.

Responsibilities:
• Develop and maintain robust, scalable, and secure Ruby-based applications.
• Build APIs and integrations to power our platform and deliver seamless user experiences.
• Collaborate with cross-functional teams, including Product, Design, and DevOps, to ship features quickly and efficiently.
• Write clean, maintainable, and testable code following best practices and coding standards.

Technical Skills:
• Proven expertise as a Ruby/Ruby on Rails developer in a fast-paced environment.
• Strong understanding of RESTful APIs, database design, and system architecture.
• Experience working as part of an agile team, utilising TDD and DevOps practices.
• Proficiency in modern development tools and practices (e.g., Git, CI/CD pipelines).
• Knowledge of front-end technologies (e.g., JavaScript, HTML, CSS) is a plus.
• Familiarity with cloud platforms, ideally AWS.

If this opportunity excites you, please apply or feel free to reach out directly at scott@futuretalent.io",scott@futuretalent.io,,True,,,fulltime,https://uk.linkedin.com/jobs/view/senior-ruby-engineer-saas-tech4good-gis-data-remote-first-team%C2%A0-at-future-talent-group-4133366858?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Bristol,,,Senior Ruby Engineer - (SaaS / Tech4Good / GIS Data) - Remote-First Team
WHD,,1737590400000,"Data Engineer

I am looking for a Data Engineer / Data Scientist for a company in the Maidenhead area.

Work is Hybrid – 3 days onsite, 2 days remote. You will be leveraging your analytical skills and programming experience to extract insights from complex datasets, develop predictive models and support decision making.

KEY Responsibilities

Data Analysis & Modelling:
• Analyse large, complex datasets to identify trends, patterns, and actionable insights.
• Develop, implement, and optimize machine learning models to solve business problems.
• Conduct A/B testing and experimental analysis to validate hypotheses.

Data Management & Engineering:
• Collaborate with data engineering teams to ensure data quality, accessibility, and efficiency.
• Design and develop ETL pipelines and workflows for data preprocessing.
• Develop automated tests to validate the processes and models you create.

Collaboration & Communication:
• Collaborate with stakeholders to define project goals, requirements, and deliverables.
• Actively participate in design meetings to help shape the solutions that the team delivers
• Present findings and recommendations to technical and non-technical audiences.
• Acquire domain knowledge to inform modelling opportunities and model feature creation

Technical Leadership:
• Mentor junior data scientists and provide peer reviews for modelling projects.
• Stay current with industry trends, tools, and best practices to continuously improve the team's capabilities.

QUALIFICATIONS

Education:
• Bachelor’s degree in data science, Statistics, Mathematics, or a related field.

Experience:
• 2 or more years of experience in a data science or analytics role.
• Proven experience in building machine learning models, statistical analysis, and predictive analytics.
• Experience designing experiments or modelling approaches to solve a specified business problem.

PREFERRED QUALIFICATIONS
• Proficiency in programming languages such as Python or R; knowledge of is R an advantage.
• Experience with SQL and working knowledge of relational databases.
• Proficiency with data visualisation tools and techniques.
• Experience with AWS is a plus.
• Strong problem-solving and critical-thinking abilities.
• Excellent communication and presentation skills.
• Ability to manage multiple projects and prioritize tasks effectively.",,,True,,,fulltime,https://www.cv-library.co.uk/job/222946437/Data-Engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Maidenhead,,,Data Engineer
Roke Manor Research Limited,,1737590400000,"As a Data Engineer, you’ll be actively involved in development of mission critical technical solutions that focus on data services for our National Security customers.

Roke are a leading technology & engineering company with clients spanning National Security, Defence and Industry . You will work alongside our customers to solve their complex and unique challenges.

As our next Data Engineer, you’ll be managing and developing data pipelines that transform raw data into valuable insights for Roke’s National Security customers, enabling downstream analytics and reporting. You’ll be working with diverse data sources (batch, streaming, real-time and unstructured), applying distributed compute techniques to handle large datasets.

The Key Requirements...
• Able to develop Extract, Transform, Load (ETL) or Extract, Load, Transform (ELT) workflows to move data from source systems to date stores
• You will have used one or more supporting technologies i.e. Apache, Kafka, NiFi, Spark, Flink or Airflow etc.
• A history working with SQL and NoSQL type databases (PostgreSQL, Mongo, ElasticSearch, Accumulo or Neo4j etc.)
• You will be able to code using a modern software language such as Python, Java or Go
• Experience of distributed computing techniques.

Built over a 60-year heritage, Roke offers specialist knowledge in sensors, communications, cyber, and AI and ML, and Data Science. We change the way organisations think and act through dynamic insights from the analysis of multiple layers of data. We take care of the innovative, technical stuff that keeps everyone safe that’s our mission, passion, and motivation.

Joining a team united by purpose and ambition, you’ll be at the heart of an exciting growth journey: having doubled in size over the last 4 years, we intend to double our headcount by 2027. At Roke, every individual counts. We push technical boundaries, together. We re-invest in product innovation, and we empower our people to make a difference.

Where you’ll work

You’ll find our Gloucester site in a business park two minutes from junction 11A of the M5; The site allows easy access to our local customer base. Set on the outskirts of the Cotswolds, you are never far from a picturesque view or lunch time walk.

Why you should join us...

We are one Roke. We believe we all have a responsibility to create an environment where we all have the time, trust and freedom to succeed and where we are encouraged to bring our whole self to work. We are committed to a policy of Equal Opportunity, Diversity and Inclusion, enabled by our employee led resource groups of Women In Roke, Neurodiversity, Inspire (LGBT+) and ME (Majority Ethnic), which each contribute to making Roke a great place for people from all backgrounds to work.

Mental health and wellbeing is important to us, and we have a group of supportive Mental Health First Aiders to lend a listening ear for anyone who needs it. We also have a team of Mental Health First Aid Champions who help build a mentally healthy workplace, challenge stigma and support positive wellbeing.

The Benefits and Perks...
• Flexi-time: Working hours to suit you and your life
• Annual bonus: Based on profit share and personal performance
• Private medical insurance: Includes cover for existing conditions
• Holiday: You'll receive competitive annual leave plus bank holidays. We also offer the opportunity to buy and sell annual leave
• Chemring Share Save: Monthly savings into a 3 or 5 year plan.

Clearances

Due to the nature of this role, we require you to be eligible to achieve DV clearance. As a result, you should be a British Citizen and have resided in the U.K. for the last 10 years.

The Next Step...

Click apply, submitting an up-to-date CV. We look forward to hearing from you.",,,False,,,fulltime,"https://www.glassdoor.co.uk/job-listing/data-engineer-roke-manor-research-limited-JV_IC3379755_KO0,13_KE14,41.htm?jl=1009249386241&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",,,Gloucester,,,Data Engineer
Robert Walters,,1737590400000,"Lead Data Engineer

Cheshire- Hybrid working

£80,000-£85,000+ benefits

We are seeking a highly skilled and experienced Lead Data Engineer to join a growing Insurance firm and report into the Head of Data. The ideal candidate will be a strong Azure user and have extensive experience with data engineering

Lead Data Engineer duties:
• Lead the design, implementation, and maintenance of scalable data pipelines to support business analytics, reporting, and machine learning initiatives.
• Collaborate with data scientists, analysts, and business stakeholders to define data requirements and deliver data solutions that meet organisational needs.
• Oversee the architecture of data infrastructure, including data warehousing, ETL processes, and data storage solutions.
• Ensure data quality, consistency, and security across systems.
• Optimise the performance and scalability of data systems.
• Provide technical leadership and mentorship to a team of data engineers, fostering a culture of continuous learning and improvement.
• Guide the adoption of best practices for data engineering, including code reviews, testing, and deployment processes.
• Monitor data pipeline performance and troubleshoot issues to ensure data availability and reliability.
• Stay up to date with the latest trends and technologies in the data engineering space and evaluate tools to continuously improve data infrastructure.
• Ensure compliance with data governance, privacy, and regulatory requirements.

As Lead Data Engineer, you will have:
• Experience with machine learning frameworks or data science workflows.
• Familiarity with modern BI and data visualization tools (e.g., Tableau, Power BI).
• Experienced doing similar duties within a similar role capacity..
• Experience with ETL tools and frameworks.
• Solid understanding of data modelling, data warehousing, and database design principles.
• Familiarity with data governance, data privacy regulations (GDPR, CCPA), and best practices for data security.
• Expertise in cloud platforms preferably Azure and associated data services.
• Excellent communication skills and the ability to work collaboratively with cross-functional teams.
• Strong problem-solving skills and a passion for working with large datasets and complex data challenges.

Robert Walters Operations Limited is an employment business and employment agency and welcomes applications from all candidates",,,False,,,fulltime,https://www.robertwalters.co.uk/technologydigital/jobs/databases/1805048-lead-data-engineer.html?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,,,,Lead Data Engineer
Machine Learning Jobs,,1737590400000,"Azure Data Engineer | £65,000 - £70,000 | UK/Remote |

Power BI | Synapse | Azure Data Bricks | ADF | SQL | Data Engineer | Reporting | Data Sets | Fabric |

Are you a Data Engineer who enjoys getting involved with the architecture side of the role? Or maybe you want to join a company and have autonomy? If so I have a role for you.

I am looking for an experienced Data Engineer to join a company that support the automotive industry covering a range of aspects from theft prevention to fleet management. They have grown impressively over the last year and are now looking to invest in people.

They have recently gone through an Azure Migration and are looking for a Data Engineer to join a small team to architect data sets, push them into Power BI and move them export to data lake to fabric link.

They are using a great tech stack which includes –Azure ADF, Data Lakes, Synapse, Power BI, Fabric, Logic Apps, SQL.

You will also be working closely with BI and SQL Developers with building dashboards and reports which will be going out to various customers.

Salary is up to £70,000 and the tech team work remotely with occasional visits to the office.

Other benefits include –
• 5% company pension
• Private healthcare
• Learning and Development budget
• Perkbox
• Life Assurance
• Wellbeing options

Even though this is a remote position you need to be a full time UK resident and sponsorship isn’t available.

This a brilliant opportunity for someone looking to grow their career. They have a fantastic tech stack and have brilliant progression routes.

Power BI | Synapse | Azure Data Bricks | ADF | SQL | Data Engineer | Reporting | Data Sets | Fabric |",,,True,,,fulltime,https://machinelearningjobs.co.uk/view-job/azure-data-engineer-ps65000-ps70000-ukremote-7842afddd4f1?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Southampton,,,"Azure Data Engineer | £65,000 - £70,000 | UK/Remote |"
Machine Learning Jobs,,1737590400000,"Lead Data Engineer - Azure

Hybrid working - London

SC Clearance or SC Clearable

Key skills - Azure, Fabric, SQL, Synapse

We are looking for an experiencedLead Data Engineerwho has a strong background in data engineering and architecture, with expertise inAzure Data Factory, Synapse, Fabric,andSQL. The role requires hands-on technical skills as well as the ability to lead a team or manage projects.

Key Responsibilities:
• Design, develop, and maintain data solutions usingAzure Data Factory,Azure Synapse Analytics,Azure Fabric, andSQL.
• Lead and mentor a team of data engineers, guiding them in best practices for data management and architecture.
• Oversee end-to-end data pipeline development, ensuring data quality, integrity, and scalability.
• Collaborate with stakeholders to understand business requirements and translate them into effective data solutions.
• Optimize data storage and retrieval processes, ensuring high performance and efficiency.
• Maintain documentation of data architecture and processes.
• Ensure compliance with industry regulations and security standards.

Must-Have Skills:
• Azure Data Factory, Synapse, Fabric, SQL: Advanced experience in designing and implementing solutions.
• Has experience in leading a team or managing data engineering projects.
• SC Clearance or SC Clearable: Candidates must currently holdSC (Security Clearance)or be eligible for clearance.
• Experience with other Azure services, such asAzure DatabricksorAzure Data Lake.
• Knowledge ofdata governanceanddata security best practices.

Send through your CV if interested to arrange a call and discuss further!",,,False,,,fulltime,https://machinelearningjobs.co.uk/view-job/data-team-lead-76550548689e?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Team Lead
Accenture,,1737504000000,"Data Engineer, Associate Manager

Job Title: Data Engineer, Associate Manager CL8

Locations: London/Bristol/Manchester

Salary: Competitive salary and package (Depending on level of experience)

Please Note: Any offer of employment is subject to satisfactory BPSS and SC security clearance which requires 5 years continuous UK address history at the point of application.

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. With our thought leadership and culture of innovation, we apply industry expertise, diverse skill sets and next-generation technology to each business challenge.

We believe in inclusion and diversity and supporting the whole person. Our core values comprise of Stewardship, Best People, Client Value Creation, One Global Network, Respect for the Individual and Integrity. Year after year, Accenture is recognised worldwide not just for business performance but for inclusion and diversity too.

""Across the globe, one thing is universally true of the people of Accenture: We care deeply about what we do and the impact we have with our clients and with the communities in which we work and live. It is personal to all of us."" - Julie Sweet, Accenture CEO

Key responsibilities

• Implement ETL pipelines and orchestrate data flows using batch and streaming technologies based on software engineering best practice
• Define, document and iterate data mappings based on concepts and principles of data modelling
• Re-engineer data pipelines to be scalable, robust, automatable, and repeatable
• Navigate, explore and query large scale datasets
• Build processes supporting data transformation, data structures, metadata, dependency and workload management
• Identify and resolve data issues including data quality, data mapping, database and application issues
• Implement data flows to connect operational systems, data for analytics and business intelligence (BI) systems
• Deliver high quality implementation and documentation for critical functionality
• Deliver code, unit tests, feature tests, stubs and integration tests.
• Operate in an agile environment as part of a scrum team and participate in sprint rituals
• Work with team members to understand designs, functional requirements and triage issue
Qualifications

We have a number of opportunities available from junior to senior level and we are looking for data engineers who have a variety of different skills which include some of the below.

• Strong proficiency in at least one programming language (Python, Java, or Scala)
• Extensive experience with cloud platforms (AWS, GCP, or Azure)
• Experience with:
• Data warehousing and lake architectures
• ETL/ELT pipeline development
• SQL and NoSQL databases
• Distributed computing frameworks (Spark, Kinesis etc)
• Software development best practices including CI/CD, TDD and version control.
• Strong understanding of data modelling and system architecture
• Excellent problem-solving and analytical skills
Whilst having experience in a consultancy is beneficial, demonstrable experience in working with clients/external partners in other settings will always be considered.

What's in it for you

At Accenture in addition to a competitive basic salary, you will also have an extensive benefits package which includes 25 days' vacation per year, private medical insurance and 3 extra days leave per year for charitable work of your choice!

Flexibility and mobility are required to deliver this role as there will be requirements to spend time onsite with our clients and partners to enable delivery of the first-class services we are known for.

About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialised capabilities across more than 40 industries - powered by the world's largest network of Advanced Technology and Intelligent Operations centres.

With 509,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity, or any other basis as protected by applicable law.

Closing Date for Applications 31st March 2025

Accenture reserves the right to close the role prior to this date should a suitable applicant be found.

About Accenture
Accenture is a leading global professional services company that helps the world's leading organizations build their digital core, optimize their operations, accelerate revenue growth and enhance services-creating tangible value at speed and scale. We are a talent- and innovation-led company with 774,000 people serving clients in more than 120 countries. Technology is at the core of change today, and we are one of the world's leaders in helping drive that change, with strong ecosystem relationships. We combine our strength in technology and leadership in cloud, data and AI with unmatched industry experience, functional expertise and global delivery capability. Our broad range of services, solutions and assets across Strategy & Consulting, Technology, Operations, Industry X and Song, together with our culture of shared success and commitment to creating 360Â° value, enable us to help our clients reinvent and build trusted, lasting relationships. We measure our success by the 360Â° value we create for our clients, each other, our shareholders, partners and communities.
Visit us at www.accenture.com

Equal Employment Opportunity Statement

All employment decisions shall be made without regard to age, race, creed, colour, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status or any other basis as protected by applicable law.

Job candidates will not be obligated to disclose sealed or expunged records of conviction or arrest as part of the hiring process.",,,False,,,fulltime,https://www.efinancialcareers.co.uk/jobs-UK-London-Data_Engineer_Associate_Manager.id22436565?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,"Data Engineer, Associate Manager | London, UK"
Opus Recruitment Solutions,,1737504000000,"Data Engineer (DV Cleared) - £80,000 - £90,000 – Cambridge/Hybrid |

Azure | Databricks | Data Factory | Synapse | SC Clearance | DV Cleared | Public Sector | Consultancy |

Are you a Data Engineer that holds SC Clearance? Or maybe you enjoy working with cloud technologies. If so I have a role for you!

I am currently supporting a boutique defence consultancy that believe in the transformative power of data to enhance global safety, resilience, and prosperity. This organisation specialises in converting complex data into clear, actionable insights, enabling precise behavioural analysis for the defence, intelligence, public, and commercial sectors.

Responsibilities include:
• Designing and managing scalable data pipelines.
• Creating effective solutions for data storage and retrieval.
• Upholding data retention policies and ensuring compliance with governance standards.
• Working alongside infrastructure engineers to integrate data processes.
• Safeguarding data security and overseeing data pipeline performance.
• Recording data engineering procedures.

Experience needed –
• Active DV Clearance (essential)
• Azure Data Tech stack - (ADF, Databricks, Synapse, SQL)

What do you get in return –
• Salary up to £90,000
• Hybrid working (1 day a week)
• Share scheme
• Private healthcare + dental
• Flexible hours
• International travel opportunities

If you’re interested please apply or drop me a message. if you do not have active DV Clearance then unfortunately you cannot be considered for this role.",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-dv-cleared-%C2%A380-000-%C2%A390-000-%E2%80%93-cambridge-hybrid-at-opus-recruitment-solutions-4131735137?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Cambridge,,,"Data Engineer (DV Cleared) - £80,000 - £90,000 – Cambridge/Hybrid |"
Photon,,1737504000000,"Database Management / Architecture (competent)

Maintains awareness of modelling techniques covering full range of analysis situations in the context of business analysis.

Selects appropriate modelling techniques for meeting assigned objectives, and models current and desired future scenarios as directed.

Works with clients/users and development groups to identify most appropriate and effective use of DB facilities and set strategy and standards for whole application areas.

Data Management (competent)

Leads the quality assurance of corporate data structures, and project developed data structures and associated components (e.g. Entity descriptions, Relationship descriptions, Attribute definitions).

Works with data management colleagues to ensure that modelling is carried out consistently, and that corporate standards for repository administration and data dictionaries are observed.

Contributes to the setting of standards for database objects (e.g. naming conventions) and ensures conformance to these standards.

Application Maintenance & Delivery (competent)

Within a project environment, assists in the investigation of application data and process requirements, documenting them according to the required standards utilising the prescribed methods and tools.

Programming & Application Development (competent)

Interprets design architecture to meet specification e.g. assistive technology, parallel processing.

Takes responsibility for the design, coding, testing and documentation of particularly large, complex or mission critical programs.

Analysis (competent)

Analyses requirements for fitness for purpose as well as adherence to business objectives and consistency, challenging positively as appropriate.

Communication lines

Scrum Team, Business Owner, Scrum Master

Architecture Team

IT Experts and Teams

Support Teams (Platform, Operations)

Business SMEs, Stakeholders

Qualifications

Minimum University / College degree in preferably IT domain, or Business/Economics

4-5+ years of relevant work experience in data engineering and/or business intelligence

Experience/Requirements

Solid expertise in many areas of data engineering, including: data modelling, ETL design and development, data and metadata managements., query design/development/tuning, database optimization, data governance, data quality, best practices

Understanding of databases and data technologies including: traditional RDMBS, noSQL, data stream solutions

Strong understanding of cloud (AWS) platforms and design patterns

Regularly makes commitments and consistently meeting targets

The role requires to have eagerness and ability to learn and adapt technologies, industry practices, tools, and trends

Solid experience with Python/SQL and Redshift or Postgres

Experience processing JSON, Avro JSON and other file formats

Nice to have: Experience with BI tools: Tableau, PowerBI, Airflow or other ETL tool",,,False,,,fulltime,"https://www.glassdoor.co.uk/job-listing/sr-data-engineer-aws-and-oracle-cloud-photon-JV_IC2671300_KO0,37_KE38,44.htm?jl=1009538755574&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",,,London,,,Sr Data Engineer - AWS and Oracle cloud
Hertz,,1737504000000,"Job Description:

The Data Science Analyst is responsible for Applications, Tools and Models that deliver actions and insights from Hertz’s rich history of observational data. Working closely with management, Analytics and the Data Science team, Data Science Analyst will build descriptive, predictive, and prescriptive models and support applications with the ultimate goal of maximizing profit and gaining a competitive advantage in the market.

What You’ll Do:
• Oversees the data science department’s training and competency development, determining best practices and work standards. The Data Science initiates data science programs across the department not only with a view of improving departmental performance but also with a focus on revenue growth and achievement of the business’ overall targets and objectives.
• Building and managing new data tables that support data collection in the department, cross-channel data integration, data visualization, dashboards, predictive analytics, and data mining.
• Leverages data science tools and techniques in analyzing large data-sets that will enable him to develop custom models and algorithms to uncover insights, trends, and patterns in the data, which will be useful in availing informed courses of action.
• Create data science platforms to test and experiment with techniques inclusive of advanced analytics, behavioral modeling, and churn capitalizing on new data science approaches that can yield revenue for the business.
• Design and architect data processing pipelines for the department. In this analytical position, the Data Science further drives the collection of new data as well as the refinement of existing business data sources.
• Leads the department in the development of new insights, advanced modeling techniques, and data science capabilities.
• Mentor members of data scientist and data analysts in best practices for data preparation, analysis, coding and modeling

What We’re Looking For:

Educational Background:
• Degree in a quantitative field with an emphasis on predictive modeling, including: Statistics, Data Science, Operations Research, Industrial Engineering, Actuarial Science, Mathematics, or Economics
• Graduate degree preferred but not required in lieu of experience

Required Experience:
• Designing and architecture of relational database systems
• Designing and architecture of distributed structured/unstructured data lakes / meshes system
• Experience in finding patterns in data and creating statistical models, data exploration, data visualization and data mining
• Experience in designing solution in: SQL Server, Teradata, Cloud (AWS), Databricks, Delta Lakes
• Solid understanding of MS SQL Server, Apache Spark
• Fluency in languages, SQL (T-SQL, Spark SQL), Python
• Experience in PySpark
• Strong problem solving and critical thinking skills with a proven record for identifying and diagnosing problems, and solving complex problems with simple, logical solutions.

What You’ll Strive For:
• Design & Build High Performance, failproof data pipeline solutions that drives Analytics & Data Science for Corporate Europe. In this analytical position, the Data Science further drives the collection of new data as well as the refinement of existing business data sources.
• Leads the department in the development of new insights, advanced modeling techniques, and data science capabilities.

What You’ll Get:
• Up to 40% off the base rate of any standard Hertz rental in a Corporate country
• Paid Time Off
• Employee Assistance Programme for employees and family",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/rm-data-science-analytics-engineer-at-hertz-4130101726?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Uxbridge,,,RM Data Science Analytics Engineer
Wren Kitchens,,1737504000000,"About The Role

We are seeking a highly motivated and experienced data engineering leader to own and manage all aspects of Wren's data lake including its transformation processes and data integrations. Your responsibilities will encompass managing the day-to-day activities within the data engineering team and providing technical guidance and mentorship to other engineers.

Key Responsibilities:
• Ensure the data lake is continuously monitored for performance, security, and availability. Using robust monitoring tools like Datadog to detect and resolve anomalies quickly. Maintain SLAs to ensure reliable data availability.
• Develop and enforce best practices for automated testing of ETL pipelines and data workflows. Implement data quality frameworks to ensure accuracy, consistency, and completeness of data at every stage. Leverage tools for unit testing, integration testing, and regression testing within the CI/CD pipeline to promote reliable deployments.
• Provide day-to-day management, coaching, and performance reviews for the data engineering team. Set clear objectives, define career development plans, and foster an environment of collaboration and continuous improvement. Identify skill gaps and provide necessary training and support.
• Act as the primary technical liaison for internal and external stakeholders. Work closely with business leaders, and analysts to understand data requirements and align engineering efforts with business objectives. Effectively collaborate with project managers to communicate project progress, risks, dependencies, and timelines to key stakeholders, ensuring alignment and proactive issue resolution throughout the project lifecycle.
• Oversee the architecture, governance, and evolution of the data lake. Ensure it remains scalable, secure, and cost-effective. Define policies and standards for data ingestion, access control, data retention, and data governance, ensuring compliance with regulatory and company guidelines.
• Foster a culture of innovation and learning by mentoring junior and mid-level engineers. Provide technical guidance on design patterns, data transformations, and cloud technologies. Encourage knowledge sharing within the team through code reviews, paired programming, and collaborative problem-solving.
• Ensure all aspects of the data platform, pipelines, and processes are well-documented, including architecture diagrams, data lineage, and operational guides. Maintain a comprehensive knowledge base to facilitate onboarding, troubleshooting, and system improvements.
• Collaborate with senior leadership to define the long-term strategy for data engineering, ensuring alignment with broader business goals. Identify emerging trends and technologies in data engineering and recommend innovations to keep the data platform future-proof and competitive.
• Decision-maker for architectural choices, tool selection, and implementation approaches. Perform thorough evaluations of technical options and provide clear recommendations backed by data and industry best practices. Balance technical excellence with pragmatic delivery to meet business needs efficiently.
• Act as a key partner for Business Intelligence teams, working closely to understand their data needs ensuring to maintain high-quality and well-structured data. Collaborate on the design of data models and abstractions. Provide guidance on data sourcing, transformation logic, and performance optimisation for BI tools.

Required Skills:
• Proactive and forward-thinking, with a focus on continuous improvement and anticipating future challenges.
• Minimum of 5 years' experience designing, building, and maintaining data platforms in production environments.
• Skilled in using modern monitoring tools such as Datadog, CloudWatch, or similar for observability and alerting.
• 5+ years of experience using Python for ETL/ELT processes, including data wrangling and pipeline orchestration.
• Strong communication skills, with the ability to convey technical concepts to both technical and non-technical stakeholders.
• Adept at problem-solving and root cause analysis, with a structured approach to troubleshooting complex data issues.
• At least 2 years of experience working with modern data lakes and ETL platforms such as Snowflake, Databricks, or equivalent.
• Hands-on experience with cloud platforms (AWS, Azure, or GCP), including compute, storage, and serverless services.
• Strong attention to detail, ensuring data quality, consistency, and accurate documentation.
• Experience using BI tools such as Tableau, Power BI to build reports and support data-driven decision-making

About You
• Experience using Jira for task tracking, sprint planning, and project management.
• Comfortable working within Agile frameworks, with experience in iterative development and sprint cycles.
• Experience serving as a Scrum Master, facilitating stand-ups, retrospectives, and sprint planning sessions.
• Familiar with the latest Databricks features, with the ability to evaluate and adopt them effectively.

About The Company

Wren, a leading name in the kitchen and bedroom industry, boasts an extensive and unique retail infrastructure, underpinned by a variety of in-house applications and services. As we continue to experience remarkable growth and success, we are seeking an experienced Lead Data Engineer to underpin our dynamic team.

Location",,,False,,,fulltime,https://www.breakroom.cc/en-gb/jobs/listing/75686585-wren-kitchens-lead-data-engineer-hybrid-barton-upon-humber?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Barton-upon-Humber,,,Lead Data Engineer-Hybrid
Searchability®,,1737504000000,"Data Engineer - C# Experience
• Opportunity for a Data Engineer to join an exciting Internet Marketing Agency in Liverpool
• Salary up to £45,000 + some fantastic benefits including hybrid working, a collaborative environment and private health insurance
• Apply online or contact Chelsea Hackett via Chelsea.hackett@searchability.com

WHO WE ARE:

We are a thriving agency in Liverpool looking to recruit a Data Engineer to join our growing function. With over 20 years of business under our belt we are a market leader within the industry and have a customer-centric approach, aiming to deliver high-quality service and build lasting relationships with our clients.

OUR BENEFITS:
• Flexible and hybrid working
• Autonomous working
• Companywide collaborative events
• Performance reward and achievements
• Private Health Insurance
• Pension Contribution
• And more…

WHAT WILL YOU BE DOING?

As a Data Engineer, you will be integral to managing and optimising our data infrastructure, ensuring smooth data integration and flow to support our innovative marketing solutions. Your primary responsibilities will include designing and implementing robust ETL pipelines. This position is essential for supporting the organisation's data-driven decision-making and maintaining the availability, integrity, and usability of data across the company.

DATA ENGINEER – ESSENTIAL SKILLS
• Stakeholder Engagement
• C#
• SQL
• Excellent communication
• Azure Data Factory

TO BE CONSIDERED…

Please either apply by clicking online or emailing me directly chelsea.hackett@searchability.com. By applying to this role you give express consent for us to process and submit (subject to required skills) your application to our client in conjunction with this vacancy only.","Chelsea.hackett@searchability.com, chelsea.hackett@searchability.com",,False,,,fulltime,https://talents.studysmarter.co.uk/companies/searchability/searchability-data-engineer-711495/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Liverpool,,,Searchability® | Data Engineer
Harnham,,1737504000000,"DATA ENGINEER

£55,000-£60,000 + BENEFITS

LEEDS (Hybrid)

A leading company in the retail industry is seeking a proactive Data Engineer to join their innovative team.

THE COMPANY:

This is a well-established brand driven by an ambitious vision. They are currently investing in their data team, and are looking for a Data Engineer to help gather requirements and build solutions.

THE ROLE:

A Data Engineer will need to:
• Work closely with stakeholders across the business
• Manage data warehouse end-to-end (gathering requirements and building solutions)
• Helping to build data models

YOUR SKILLS AND EXPERIENCE:

A successful Data Engineer will have the following skills and experience:
• Ability and experience interacting with key stakeholders
• Strong experience in SQL/Python
• Experience with Azure/ADF
• Background in CI/CD

THE BENEFITS:

You will receive a salary, dependent on experience. Salary is up to £60,000 On top of the salary there are some fantastic extra benefits.

HOW TO APPLY

Please register your interest by sending your CV to Molly Bird via the apply link on this page.",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/harnham/harnham-senior-azure-data-engineer-702981/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Leeds,,,Harnham | Senior Azure Data Engineer
AM Healthcare Group,,1737417600000,"Location: Abingdon, Oxfordshire (Hybrid Working)

AM Healthcare Group are a market leading international healthcare products and services provider, operating primarily in areas that enhance mobility and accessibility including orthotics, prosthetics, and wheelchairs. We have more than 60 sites across the UK and Ireland, as well as operations in France, The Netherlands and Sweden: employing approximately 700+ staff.

We have an exciting opportunity for a Business Intelligence Data Engineer to join our team in Abingdon, Oxfordshire.

Working at Head Office & Remote

This position will predominantly be working remotely with travel to the office expected at least once a week or when required.

Job role summary

We are currently seeking an experienced Business Intelligence Data Engineer who is looking for an opportunity to develop their career and be a part of our large and dynamic team in Abingdon.

The Data Engineer will be responsible for designing, developing, and maintaining Business Intelligence solutions using Microsoft Power BI. This role involves working extensively with Microsoft Fabric (F64) and Lakehouse architectures, Data Flows, and Data Pipelines to ensure the seamless integration and transformation of data from various sources. The ideal candidate will have a strong background in data analysis, data modelling, and Power BI development.

Key Responsibilities:
• Datawarehouse/Lakehouse Architecture: Design, implement, and manage data architectures, including Lakehouse frameworks, to support scalable and efficient data storage and retrieval for BI solutions.
• Data Flows: Develop and manage Power BI Data Flows, enabling the preparation, transformation, and integration of data from various sources into a unified and consistent format for reporting and analytics.
• Data Pipelines (Data Factory): Create and maintain data pipelines to automate the extraction, transformation, and loading (ETL) of data into Power BI, ensuring real-time or near-real-time data availability for business users.
• Data Modelling: Create and maintain complex data models, including relationships, calculated columns, and measures, to support reporting and analytics needs.
• Data Integration: Extract, transform, and load (ETL) data from various sources, including databases, cloud services, and APIs, into Power BI.

Skills & Experience:

Education:
Desired but not essential:
- Microsoft Certified: Fabric Analytics Engineer Associate

Experience:
5+ years of experience in:
- Business Intelligence
- Data Analytics
- Or a related field with a focus on Fabric development

Technical Skills:
- Experience with data integration and transformation using Microsoft Fabric.
- Proficiency in using Microsoft Fabric for data modelling and analytics.
- Understanding of data governance and security within Microsoft Fabric.
- Proficiency in Microsoft Power BI, including Power Query, DAX.
- Strong understanding of relational databases, SQL, and data warehousing concepts.
- Experience with ETL processes and tools (e.g., SSIS, Azure Data Factory).
- Knowledge of Lakehouse architectures and data pipeline management.
- Basic understanding of Azure services, including Azure SQL Database, Azure Synapse Analytics, or similar cloud platforms.
- Desired Experience with data extraction and integration from Navision/BC Central

What We Offer:
- Competitive market salary.
- Industry leading training opportunities.
- Incremental holiday allowance 33 days up to 38 days (inclusive of bank holidays).
- Refer a friend incentive scheme.
- Continued professional development.

To apply please email your CV with a covering letter ASAP to recruitment@am-healthcare.com.

For more details and additional vacancies please see our website www.amhealthcaregroup.com.

Eligibility to Work in the UK: Please note that applicants must have the right to work in the UK at the time of application. Unfortunately, we are unable to provide visa sponsorship for this role.

AM Healthcare Group are an equal opportunities employer, we have a clear goal of driving diversity and inclusion across all operations of the group.",recruitment@am-healthcare.com,,True,,,fulltime,https://amhealthcaregroup.com/jobs/business-intelligence-data-engineer-abingdon/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Abingdon,,,Business Intelligence Data Engineer – Abingdon
Robert Walters,,1737417600000,"Senior Data Engineer

Warrington- 1 day per week

Financial Services Sector

Robert Walters are delighted to be supporting a Financial focused business near Cheshire, in their hunt for a proficient Senior Data Engineer. This role will hone in on your Azure Synapse skills and require strong experience with ETL Processes and T SQL. This is a fast growing company with plenty progressional opportunities for the right candidate.

Responsibilities as Senior Data Engineer:
• Design, develop, and maintain scalable and reliable data pipelines and architecture, ensuring smooth data flow from source systems to the Landing Zone and onward to DataMarts.
• Utilise Azure Synapse for large-scale data processing, optimising its integration within the overall data architecture.
• Collaborate with the Director of Global Data and Analytics to align the data engineering strategy with business objectives, ensuring that data solutions meet organisational requirements.
• Develop and optimise complex data models, database schemas, and ETL processes to support business intelligence and analytical reporting.
• Implement and maintain data quality checks and monitoring systems to ensure data integrity and consistency.
• Lead and mentor Junior Data Engineers, providing guidance and promoting best practices in data engineering.
• Leverage PowerBI for advanced data modeling and configure data gateways to enable secure and efficient access to on-premises data sources.
• Continuously improve data architecture, processes, and technologies by staying current with industry trends and emerging best practices.
• Provide expert-level support and troubleshoot any data-related issues within the organisation.

As Senior Data Engineer, you will have:
• Proven experience as a Senior Data Engineer with a focus on designing and building scalable data architectures.
• Proficiency in Azure Synapse, Azure Data Pipelines, and other Azure cloud services for data management and analytics.
• Strong expertise in T-SQL, including complex query optimisation and database management.
• Extensive experience with ETL processes, data warehousing, and database design.
• Familiarity with Alteryx for data processing, analytics, and reporting.
• Experience with Agile methodologies and DevOps practices in a data engineering environment.
• Knowledge of the HCM industry.
• Understanding of data governance, security, and compliance practices, particularly in a global data environment.

Robert Walters Operations Limited is an employment business and employment agency and welcomes applications from all candidates",,,False,,,fulltime,https://www.robertwalters.co.uk/technologydigital/jobs/databases/1804600-senior-data-engineer.html?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Warrington,,,Senior Data Engineer
Jefferson Frank,,1737417600000,"Senior Data Engineer - Snowflake - £85,000 - £100,000 (+10% Bonus) - London - Hybrid

Company Overview:

My client is a global leader in the insurance industry, serving millions of customers worldwide. With strong financial foundations established over decades, their commitment to utilising innovative solutions and cutting-edge technologies is a key pillar of their recent success. They are also dedicated to ensuring the well-being and happiness of their employees through very flexible hybrid working patterns, as well as other amazing benefits, and a great company culture - over 4 out of 5 employees would recommend working here.

Role Overview:

As a Senior Data Engineer you'll be responsible for building and deploying full solutions from scratch, while maintaining security and data best practices. Duties will include product-based work as well as migration tasks. Due to your seniority you will also be tasked with mentoring junior engineers. You will be joining a close-knit team of 6 Data Engineers, as well as 30 Engineers in the businesses data arm.

Requirements:
• 3+ Years data engineering experience
• Snowflake experience
• Proficiency across an AWS tech stack
• DevOps experience building and deploying using Terraform

Nice to Have:
• DBT
• Data Modelling
• Data Vault
• Apache Airflow

Benefits:
• Up to 10% Bonus
• Up to 14% Pensions Contribution
• 29 Days Annual Leave + Bank Holidays
• Free Company Shares

Interviews ongoing don't miss your chance to secure a role working with cutting edge technology while maintaining exceptional work-life balance.

Contact me @ j.shaw-bollands@tenthrevolution.com or on 0191 338 6641.

Data Engineer, Snowflake, Cloud, ETL, Analytics, SQL, Python, AWS, Terraform, DevOps, end-to,end",j.shaw-bollands@tenthrevolution.com,,False,,,fulltime,https://www.jeffersonfrank.com/job/a0M1i00000X3lil.1_1737456842/senior-data-engineer-snowflake-100000-london-hybrid?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,"Senior Data Engineer - Snowflake - £100,000 - London - Hybrid"
NHS Jobs,,1737417600000,"To read more information about the advertised role, and the main job duties/responsibilities please open the Job Description and Person Specification located under the supporting documents heading. You can also read more information about working at the Northern Care Alliance within the attached Candidate Information Pack or by visiting our careers website: http://www.careers.northerncarealliance.nhs.uk",,,False,,,fulltime,https://findajob.dwp.gov.uk/details/15920457?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Salford,,,Senior Data Engineer
FJN Solutions,,1737417600000,"Job Title: Data Engineering Architect

Location: London Bridge - Hybrid (2-3 days per week)

About Them:

Our client are a newly launched personal lines Insurtech start-up, backed by a well-known and loved UK retail group. Their mission is to redefine the personal insurance experience through data-driven innovation and advanced technology. As an early-stage start-up, they are building their foundation and are looking for a talented Data Engineering Architect/Principal Engineer to play a critical role in shaping their data infrastructure and strategy.

Role Overview:

As the Data Engineering Architect/Principal Engineer, you will take ownership of designing and implementing a scalable, robust data architecture to support our clients cutting-edge insurance platform. You will be instrumental in building a strong data foundation, ensuring seamless integration of data pipelines, and driving the use of data as a strategic asset. This role combines hands-on technical expertise with strategic architectural responsibilities in a fast-paced, start-up environment.

Key Responsibilities:

· Design and Implement: Scalable, high-performance data architecture for the platform.

· Build and Optimise: Data pipelines, ensuring the efficient collection, transformation, and storage of data.

· Drive Best Practices: In data engineering, including data quality, security, and governance.

· Collaborate: With cross-functional teams to align data architecture with business and technical goals.

· Lead Selection and Integration: Of tools, frameworks, and technologies to support data initiatives.

· Provide Hands-On Technical Leadership: Continuously evaluate and improve existing data systems, ensuring scalability and reliability as the company grows.

· Adaptability: Be comfortable navigating the challenges of an early-stage start-up and contribute to a culture of adaptability and collaboration.

Technical Proficiency:

· Database Design: Deep understanding of database design principles, including SQL and NoSQL databases.

· Data Modelling: Proficiency in creating conceptual, logical, and physical data models.

· Data Warehousing: Knowledge of data warehousing and ETL (Extract, Transform, Load) processes.

· Big Data Technologies: Familiarity with big data technologies like Hadoop, Spark, and cloud storage solutions.

· Data Integration: Skills in integrating data from various sources to create a cohesive dataset.

· Data Security: Implementing robust security measures to protect data integrity and privacy.

Skills & Experience:

· Extensive Experience: In data engineering, including building and maintaining scalable data systems.

· Proven Experience: In designing data architectures for complex platforms.

· Expertise: In data pipeline tools, ETL processes, and database technologies.

· Programming Skills: Strong programming skills, ideally in Python or other relevant languages.

· Cloud-Based Solutions: Experience with cloud-based data solutions, with a preference for Azure or similar platforms.

· Data Governance: Knowledge of data governance, security, and compliance best practices.

· Modern Data Frameworks: Familiarity with modern data frameworks, such as Apache Spark, Kafka, or similar tools.

· Problem-Solving: Excellent problem-solving skills and a proactive, hands-on approach to challenges.

· Start-up Experience: Previous experience in an early-stage start-up or dynamic, fast-paced environment is highly desirable.

Qualifications:

· Education: Bachelor's or master’s degree in Computer Science, Software Engineering, or a related field.

· Experience: Proven experience as a Data Engineering Architect, Principal Engineer, or similar role with a track record of successful architectural designs.

· Technical Skills: Proficiency in architectural frameworks, design patterns, and technologies such as data architecture, Microsoft data platforms, ESBs, and microservices architecture.

· Certifications: Relevant industry certifications such as TOGAF, Certified Data Architect, etc.

Why Join?

· Impact: Be part of a ground breaking Insurtech venture with the backing of a large, established retail group.

· Pivotal Role: Play a key role in defining and building our data strategy from the ground up.

· Collaboration: Work with a talented team in a hybrid work environment.

· Competitive Package: Competitive salary and benefits, along with opportunities for career growth.

If you’re a data engineering expert with a passion for creating transformative solutions in a start-up environment, we’d love to hear from you! Apply now to join our journey and make a meaningful impact in the world of insurance.",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/fjn-solutions/fjn-solutions-data-engineering-architect-696720/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,FJN Solutions | Data Engineering Architect
Optima Dev,,1737417600000,"You’ll probably be the kind of Engineer who loves rolling up their sleeves, and still getting stuck into coding. You’ll probably like the sound of having no legacy tech to worry about – and you’re probably looking for the chance to actually influence decisions.

Well, this is the role for you.

You’d be joining a team who’ve built their data infrastructure from scratch over the last few years. Even better, they’re having no issues and things are going well – but they don’t want to stand still.

But as they’re continuing to grow, they’re looking to take it to the next level and make their infrastructure more mature – so you’ll come in to help with reliability and stability.

They already have plans to form a Central Data Hub (which you’ll play a big part in) – and establishing a larger data mesh.

Your focus will be on all things data processing within Databricks, ingestion pipelines, and DataOps/DevOps.

Tech wise, you’d surround yourself with PySpark/Python, Azure, Kubernetes, Terraform and IaaC. Of course, you’ll ideally have exposure with most of it.

As it stands, their Data team is only small – just one other Data Engineer at the mo. So you’ll get the chance to put your own stamp on things, and take ownership of your own work.

Salary wise, they’ll pay anywhere from £70,000-£82,000 DOE. It’s majority remote – heading into Oxford once every couple of months or so.

They can interview this side of Christmas too.

Get in touch with Jack Leeming @ Optima Dev for a chat.

You need to be UK-based, and they can't offer sponsorship.",,,True,,,fulltime,https://talents.studysmarter.co.uk/companies/optima-dev/optima-dev-senior-data-engineer-95-remote-695912/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Leeds,,,Optima Dev | Senior Data Engineer (95% Remote)
Accenture UK & Ireland,,1737417600000,"Job Title: Data Engineer, Associate Manager CL8

Locations: London/Bristol/Manchester

Salary: Competitive salary and package (Depending on level of experience)

Please Note: Any offer of employment is subject to satisfactory BPSS and SC security clearance which requires 5 years continuous UK address history at the point of application.

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. With our thought leadership and culture of innovation, we apply industry expertise, diverse skill sets and next-generation technology to each business challenge.

We believe in inclusion and diversity and supporting the whole person. Our core values comprise of Stewardship, Best People, Client Value Creation, One Global Network, Respect for the Individual and Integrity. Year after year, Accenture is recognised worldwide not just for business performance but for inclusion and diversity too.

“Across the globe, one thing is universally true of the people of Accenture: We care deeply about what we do and the impact we have with our clients and with the communities in which we work and live. It is personal to all of us.” – Julie Sweet, Accenture CEO

Key Responsibilities
• Implement ETL pipelines and orchestrate data flows using batch and streaming technologies based on software engineering best practice
• Define, document and iterate data mappings based on concepts and principles of data modelling
• Re-engineer data pipelines to be scalable, robust, automatable, and repeatable
• Navigate, explore and query large scale datasets
• Build processes supporting data transformation, data structures, metadata, dependency and workload management
• Identify and resolve data issues including data quality, data mapping, database and application issues
• Implement data flows to connect operational systems, data for analytics and business intelligence (BI) systems
• Deliver high quality implementation and documentation for critical functionality
• Deliver code, unit tests, feature tests, stubs and integration tests.
• Operate in an agile environment as part of a scrum team and participate in sprint rituals
• Work with team members to understand designs, functional requirements and triage issue

Qualifications

We have a number of opportunities available from junior to senior level and we are looking for data engineers who have a variety of different skills which include some of the below.
• Strong proficiency in at least one programming language (Python, Java, or Scala)
• Extensive experience with cloud platforms (AWS, GCP, or Azure)
• Experience with:
• Data warehousing and lake architectures
• ETL/ELT pipeline development
• SQL and NoSQL databases
• Distributed computing frameworks (Spark, Kinesis etc)
• Software development best practices including CI/CD, TDD and version control.
• Strong understanding of data modelling and system architecture
• Excellent problem-solving and analytical skills

Whilst having experience in a consultancy is beneficial, demonstrable experience in working with clients/external partners in other settings will always be considered.

What’s In It For You

At Accenture in addition to a competitive basic salary, you will also have an extensive benefits package which includes 25 days’ vacation per year, private medical insurance and 3 extra days leave per year for charitable work of your choice!

Flexibility and mobility are required to deliver this role as there will be requirements to spend time onsite with our clients and partners to enable delivery of the first-class services we are known for.

About Accenture

Accenture is a leading global professional services company, providing a broad range of services in strategy and consulting, interactive, technology and operations, with digital capabilities across all of these services. We combine unmatched experience and specialised capabilities across more than 40 industries — powered by the world’s largest network of Advanced Technology and Intelligent Operations centres.

With 509,000 people serving clients in more than 120 countries, Accenture brings continuous innovation to help clients improve their performance and create lasting value across their enterprises. Visit us at www.accenture.com

Accenture is an equal opportunities employer and welcomes applications from all sections of society and does not discriminate on grounds of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, or gender identity, or any other basis as protected by applicable law.

Closing Date for Applications 31st March 2025

Accenture reserves the right to close the role prior to this date should a suitable applicant be found.",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-associate-manager-at-accenture-uk-ireland-4129228435?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,"Data Engineer, Associate Manager"
BJSS,,1737417600000,"About Us

We’re an award-winning innovative tech consultancy - a team of creative problem solvers. Since 1993 we’ve been finding better, more sustainable ways to solve complex technology problems for some of the world’s leading organisations and delivered solutions that millions of people use every day.

In the last 30 years we won several awards, including a prestigious Queen’s Award for Enterprise in the Innovation category for our Enterprise Agile delivery approach.

Operating from 26 locations across the world, we bring together teams of creative experts with diverse backgrounds and experiences, who enjoy working and learning in our collaborative and open culture and are committed to world-class delivery.

We want to continue to grow our team with people just like you!

About the Role

We are DataOps advocates and use software engineering best practices to build scalable and re-usable data solutions to help clients use their data to gain insights, drive decisions and deliver business value. Clients don’t engage BJSS to do the straightforward things, they ask us to help on their biggest challenges which means we get to work with a wide range of tools and technologies and there are always new things to learn.

BJSS data engineers are specialist software engineers that build, optimise and maintain data applications, systems and services. This role combines the discipline of software engineering with the knowledge and experience of building data solutions in order to deliver business value.

As a BJSS data engineer you’ll help our clients deploy data pipelines and processes in a production-safe manner, using the latest technologies and with a DataOps culture.

You’ll work in a fast moving, agile environment, within multi-disciplinary teams of highly skilled consultants, delivering modern data platforms into large organisations.

You can expect to get involved in variety of projects in the cloud (AWS, Azure, GCP), learning about and using data services such as Databricks, Data Factory, Synapse, Kafka, Redshift, Glue, Athena, BigQuery, S3, Cloud Data Fusion etc.

About You
• You're an engineer at heart and enjoy the challenge of building reliable, efficient data applications systems, services and platforms.
• You have a good understanding of coding best practices and design patterns and experience with code and data versioning, dependency management, code quality and optimisation, error handling, logging, monitoring, validation and alerting.
• You have experience in writing well tested object-oriented Python.
• You have experience with using CI/CD tooling to analyse, build, test and deploy your code.
• You have a good understanding of design choices for data storage and data processing, with a particular focus on cloud data services.
• You have experience in using parallel computing to process large datasets and to optimise computationally intensive tasks.
• You have experience in programmatically deploying, scheduling and monitoring components in a workflow.
• You have experience in writing complex queries against relational and non-relational data stores.

Some of the Perks
• Flexible benefits allowance – you choose how to spend your allowance (additional pension contributions, healthcare, dental and more)
• Industry leading health and wellbeing plan - we partner with several wellbeing support functions to cater to each individual's need, including 24/7 GP services, mental health support, and other
• Life Assurance (4 x annual salary)
• 25 days annual leave plus bank holidays
• Hybrid working - Our roles are not fully remote as we take pride in the tight knit communities we have created at our local offices. But we offer plenty of flexibility and you can split your time between the office, client site and WFH
• Discounts – we have preferred rates from dozens of retail, lifestyle, and utility brands
• An industry-leading referral scheme with no limits on the number of referrals
• Flexible holiday buy/sell option
• Electric vehicle scheme
• Training opportunities and incentives – we support professional certifications across engineering and non-engineering roles, including unlimited access to O’Reilly
• Giving back – the ability to get involved nationally and regionally with partnerships to get people from diverse backgrounds into tech
• You will become part of a squad with people from different areas within the business who will help you grow at BJSS
• We have a busy social calendar that you can choose to join– quarterly town halls/squad nights out/weekends away with families included/office get togethers
• GymFlex gym membership programme",,,True,,,fulltime,https://talents.studysmarter.co.uk/companies/bjss/bjss-data-engineer-694344/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Swansea,,,BJSS | Data Engineer
Bits,,1737331200000,"About Bits:
Bits is a fast-growing fintech startup based in London. We are dedicated to promoting financial inclusion and providing credit building solutions to individuals who have been overlooked by mainstream lenders. With the support of renowned investors, we have quickly gained traction and currently serve over 300,000 customers across the UK.

About the Role:
We are seeking a Senior Data Engineer to join our team. As our first data engineer, you will play a crucial role in scaling our data infrastructure and enabling real-time, data-driven decision-making. Your primary responsibility will be designing and maintaining robust NoSQL database solutions that can handle high transaction volumes, providing low-latency, high availability, and ensuring smooth integration with our applications. You'll work closely with our engineering team to create data solutions that help us provide seamless services to our users.

Responsibilities:

Build our data foundation: Lead the design, development, and optimization of NoSQL databases (e.g. DynamoDB) to handle large volumes of data from multiple sources (e.g. customer applications, credit card transactions).
Data-driven decision-making: Enable real-time and batch processing of customer and credit data to support product development, risk management, and responsible lending decisions.
Collaborate across teams: Work closely with product, risk management, customer service, and compliance teams to ensure that data is available, clean, and actionable for business operations.
Optimize and scale: Build systems that scale with Bits' growth as we expand our customer base and data complexity, optimizing for performance, cost, and efficiency.
Data governance and security: Ensure data systems comply with regulatory requirements (e.g., GDPR) and uphold data privacy and security best practices.
Support risk and underwriting: Develop tools and processes to streamline data access for our underwriting team, providing them with accurate and timely data for credit risk assessments.
Automation and reporting: Work on automation of key data workflows and support data analytics teams by ensuring self-service capabilities for business intelligence reporting.
Be a key decision-maker: As a founding engineer, you will have significant input into the architecture, technology stack, and data strategy.
Requirements

Bachelor's degree in Computer Science, Information Technology, or a related field.
3+ years of experience in designing scalable, robust relational and non-relational database architectures
Hands-on experience with cloud platforms (e.g., AWS, GCP, Azure) and big data technologies (e.g., Hadoop, Spark, Kafka).
Proficient in SQL , but also highly skilled in non-relational database querying and manipulation.
Experience with ETL frameworks that handle both real-time and batch processing.
Programming proficiency in languages like Python or Java for data processing tasks and automation.
Expertise in data security , encryption, and handling compliance requirements
Strong communication skills and the ability to work collaboratively in a fast-paced environment.ring, or a related field.
Prior experience in the FinTech industry is a plus.
Nice-to-haves:

Experience in the fintech industry or a deep understanding of credit-building
products.
Experience with business intelligence BI tools like Looker, Omni, or similar
Familiarity with machine learning pipelines and model deployment.
Benefits
• A competitive market salary
• 28 days holidays/ year incl. UK/ England public & bank holidays
• Free fruit in the office
• Regular team meals",,,False,,,fulltime,https://uk.jooble.org/rjdp/555494822724753863?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,"(Senior) Data Engineer (ML, Big Data)"
Optima Dev,,1737331200000,"You’ll probably be the kind of Engineer who loves rolling up their sleeves, and still getting stuck into coding. You’ll probably like the sound of having no legacy tech to worry about – and you’re probably looking for the chance to actually influence decisions.

Well, this is the role for you.

You’d be joining a team who’ve built their data infrastructure from scratch over the last few years. Even better, they’re having no issues and things are going well – but they don’t want to stand still.

But as they’re continuing to grow, they’re looking to take it to the next level and make their infrastructure more mature – so you’ll come in to help with reliability and stability.

They already have plans to form a Central Data Hub (which you’ll play a big part in) – and establishing a larger data mesh.

Your focus will be on all things data processing within Databricks, ingestion pipelines, and DataOps/DevOps.

Tech wise, you’d surround yourself with PySpark/Python, Azure, Kubernetes, Terraform and IaaC. Of course, you’ll ideally have exposure with most of it.

As it stands, their Data team is only small – just one other Data Engineer at the mo. So you’ll get the chance to put your own stamp on things, and take ownership of your own work.

Salary wise, they’ll pay anywhere from £70,000-£82,000 DOE. It’s majority remote – heading into Oxford once every couple of months or so.

They can interview this side of Christmas too.

Get in touch with Jack Leeming @ Optima Dev for a chat.

You need to be UK-based, and they can't offer sponsorship.",,,True,,,fulltime,https://talents.studysmarter.co.uk/companies/optima-dev/optima-dev-senior-data-engineer-95-remote-674254/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Ashton-under-Lyne,,,Optima Dev | Senior Data Engineer (95% Remote)
Playtech,,1737244800000,"Company Description

About Playtech

Founded in 1999, the company has a premium listing on the Main Market of the London Stock Exchange and is focused on regulated and regulating markets across its B2B and B2C businesses. Both divisions leverage Playtech’s proprietary technology to deliver innovative products and services to ensure a safe, engaging and entertaining betting and gaming experience.

Playtech is the gambling industry's leading technology company delivering business intelligence-driven gambling software, services, content, and platform technology across the industry's most popular product verticals, including, casino, live casino, sports betting, bingo and poker. Read more about who we are and what we do here: www.playtech.com & www.playtechpeople.com

Here at Playtech, we genuinely believe that people are our biggest asset. Diverse thoughts, experiences, and individual characteristics enrich our work environment and lead to better business decisions. Recognizing differences and ensuring our processes are transparent is the core of Playtech’s overall commitment to responsible business practices.

Ready to level up your career?

Playtech’s land-based gaming unit is looking for a talented Support Engineer with a specialism in data engineering. You will be working as part of a product support team delivering and supporting a suite of modern applications for our customers globally. The data specialism provides the opportunity to focus on supporting the data layers (including OLTP databases, OLAP databases, data warehouses) used by our customers as part of the Neon Casino Management System.

Job Description

Your influential mission. You will…
• Identify, analyse, and resolve data-related issues to improve data reliability and maintain data integrity for a large global customer base
• Plan and execute data migrations between disparate systems
• Install, upgrade, and maintain applications, services, and databases
• Ensure data security and compliance with industry regulations and best practices
• Proactively identify opportunities for data architecture improvements and implement changes to optimize system performance and scalability
• Stay up to date with the latest data engineering trends, technologies, and best practices to ensure that our data infrastructure remains cutting-edge and efficient.
• Mentor and provide guidance to junior data team members, fostering a culture of continuous learning and improvement.

Qualifications

Components for success. You…
• Have 2+ years of experience supporting complex data-driven business applications
• Have excellent knowledge supporting Microsoft SQL Server 2016+ database deployments, including knowledge of installation, querying (T-SQL), stored procedures, SQL Agent, data manipulation, replication, and maintenance tasks (backup, restore, etc.)
• Have experience with query optimization and data analysis using Excel
• Have experience with data-quality monitoring and database performance monitoring and optimization.
• Possess high problem-solving and analytical skills, with a keen attention to detail
• Are someone who works well with other people and is committed to the cause

You’ll get extra points for…
• Experience in the gaming industry
• Experience with SQL Server Analysis Services (SSAS), SQL Server Integration Services (SSIS), and SQL Server Reporting Services (SSRS)
• Have good knowledge of Windows Server 2016+ and PowerShell
• Experience with PowerBI
• Knowledge of data warehouse modelling (e.g. Kimball, star schema etc.)
• Experience with Microsoft Azure, Amazon Web Services or Google Cloud Platform
• Having experience with source code control and Agile workflows.
• Your excellent spoken and written communication skills in English, allowing you to deliver complex information clearly to your colleagues
• Foreign languages particularly French or Spanish

Thrive in a culture that values…
• Empowerment, support, and mentoring
• Constant learning and development opportunities
• An active lifestyle and mental well-being
• Fun company events

Additional Information

HOW TO APPLY?

In addition to your CV, please add a brief motivation letter covering your goals, your current experience as a Technical Support Engineer in your industry, etc. You can write it in the comment section at the end of the application page (under ""your message to the hiring manager"").

Playtech is an equal opportunities employer. Our mission is to welcome everyone and create inclusive teams. We celebrate differences and encourage everyone to join us and be themselves at work.",,,False,,,fulltime,"https://www.glassdoor.co.uk/job-listing/support-engineer-data-playtech-JV_IC2691218_KO0,21_KE22,30.htm?jl=1009571851279&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic",,,Manchester,,,Support Engineer - Data
Oliver Bernard,,1737158400000,"Location: London, N5 1RA Working Arrangements: Hybrid, 2-3 days p/w in office Salary: £80,000 - £100,000 Industry: Marketing/Advertising Tech Stack: Python, SQL, GCP Great opportunity for a talented Engineer (Python, SQL, GCP) to join a market analytics platform. The Company Global marketing and analytics platform that focus on providing data driven insights to international clients and customers. The Role They are seeking a highly pragmatic Engineer (Python, SQL, GCP) to help build their data platform as they go through a period of business growth. You (Python, SQL, GCP) will work closely with the analytics team to build platforms that can be used to provide business critical insights. The ideal candidate (Python, SQL, GCP) will be comfortable working both individually and as part of a team and liaise with other teams within the business and external vendors. Desired Skills ️ Python SQL (SQL Server, Azure SQL), NoSQL Apache Airflow, Kubernetes Kafka, Spark GCP Benefits Quarterly bonuses Private Health Care Training programmes Annual off-sites If you are a skilled engineer (Python, SQL, Spark, Azure) who is interested in this role then please apply below and I will be in touch with more details.",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/oliver-bernard/senior-data-engineer-gcp-656624/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Senior Data Engineer – GCP
Forward Role,,1737072000000,"Candidates MUST be DV or eDV Cleared - be a bristish citizen and lived in the UK for the past 10 years.

£50,000 - £100,000 + Bonus

Manchester, Surrey, Cheltenham or Southampton

My client is seeking a passionate and innovative Data Engineer to join a high-performing team focused on delivering advanced technical solutions for critical data services within the National Security sector. This role offers the chance to contribute to meaningful projects that address some of the most complex and sensitive challenges in the field.

As a Data Engineer, you will design and manage robust data pipelines that transform raw data into actionable insights. Working with huge diverse datasets coming from a variety of sources in many forms, predominantly very unstructured - you will apply cutting-edge distributed computing techniques to support downstream analytics and reporting.

Key Responsibilities
• Develop and optimize ETL/ELT workflows to efficiently transfer data from source systems to data repositories.
• Work with a variety of modern tools and technologies such as Apache Kafka, NiFi, Spark, Flink, or Airflow to streamline data processing.
• Leverage your expertise in both SQL and NoSQL databases (e.g., PostgreSQL, MongoDB, Elasticsearch, Accumulo, Neo4j).
• Write high-quality code using modern programming languages like Python, Java, or Go to solve complex technical challenges.
• Utilise distributed computing techniques to handle and analyse large-scale datasets.

About You

As a Data Engineer, you will be a proactive problem solver with a passion for harnessing data to drive critical insights. You bring experience in the development and management of incredibly complex data ecosystems and have a strong understanding of the technologies shaping this field. The successful candidate will be passionate about the impact of their work.

This is your chance to work with a high-growth, leading organisation that values technical excellence and innovation. You’ll collaborate closely with clients in the National Security sector, addressing unique challenges with tailored solutions.

As an industry leading, nationwide Marketing, Digital, Analytics, IT and Design recruitment agency, we are continually receiving new assignments to work on, so keep a close eye on our website, Facebook, LinkedIn and Twitter pages for a full list of current permanent and interim opportunities as well as marketplace news and fun stuff.

Forward Role is operating as an employment agency.",,,False,,,fulltime,https://www.forwardrole.com/jobs/84983dataengineerdvcleared?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Manchester,,,Data Engineer - DV CLEARED
Change Digital,,1737072000000,"Are you an experienced Data Engineer ? Do you have extensive Informatica skills ? Have you worked with Snowflake and AWS ? Would you like to work for a fast growing business that specialises in Business Intelligence & Data Analytics ? Its a hybrid working role and you will be based from either their London, Leeds, Manchester or Edinburgh office, typically 3 days a week from home and 2 day in office / on client site. To be considered for the role you must have experience working in the financial services sector, be it direct or through consultancy. **Visa sponsorship is not provided** Your skills and attributes: * An excellent team player and able to work independently. * Excellent client facing skills. * A self-starter who is proactive in nature. * Excellent verbal, written communication, and presentational skills. * Ability to build internal and external relationships. * Effective negotiating and influencing skills. * Ability to think creatively and propose innovative solutions. * Strong self-developer. * Leadership skills. Skills: * Informatica: Extensive hands-on experience with Informatica, including building and managing ETL pipelines. * Cloud Integration: Experience with cloud integration using AWS * ETL Processes: Proven ability in developing optimal and reliable ETL processes ingested from a wide variety of data sources, both structured and unstructured. Snowflake experience is required. * Data Transformation: Strong skills in data transformation, data cleansing, and data mapping using Informatica Cloud tools. * SQL: Advanced working knowledge in SQL and relational databases (e.g., Microsoft SQL Server, Oracle). * Data Warehousing: Experience in data warehousing, including data modeling and implementing data pipelines. * Data Management: Multi-skilled experience in Data Management, Data Integration, Data Quality, and Data Analytics. * Agile Methodologies: Experience working within Agile, Scrum, or DevOps environments. * Technical Business Analysis: Ability to translate business requirements into technical solutions. For more information get in touch asap",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/change-digital/data-engineer-informatica-646660/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer – Informatica
HippoDigital,,1736985600000,"About The Role
Hippo is recruiting for a Principal Data Engineer to join our Hippo Herd. Principal Data Engineers work in multi-disciplinary teams that build, support & maintain User-Centred digital solutions that offer real value and work for everyone.

Hippo’s Principal Data Engineers are experts in their field. You will act as a principal consultant providing technical expertise in data engineering practices both internally and to our clients. You will drive the team's technical deliverables, maintain client relationships and be passionate about developing and upskilling others.

Your role in nutshell:
• Act as a technical SME within the Hippo engineering community to produce and ensure user-centred software is developed based on business requirements and following best practice
• Work collaboratively with colleagues to explore, design and deliver solutions to client problems
• Maintain client relationships and troubleshoot issues through collaboration
• Design and manage software development and deployment pipelines resolving issues and potential bottlenecks before they occur
• Continuously reviews and prioritises the delivery teams workload and can anticipate the need for realignment with evolving operational prioritise and complex work-streams and assignments
• Be a strong communicator and presenter, presenting prototypes, solutions and progress to internal/external stakeholders in a clear concise manner
• Build great relationships with your team and stakeholders, identifying and ensuring that challenges are overcome
• Lead in the recruitment of other engineers, and support other consultants in their professional development
• Ensure Hippo’s Data and Engineering communities contribute to Hippo’s business at a strategic level
• Lead on new business opportunities, writing technical bids and proposals
• Promote Hippo’s Data Herd externally (for example through writing Blogs, Workshops, Seminars or Conferences)

Skills and experience that you need
• Excellent experience delivering in Python and experience with at least one other core language
• Excellent experience of SQL and relational databases. NoSQL databases is also desirable.
• Solid experience of at least one Cloud provider such as AWS, Azure or GCP.
• Preference will be given on candidates with strong Azure Cloud and general Microsoft Technology Stacks (e.g. MS SQL and .Net frameworks)
• Strong experience of working with different data formats, e.g., CSV, JSON and XML
• Building reliable Data Pipelines
• Broader knowledge of IT — e.g., Security and Networking
• Working in an Agile Environment
• Test-Driven Development and/or Behaviour Driven Development
• Continuous Integration and Continuous Deployment (CI/CD)
• Experience of operating as a technical leader on complex projects and able to manage stakeholder expectations and influencing decisions
• Coaching and guiding others on the best way to achieve an optimal solution
• Excellent verbal/written communication skills, able to articulate in both technical/non-technical terms depending on audience
• Technical leadership and/or mentoring
• Define working procedures and methodologies for the team

What makes us great
As well as a competitive salary which we’re transparent about from the outset, you can also expect a range of benefits:
• Contributory pension scheme (Hippo 6% with employee contributions of 2%)
• 25 days holiday plus UK public holidays
• Perkbox access for a wide range of discounts
• Critical illness cover
• Life assurance and death in service cover
• Volunteer days
• Cycle-to-work scheme for the avid cyclists
• Salary sacrifice electric vehicles scheme
• Season ticket loans
• Financial and general wellbeing sessions
• Flexible benefits scheme with options of:
• private health cover
• private dental cover
• additional company pension contributions
• additional holidays (up to an extra 2 days)
• wellbeing contribution
• charity contributions
• tree planting

Diversity, Inclusion and Belonging at Hippo
At Hippo, we’re dedicated to creating a diverse, equitable and inclusive workplace that works for everyone. We understand that having a diverse team unlocks our capacity for innovation, creativity and problem solving. Only by building a community of diverse perspectives, cultures and socio-economic backgrounds can we create an environment where all can contribute and thrive.

We actively encourage applications from underrepresented groups including women, ethnic minorities, LGBTQ+, neurodivergent and people with disabilities. We are committed to providing an inclusive and accessible recruitment process that reflects our workplace culture. We are a registered Disability Confident Employer, Mindful Employer, Endometriosis Friendly Employer and a member of the Armed Forces Covenant. Hippo continually strives to remove barriers, provide accommodations and offer reasonable adjustments to ensure equity throughout our practices.

Hi, we’re Hippo.

At Hippo, we design with empathy and build for impact. We do this by combining data-informed evidence, human-centred design and software engineering. We're a digital services partner who is genuinely invested in helping our clients thrive as modern organisations. Our delivery methodology is truly agile, from concept to reality, supporting innovation and continuous improvement to achieve your desired outcomes.

We firmly believe that technology should serve humanity, not the other way around. We take a human-centred approach to everything we do because we understand that complex problems require a service design approach. This means understanding how users behave and ensuring our solutions work for them in the real world.

Our combination of data, design, and engineering delivers bespoke digital services that make a positive and meaningful impact on organisations and society. We're confident in our abilities, authentic in our approach, and passionate about what we do. If you're looking for a digital services partner that can deliver real results, let us help you build for the future and make a lasting impact.

Hippo locations
We are headquartered in Leeds and located across the UK in Edinburgh, Manchester, Birmingham, London and Bristol. We're on the lookout for top talent nationwide, so don't let location hold you back from applying. We welcome candidates from all over the UK who possess the flexibility to work from any of our locations. Plus, we offer a generous relocation support package of up to £8k to help make your move a smooth one. It's worth noting that, given the dynamic nature of our business, you may be required to work on-site at client locations or from your own home.

Job Type: Full-time

Pay: £79,000.00-£100,000.00 per year

Schedule:
• Monday to Friday

Work Location: Hybrid remote in Birmingham B5 4TB",,,True,,,fulltime,https://www.simplyhired.co.uk/job/QQvIK_TGoqZdBoDh3UBnSR9o0WPNLrmjpEXiY1DxW1og6sp38UL-bQ?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Birmingham,,,Principal Data Engineer
Noir,,1736985600000,"Data Engineer - Leading Travel Company - Bristol

(Tech Stack: Data Engineer, Databricks, Python, Power BI, AWS QuickSight, Azure, AWS, TSQL, ETL, Agile Methodologies)

About the Company: Our client, a leading company in the travel industry, is seeking a talented Data Engineer to join their dynamic team in Bristol. This is a hybrid role, offering a blend of remote and in-office work, providing flexibility while maintaining a collaborative team environment.

Key Responsibilities:
• Maintain and optimise on-premises SQL Server data warehouses with a focus on stored procedures, indexing, partitioning, and load performance.
• Utilise Azure cloud tools including Azure Synapse Analytics, Azure Data Lake, Azure Data Factory, and Logic Apps for effective data management.
• Leverage hands-on experience with Microsoft Fabric or similar modern cloud platforms, emphasising data migration strategies and ETL development.
• Develop advanced SQL queries, stored procedures, and Python scripts for data manipulation, pipeline development, and automation.
• Design and optimise ETL processes and data pipelines using both on-premise tools like SSIS and cloud-based solutions like Azure Data Factory.
• Create and manage Power BI Premium reports, including data modeling, DAX, performance tuning, and advanced features such as composite models and incremental refresh.
• Implement data governance and security best practices, ensuring compliance with GDPR and other relevant regulations.
• Collaborate within an Agile framework, contributing to sprint planning, reviews, and retrospectives.
• Communicate effectively with stakeholders, translating complex data concepts into actionable insights and recommendations.

Essential Knowledge, Skills, and Experience:
• Extensive Data Warehouse Experience: Proven expertise in maintaining and optimizing SQL Server data warehouses, with a strong focus on stored procedures, indexing, partitioning, and load performance.
• Proficiency in Azure Cloud Tools: In-depth knowledge of Azure Synapse Analytics, Azure Data Lake, Azure Data Factory, and Logic Apps.
• Experience with Microsoft Fabric: Hands-on experience with Microsoft Fabric or similar platforms, particularly in data migration and ETL development.
• Advanced SQL and Python Skills: High-level proficiency in writing advanced SQL queries, stored procedures, and Python scripts for data manipulation and automation.
• ETL and Data Pipeline Expertise: Strong experience in designing and managing ETL processes using both on-premises tools like SSIS and cloud-based solutions like Azure Data Factory.
• Power BI Premium Expertise: Advanced skills in Power BI Premium, including data modeling, DAX, performance tuning, and utilizing advanced features like composite models and incremental refresh.
• Strong Understanding of Data Governance and Security: Comprehensive knowledge of data governance principles, security best practices, and compliance with GDPR and other regulations.
• Agile Methodology Experience: Demonstrated experience working within Agile teams and contributing to various Agile processes.
• Effective Stakeholder Communication: Excellent communication skills, with the ability to convey complex technical concepts to non-technical stakeholders clearly and effectively.

Benefits:
• Competitive salary
• Hybrid working model
• Opportunities for professional development
• Collaborative and innovative work environment

Location: Bristol, UK / Remote Working

Salary: £45,000 - £55,000 + Bonus + Pension + Benefits

Applicants must be based in the UK and have the right to work in the UK even though remote work is available.

To apply for this position please send your CV to Matt Jones at Noir.

NOIRUKTECHREC

NOIRUKREC

NC/RG/DE",,,True,,,fulltime,https://www.reed.co.uk/jobs/data-engineer-leading-travel-company-bristol/54324951?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Bristol,,,Data Engineer - Leading Travel Company - Bristol
Roke,,1736985600000,"As a Data Engineer, you’ll be actively involved in development of mission critical technical solutions that focus on data services for our National Security customers.
Roke are a leading technology & engineering company with clients spanning National Security, Defence and Industry . You will work alongside our customers to solve their complex and unique challenges.
As our next Data Engineer, you’ll be managing and developing data pipelines that transform raw data into valuable insights for Roke’s National Security customers, enabling downstream analytics and reporting. You’ll be working with diverse data sources (batch, streaming, real-time and unstructured), applying distributed compute techniques to handle large datasets.
The Key Requirements...
• Able to develop Extract, Transform, Load (ETL) or Extract, Load, Transform (ELT) workflows to move data from source systems to date stores
• You will have used one or more supporting technologies i.e. Apache, Kafka, NiFi, Spark, Flink or Airflow etc.
• A history working with SQL and NoSQL type databases (PostgreSQL, Mongo, ElasticSearch, Accumulo or Neo4j etc.)
• You will be able to code using a modern software language such as Python, Java or Go
• Experience of distributed computing techniques.

Built over a 60-year heritage, Roke offers specialist knowledge in sensors, communications, cyber, and AI and ML, and Data Science. We change the way organisations think and act – through dynamic insights from the analysis of multiple layers of data. We take care of the innovative, technical stuff that keeps everyone safe – that’s our mission, passion, and motivation.
Joining a team united by purpose and ambition, you’ll be at the heart of an exciting growth journey: having doubled in size over the last 4 years, we intend to double our headcount by 2027. At Roke, every individual counts. We push technical boundaries, together. We re-invest in product innovation, and we empower our people to make a difference.
Where you’ll work…
You’ll find our Gloucester site in a business park two minutes from junction 11A of the M5; The site allows easy access to our local customer base. Set on the outskirts of the Cotswolds, you are never far from a picturesque view or lunch time walk.
Why you should join us...
We are one Roke. We believe we all have a responsibility to create an environment where we all have the time, trust and freedom to succeed and where we are encouraged to bring our whole self to work. We are committed to a policy of Equal Opportunity, Diversity and Inclusion, enabled by our employee led resource groups of Women In Roke, Neurodiversity, Inspire (LGBT+) and ME (Majority Ethnic), which each contribute to making Roke a great place for people from all backgrounds to work.
Mental health and wellbeing is important to us, and we have a group of supportive Mental Health First Aiders to lend a listening ear for anyone who needs it. We also have a team of Mental Health First Aid Champions who help build a mentally healthy workplace, challenge stigma and support positive wellbeing.
The Benefits and Perks...
• Flexi-time: Working hours to suit you and your life
• Annual bonus: Based on profit share and personal performance
• Private medical insurance: Includes cover for existing conditions
• Holiday: You'll receive competitive annual leave plus bank holidays. We also offer the opportunity to buy and sell annual leave
• Chemring Share Save: Monthly savings into a 3 or 5 year plan.

Clearances…
Due to the nature of this role, we require you to be eligible to achieve DV clearance. As a result, you should be a British Citizen and have resided in the U.K. for the last 10 years.
The Next Step...
Click apply, submitting an up-to-date CV. We look forward to hearing from you.",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-at-roke-4126512828?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Gloucester,,,Data Engineer
Tenth Revolution Group,,1736985600000,"Job Description

Data Engineer - London - Hybrid - £100 - £115k

This is a brand new opportunity to join a leading global company as a data engineer specialising in Snowflake, Python, SQL and/or Oracle. Being at the forefront of data management and analytics is core to my clients investment platform making you an essential part of the team and the business as a whole. This position will play an integral role as the team implements new data management platforms, creates new data ingestion pipelines, and sources new data sets. The role will assist with all aspects of data - from data architecture design to on-going data management

Salary & Benefits
• Highly competitive salary of up to £115k
• Competitive comprehensive medical, dental, retirement and life insurance benefits
• Employee assistance & wellness programs
• Parental and family leave policies
• Tuition assistance & reimbursement
• Quarterly Innovation & Collaboration Awards
• Employee discount program, including access to fitness facilities
• Competitive paid time off
• Continued learning opportunities

Role & Responsibilities
• Execute data architecture and data management projects for both new and existing data sources.
• Transition existing data sets, databases, and code from Oracle to Snowflake.
• Lead analysis of data sets using a variety of techniques such as machine learning.
• Manage end to end data ingestion process and publishing to investing teams.
• Own the process of mapping, standardizing, and normalizing data.
• Ad hoc research on project topics such as vendor trends, usage best practices, big data trends, artificial intelligence, vendors, etc.
• Help transition existing data sets, databases, and code to Snowflake.
• Assess data loads for tactical errors and build out appropriate workflows, as well as create data quality analysis that identifies larger issues in data.
• Actively manage vendors and capture changes in data input proactively.
• Properly prioritize and resolve data issues based on business usage.
• Assist with managing strategic initiatives around big data projects for the commercial (trading) business.
• Partner with commercial teams to gain understanding of current data flow, data architecture, investment process as well as gather functional requirements.
• Assess gaps in current datasets and remediate.

What Do I Need To Apply For The Role
• Bachelor's degree in Computer Science, Mathematics, Physics, Business Intelligence, or related field of study.
• 5+ years of experience in SQL programming, data architecture, and dimension modeling.
• Interest and passion for data architecture, analytics, management, and programming.
• Experience in energy commodities or financial services required.
• Experience in mapping, standardizing, and normalizing data.
• Experience with data integration platforms is preferred, and SnapLogic experience is highly preferred.
• Extensive work experience with ETL/ELT frameworks to write pipelines to load millions of records.
• Advanced skills in writing highly optimized SQL code.
• Experience with relational databases Snowflake or Oracle is preferred.
• Python work experience with Pandas, Numpy and Scikit
• Ability to communicate and interact with a wide range of data users - from very technical to non-technical.
• Team player who is execution focused, with the able to handle a rapidly changing set of projects. and priorities, while maintaining strong professional presence.
• Strong analytics skills with demonstrated attention to details.
• Familiarity with Business intelligence tools Power BI and Tableau.
• Interest or experience in machine learning/Artificial Intelligence is a plus.

My client have very limited interview slots and they are looking to fill this vacancy within the next 2 weeks. I have limited slots for 1st stage interviews next week so if you're interest, get in touch ASAP with a copy of your most recent and up to date CV and email me at m.fox@tenthrevolution.com or you can call me on 0191 300 1232.

Please Note: This is a permanent role for UK residents only. This role does not offer Sponsorship. You must have the right to work in the UK with no restrictions. Some of our roles may be subject to successful background checks including a DBS and Credit Check.

Nigel Frank are the go-to recruiter for Power BI and Azure Data Platform roles in the UK, offering more opportunities across the country than any other. We're the proud sponsor and supporter of SQLBits, Power Platform World Tour, the London Power BI User Group, Newcastle Power BI User Group and Newcastle Data Platform and Cloud User Group. To find out more and speak confidentially about your job search or hiring needs, please contact me directly at m.fox@tenthrevolution.com","m.fox@tenthrevolution.com, m.fox@tenthrevolution.com",,False,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-london-hybrid-%C2%A3100-%C2%A3115k-at-tenth-revolution-group-4124308102?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer - London - Hybrid - £100 - £115k
University of York,,1736899200000,"Looking for a job with a purpose? Make a difference and join our vibrant Research and Faculty IT team.

The University of York has set out its vision to become a University for Public Good in its 2023 strategy. IT Services actively supports that commitment. We're looking for individuals who want to be part of making a difference, using industry-leading technology to support our vision and deliver exceptional services. Working at a learning organisation, we offer a collaborative, flexible environment where growth is supported, teams care for each other, and inquiring minds can thrive.

This is an exciting new role to the Research IT team at the University of York, to support research data management at the University. The role will include elements of Data Engineering, Data Curation, and Data Analysis, with many opportunities to explore and develop the role. Duties will include managing research Data, investigating and resolving data issues.

Research and Faculty IT at the University of York

This post sits in IT Services within the Research IT team, this means you will have the opportunity to be involved in research across the university, as well as contribute to central IT research policy. The team ethos is to provide sustainable, accessible research IT. We are passionate about reducing barriers to access compute for research. We are also passionate about sustainability having recently moved our High Performance Compute Facility to EcoDC in Sweden, significantly reducing our carbon footprint. A part of this role will involve being mindful of the environmental impact of storage at the University. If you are passionate about the environment, accessible compute and research IT this could be the job for you.

The role will include elements of Data Engineering, Data Curation, and Data Analysis, with many opportunities to explore and develop the role. Duties will include managing research Data, investigating and resolving data issues. You will be responsible for working with various Data management tools to improve and streamline research Data management for academics. You will have the opportunity to engage with academic staff and students, library services and IT Services, working across different research groups that traverse multiple disciplines.

We are looking for people who have:
• Enthusiasm to support research within a University environment
• Experience of supporting data management within a University environment.
• Good customer service skills
• A passion for new technologies and how they can enhance research and teaching at the university.

Please see the attached job description for the full list of essential and desirable criteria.

Salary and benefits
• £36,924 - £45,163
• Hybrid working with a minimum one day on site (between home & office)
• 30 days annual leave (38 including bank holidays)
• Excellent pension (with a significant defined benefit element and a very generous employer contribution)

See our employee benefits page for the full package of optional benefits and special offers.

Interview date: To be confirmed

Find out more

If you would like to learn more about the role, please contact Philip Harrison at philip.harrison@york.ac.uk

The University strives to be diverse and inclusive – a place where we can ALL be ourselves.

We particularly encourage applications from people who identify as Black, Asian or from a Minority Ethnic background, who are underrepresented at the University.

We offer family friendly, flexible working arrangements, with forums and inclusive facilities to support our staff. #EqualityatYork",philip.harrison@york.ac.uk,,False,,,fulltime,https://www.simplyhired.co.uk/job/fVmqedebt3lB8MP4PXxZqAs6_kx6kw0i8WIPnqp64iubzq4fKvWKQA?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,England,,,Research IT Data Engineer
Harrington Starr,,1736812800000,"Senior Data Engineer | Innovative Fintech Startup | Bristol/London/Remote | £70,000 - £80,000

We have a Senior Data Engineer opening for a disruptive fintech startup who are changing the landscape when it comes to investor technologies.

This position can be operated remotely but will also require attendance to the Bristol office once a month for a company get together. For those who enjoy in office collaboration, you are welcome to work from the London or Bristol offices whenever you like.

All candidates must have the right to work in the UK for this position.

What are we looking for?
• Designing, implementing and maintaining automated data pipelines using Python and AWS
• Implementing processes to test data validity, latency and coverage
• Building and maintaining software infrastructure for use across the company
• Monitoring, triaging and fixing issues alongside fellow Engineers
• Taking new ideas from inception through to implementation across our tech stack
• Mentoring other Engineers to help them achieve their full potential
• Contributing to the development of internal gRPC APIs & Go services
• Developing internal frontends written in React

Our client are looking to move quick on this so please apply today or get in touch with me for more information at sean.kennedy@harringtonstarr.com",sean.kennedy@harringtonstarr.com,,True,,,fulltime,https://www.harringtonstarr.com/candidates/job/senjor-data-engineer-/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Bristol,,,Senior Data Engineer
Client Server Ltd.,,1736812800000,"Data Engineer (Python SQL Spark Azure Databricks) London to £130k

Are you a tech savvy Data Engineer with a first class education? You could be progressing your career working on complex and challenging systems at a Hedge Fund with over $17 billion under management.

What's in it for you:
• Salary to £130k
• Significant bonus earning potential
• Fund performance share
• Personal training budget and mentoring
• Family friendly benefits that include unlimited emergency backup childcare as well as care for elderly relatives
• Various social groups including sports teams
• Private healthcare and wellness activities

Your role:

As a Data Engineer you will join a small team responsible for understanding, managing and transforming raw data content from various 3rd parties for the trading team, investment quants and investment desk. Typical responsibilities will include combining and transforming raw data into useful insights, analysis and visualisations, interrogating various vendor data endpoints to source and analyse data, ensuring data consistency, completeness and accuracy across all platforms.

You'll develop data dictionaries and other documentation and collaborate with technology teams to implement and enhance data systems and processes, keeping up to date with industry trends and emerging technology in data content and tooling.

Location / WFH:

You'll join the team in fantastic London (Soho) based offices that offer a wide range of facilities including nutritionally balance breakfast, lunch and all day snacks. Please note this role is full-time office based (Monday to Friday).

About you:
• You have an outstanding record of academic achievement - minimum 2.1 in a STEM discipline from a top tier university (i.e. Russel Group or top 100 global university), backed by A grades at A-level
• You have strong technical skills with Python and SQL, experience with version control and contributing to a shared codebase
• You have experience with modern data tools and technologies including Apache Spark, Azure Databricks experience would also be great
• You have a strong knowledge of data management principles and best practices
• You have experience with data analysis, visualisation tools and techniques
• You're able to convey complex data and technical information to front office traders
• You have an understanding of financial markets and investment management

Apply now to find out more about this Data Engineer (Python SQL Spark Azure Databricks) opportunity.

At Client Server we believe in a diverse workplace that allows people to play to their strengths and continually learn. We're an equal opportunities employer whose people come from all walks of life and will never discriminate based on race, colour, religion, sex, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. The clients we work with share our values.",,,True,,,fulltime,https://www.reed.co.uk/jobs/data-engineer-python-sql-spark/54307424?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer Python SQL Spark
Consortia,,1736812800000,"Are you ready to lead cutting-edge data solutions that drive smarter pricing, market analysis, and investment strategies? Join a leader in its field, working alongside a passionate, highly skilled team with sustainability at the core of everything they do.

What You’ll Do:
• Take ownership of the end-to-end design and development of scalable, cloud-based data infrastructure, with a primary focus on Google Cloud Platform (GCP).
• Lead, mentor, and develop the existing team of two data engineers
• Build and optimise robust data pipelines with Python, Snowflake, and Databricks, ensuring seamless integration into business processes.
• Drive CI/CD best practices to maintain reliability and efficiency in all aspects of the data engineering lifecycle.
• Deliver actionable insights by developing data models that support pricing decisions, market analysis, and investment strategies.

What You’ll Bring:
• Deep expertise in GCP – you’ll bring hands-on experience with GCP tools such as BigQuery, Dataflow, and Cloud Functions.
• Proficiency in Python, SQL, and modern data engineering tools, plus familiarity with JavaScript for cross-functional collaboration.
• A strong background in Snowflake and Databricks to support scalable data solutions.
• Leadership skills, with experience mentoring a team, and the ability to inspire and grow talent.
• A commercially minded approach, with the ability to align data solutions to business priorities and outcomes.

What’s On Offer:
• Salary: £90,000- £100,000 (depending on experience).
• Benefits: Competitive bonus, private medical cover, pension, and a collaborative team culture.
• Work Policy: Hybrid model with three days onsite at the company’s modern, well-connected London office.
• Progression: Room to grow into more senior roles as the team and organisation scale.
• Impact: Work at the heart of data-driven decision-making for a company that’s not only a leader in its field but also puts sustainability at the centre of its strategy.

Key Information:

Job Title: Lead Data Engineer

Location: London

Work Policy: Hybrid (2 days a week onsite)

Salary: £100,000 - £120,000

Benefits: Bonus, private medical cover, pension, collaborative team culture

Consortia is a specialist recruitment agency with consultants focused on global roles within UX, Product, Data, and Engineering markets. If this Lead Data Engineer job in London doesn’t align with your preferences, but you are open to exploring other opportunities, please still register by applying to this role so we can match you to other requirements.

Kindly be aware that we cannot respond individually due to the high volume of applications; however, even if we do not contact you to move forward for this role, we will keep your details for future reference when a more suitable opportunity becomes available.",,,False,,,fulltime,https://www.consortia.com/jobs/data-engineers/lead-data-engineer-gcp/j17822/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Lead Data Engineer (GCP)
Fynity,,1736553600000,"Lead Data Engineer – SC Cleared (or Clearable)Location: LondonSalary: Up to £80,000Start Date: ASAPAbout the RoleJoin a dynamic Digital Transformation Consultancy as a Lead Data Engineer and play a pivotal role in delivering innovative, data-driven solutions for high-profile government clients. You’ll be responsible for designing and implementing robust ETL pipelines, leveraging cutting-edge big data technologies, and driving excellence in cloud-based data engineering.This role offers the opportunity to work with leading technologies, collaborate with data architects and scientists, and make a significant impact in a fast-paced, challenging environment.Key Responsibilities:
• Design, implement, and debug ETL pipelines to process and manage complex datasets.
• Leverage big data tools, including Apache Kafka, Spark, and Airflow, to deliver scalable solutions.
• Collaborate with stakeholders to ensure data quality and alignment with business goals.
• Utilize programming expertise in Python, Scala, and SQL for efficient data processing.
• Build data pipelines using cloud-native services on AWS, including Lambda, Glue, Redshift, and API Gateway.
• Monitor and optimise data solutions using AWS CloudWatch and other tools.
What We’re Looking For:
• Experience: Deep background in data engineering with hands-on expertise in big data technologies.
• Cloud Expertise: Proven experience implementing pipelines using AWS services.
• Technical Skills: Strong command of Python, Scala, SQL, and ETL tools.
• Security Clearance: Candidates must have or be eligible for SC clearance. Preference will be given to those already SC Cleared.
SC Clearance Criteria:
• Must be a British Citizen or have resided in the UK for at least 5 consecutive years.
• Detailed employment history for the past 10 years or longer may be required.
Why Join Us?
• Be part of a forward-thinking consultancy driving digital transformation for industry leaders.
• Work with the latest big data and cloud technologies.
• Collaborate with a team of skilled professionals in a fast-paced and rewarding environment.
If you’re passionate about delivering impactful data solutions and meet the criteria for this role, we’d love to hear from you. Apply today and lead the way in digital transformation!If you are interested please apply ASAP. The People Network is an employment agency and will respond to all applicants within three - five working days. If you do not hear within these timescales please feel free to get in touch.",,,False,,,fulltime,https://www.cv-library.co.uk/job/222887965/Lead-Data-Engineer-SC-Cleared?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Lead Data Engineer - SC Cleared
United Trust Bank,,1736553600000,"This is a hybrid role working 3 days in the office (City of London location) and 2 days working from home.

Role Purpose: The Data Engineer role is to develop and to support the Bank’s Business Intelligence (BI) functions. The role is closely linked with the Operating divisions. It requires working with Department Heads and divisional accountants with a strong focus on supporting and developing the Finance department.

Responsibilities:
• Design, develop, and hold accountability for data engineering services, including storage, orchestration, transformation & semantic layers
• Design & build ELT processes, data warehouse architectures, data marts, cubes, reports and dashboards; in-line with company reporting strategy & best practice
• Design & build relational and dimensional models
• Create reporting solutions in line with standards, architectural principles and practices
• Assess change impact on live systems and processes
• Work in an agile, proactive manner; delivering high quality solutions in agreed timescales
• Assess business requirements & ensure solutions add business value
• Follow & enforce the UTB SDLC, best practises, standards & design principles covering all aspects of data lifecycle management
• Ensure that adequate steps are taken to protect UTB data
• Collaborate to enhance UTB SDLC with a focus on improving quality of solutions delivered.
• Stay abreast of technology trends, data engineering techniques/standards to ensure UTB maintains a low technical debt & identify area(s) for improvement
• Develop Proof of Concepts to prove that business requirements can be met by solutions
• Perform data engineering activities such as release management, environment controls, CICD pipeline orchestration
• Perform Data modelling, problem solving and data analysis
• Providing front-end support to clients and colleagues in other departments
• Manage code migration across environments to ensure continued and synchronized functionality
• Establishing the root causes of application errors, and escalating serious concerns to the Head of IT

Skills and experience sought:
• Effective interpersonal skills and relationship-building skills
• Ability to present ideas in user-friendly language
• Understanding of the organisation’s goals and objectives
• Exceptional analytical and problem-solving abilities, with keen attention to detail
• Excellent written and verbal communication skills
• Self-motivated and directed, with the ability to effectively prioritise and execute tasks in a high-pressure environment
• Experience working in a team-oriented, collaborative environment
• A desire and willingness to assist with and own people’s problems to resolution
• Strong customer-service orientation with the ability to understand and meet needs of customers
• IT professional with prior experience in a financial services business with knowledge of banking processes would be at an advantage
• Computer Science or Maths degree or equivalent education/experience

Technical Knowledge:
• Proven track record with a Minimum of 3 years BI/Data Warehouse experience with in-depth MS SQL knowledge
• Solution Delivery experience in utilizing Azure BI stack (Azure ADF, Azure Blob storage, Synapse, CI/CD & PowerBI)
• Experience with other programming languages such as Python
• Exposure to other data technologies such as BigQuery & Spark
• Experience working with web services & APIs

Remuneration and Benefits:
• competitive salary and discretionary bonus scheme
• matched pension contributions up to 7%
• 26 days annual leave plus two wellbeing days and opportunity to purchase additional holiday
• flexible and hybrid working
• private medical insurance via Vitality
• life, income protection and critical illness insurance
• enhanced family leave pay
• extensive learning and personal development opportunities
• electric car scheme and cycle to work scheme
• season ticket loan
• wellbeing support – discounted gym membership, employee assistance programme, 24/7 private GP access for staff and their immediate family (online), 1:1 key life stage coaching",,,False,,,fulltime,https://uk.indeed.com/viewjob?jk=f3f0da6346ccd6dc&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer | Tech & Change
Akkodis,,1736467200000,"I am currently recruiting on behalf of an end user who is looking for a BI Data Engineer to join their team on a permanent basis. My client is looking for a highly skilled and detail-oriented BI data engineer to join a newly created BI & Data Services function, you will explore the art-of-the-possible and have expertise in delivering BI solutions to a range of global business functions using Microsoft PowerBI, Snowflake, Azure Datalake, Azure Data Factory and MS D365 F&O. You will be primarily responsible for owning development of data warehousing and BI as an internal capability within the organisation from a technology enablement perspective. Skills required:
• Highly proficient in Snowflake and supporting tooling such as dbt using airflow or prefet and Azure Data Factory.
• Highly proficient with PowerBI data models and report/dashboard building
• Highly proficient in full life cycle BI implementations using D365 F&O, M365

PowerPlatform/Fabric, Azure LogicApps, Data Factory, MS Datalake, Snowflake, dbt, SQL and DAX.
• Highly proficient with common data formats, CSV, JSON, XML, PARQUET, TABLES, and extracting data from RESTful APIs and data exchange services such as OData.
• Proficient in the Microsoft Office 365, particularly Excel and PowerBI Desktop, as well as using Azure DevOps to create a seamless end-to-end CI/CD pipelines, including deploying dbt transformation models, as well as deploying change to BI and

infrastructure across DEV, SIT/UAT and Production environments.
• Strong analytical and BI skills to understand business requirements and translate them into solid data solutions.
• Strong technical understanding of D365, Fabric and Azure Datalake architecture and

components, including their real world constraints and limitations and how to work

around them.
• Demonstratable communication and collaboration skills to align effectively with

stakeholders at all levels and explain technical concepts to non-technical audiences.
• Ability to clearly document and explain proposed solution designs.
• Demonstrable experience in being a technical and data delivery lead on projects

If you would like to apply and / or find out more please contact me today Consultant: Kamilla Ryan / Email: (url removed)

Modis International Ltd acts as an employment agency for permanent recruitment and an employment business for the supply of temporary workers in the UK. Modis Europe Ltd provide a variety of international solutions that connect clients to the best talent in the world. For all positions based in Switzerland, Modis Europe Ltd works with its licensed Swiss partner Accurity GmbH to ensure that candidate applications are handled in accordance with Swiss law.

Both Modis International Ltd and Modis Europe Ltd are Equal Opportunities Employers.

By applying for this role your details will be submitted to Modis International Ltd and/ or Modis Europe Ltd. Our Candidate Privacy Information Statement which explains how we will use your information is available on the Modis website.",,,False,,,fulltime,https://www.cv-library.co.uk/job/222886265/BI-Data-Engineer-Snowflake-D365FO-Hybrid?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,BI Data Engineer (Snowflake & D365FO) // Hybrid
Dufrain,,1736380800000,"We are Dufrain, a pure-play data consultancy specialising in helping businesses unlock the true value of their data by providing market-leading data solutions and services which includes developing strategies for AI readiness, improving data literacy and culture, enhancing real-time reporting, and managing data from mergers and acquisitions.

At Dufrain we prides ourselves on a creative and innovative approach, focusing on delivering exceptional outcomes for clients by leveraging data to drive growth and efficiency.

Our mission is to inspire, shape and deliver the data capabilities of tomorrow.

We have great opportunities for Data Engineers to play a pivotal role in supporting clients as they navigate the complexities of data management, analytics, and strategy.

Our Data Engineers
• Possess a broad range of data engineering skills, with a focus on Microsoft Azure, although experience with other cloud platforms is also desirable.
• Develop good working relationships with clients on a project including interpersonal skills with both business and technical focused colleagues.
• Experience working as a data engineer to develop performant end-to-end solutions in a collaborative team environment.
• Delivering high-quality pieces of work, proven ability to escalate problems to client / senior team members where necessary and propose possible solutions.
• Support building the Consulting practice through contribution to ongoing initiatives. This can include contributing to knowledge-sharing activities, and data services.

Essential technical experience you will demonstrate
• Strong experience designing and delivering data solutions in the Databricks Data Intelligence platform, either on Azure or AWS.
• Good working knowledge of Databricks components: DeltaLake, Unity Catalog, ML Flow, etc. Expertise in SQL, Python and Spark (Scala or Python)
• Experience working with relational SQL databases either on premises or in the cloud.
• Experience delivering multiple solutions using key techniques such as Governance, Architecture, Data Modelling, ETL / ELT, Data Lakes, Data Warehousing, Master Data, and BI.
• A solid understanding of key processes in the engineering delivery cycle including Agile and DevOps, Git, APIs, Containers, Microservices and Data Pipelines.
• Experience working with one or more of Kafka, Snowflake, Azure Data Factory, Azure Synapse or Microsoft Fabric is highly desirable.
• Knowledge of data modelling and data architectures: Inmon, Kimball, DataVault

About You
• A high level of drive with the ability to work to tight deadlines.
• Experience of providing insightful solutions
• The ability to participate effectively in meetings with senior stakeholders
• A team player who supports, encourages and shares knowledge with others
• A self-starter with the ability to work under pressure and with limited supervision
• A track record of accurate output and responsibility for elements of project delivery
• The ability to work as part of an integrated team or on an individual basis
• Awareness of industry standards, regulations and developments

What we offer you

We have a working culture that rewards high performance and nurtures talent, while providing exciting opportunities and challenges to generate positive change for our clients.

You can expect guaranteed investment to your personal development. We have structed learning paths on a number of platform including Udemy and not to mention the in house knowledge that is shared by all of our consultants, our lunch and learn sessions are regular fixtures in the calendar.

Benefits
• Competitive base salary
• Annual Performance related bonus
• Hybrid home/onsite/office working – Edinburgh, Manchester & London
• 25 days annual leave (plus bank and public holidays)
• Birthday day off – celebrate with an extra holiday
• Career progress programme - guaranteed learning and development investment and your own career coach
• Life insurance
• Private medical health insurance
• Contributory pension
• Health and wellbeing group
• And many more.

If you’re passionate about data, and you’re looking to join a leading data and analytics company based, you could find your dream role at Dufrain. Please submit your CV highlighting your relevant experience and certifications. Applicants must have the right to work in the UK and not require sponsorship now or in the future. Visa sponsorship is not available for this role.

We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, colour, national origin, gender, sexual orientation, age, marital status, or disability status.",,,False,,,fulltime,https://www.totaljobs.com/job/data-engineer-databricks/dufrain-job104100672?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer - Databricks
Nft Newsletter,,1736380800000,"Job title: Data Engineer - Digital Asset Market Making About Keyrock Since our beginnings in 2017, we've grown to be a leading change-maker in the digital asset space, renowned for our partnerships and innovation. Today, we rock with over 180 team members around the world. Our diverse team hails from 42 nationalities, with backgrounds ranging from DeFi natives to PhDs. Predominantly remote, we have hubs in London, Brussels and Singapore, and host regular online and offline hangouts to keep the crew tight. We are trading on more than 80 exchanges, and working with a wide array of asset issuers. As a well-established market maker, our distinctive expertise led us to expand rapidly. Today, our services span market making, options trading, high-frequency trading, OTC, and DeFi trading desks. But we’re more than a service provider. We’re an initiator. We're pioneers in adopting the Rust Development language for our algorithmic trading, and champions of its use in the industry. We support the growth of Web3 startups through our Accelerator Program. We upgrade ecosystems by injecting liquidity into promising DeFi, RWA, and NFT protocols. And we push the industry's progress with our research and governance initiatives. At Keyrock, we're not just envisioning the future of digital assets. We're actively building it. Mission statement Join our dynamic team at Keyrock, a leader in the digital asset market making space. We are committed to leveraging cutting-edge technology to provide liquidity and efficient trading solutions in the digital asset ecosystem. We are looking for a skilled Data Engineer to design, build, and maintain robust data pipelines that support our trading and analytics platforms. Job description Design, implement, and maintain scalable and efficient ETL pipelines using Python and SQL to process and store large volumes of financial data. Develop and optimize data models and schemas in PostgreSQL and Clickhouse to support complex queries and analytics. Build and maintain real-time data streaming and processing systems using AWS Kinesis and Lambda. Automate infrastructure management using Terraform for deploying and managing AWS resources, ensuring a secure and scalable environment. Collaborate with trading and analytics teams to understand data requirements and ensure the availability and quality of data for decision-making. Implement data monitoring and alerting mechanisms to proactively identify and resolve issues in data pipelines. Write shell scripts to automate routine data processing tasks and system maintenance. Ensure compliance with data governance and security best practices, especially around handling sensitive financial data. Background and experience 3+ years of experience as a Data Engineer or in a similar role within financial services, ideally with exposure to digital assets or cryptocurrency markets. Proficiency in Python for data engineering tasks and automation. Strong SQL skills for complex query design, optimization, and data modeling. Experience with AWS services, specifically Lambda, Kinesis, RDS, S3, and IAM. Hands-on experience with Terraform for infrastructure as code and managing AWS environments. Familiarity with Clickhouse for handling large datasets and real-time analytics is highly desirable. Experience with PostgreSQL for data warehousing and analytics. Proficiency in shell scripting for automation and system operations. Knowledge of best practices in data architecture, data security, and data governance. Strong problem-solving skills and ability to work in a fast-paced, dynamic environment. Excellent communication skills and ability to work collaboratively with cross-functional teams. Competences and personality Experience in the digital asset or cryptocurrency trading industry. Familiarity with financial market data, trading systems, and algorithms. Experience with other data processing and visualization tools like Apache Kafka, Spark, and Sisense. Our recruitment philosophy We value self-awareness in our recruitment process. We seek people who understand themselves and their career goals. We're after those with the right skills and a conscious choice to join our field. The perfect fit? A crypto enthusiast who’s driven, collaborative, and delivers solid, scalable outcomes. Our offer A competitive salary package, with various benefits depending on the method of engagement (employee or freelancer). Autonomy in your time management thanks to flexible working hours and the opportunity to work remotely. The freedom to create your own entrepreneurial experience by being part of a team of people in search of excellence. As an employer we are committed to build an inclusive, diverse and non-discriminating work environment. We welcome employees of all backgrounds, ethnicities, genders, creed and sexual orientation. We hire, reward and promote entirely based on merit and performance. Due to the nature of our business and external requirements, we perform background checks on all potential employees, passing which is a prerequisite to join Keyrock. #J-18808-Ljbffr",,,True,,,fulltime,https://talents.studysmarter.co.uk/companies/nft-newsletter/data-engineer-digital-asset-market-making-565816/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer – Digital Asset Market Making
CHEP,,1736380800000,"CHEP helps move more goods to more people, in more places than any other organization on earth via our 300 million pallets, crates and containers. We employ 11,000 people and operate in more than 55 countries. Through our pioneering and sustainable share-and-reuse business model, the world’s biggest brands trust us to help them transport their goods more efficiently, safely and with less environmental impact.

What does that mean for you? You’ll join an international organization big enough to take you anywhere, and small enough to get you there sooner. You’ll help change how goods get to market and contribute to global sustainability. You’ll be empowered to bring your authentic self to work and be surrounded by diverse and driven professionals. And you can maximize your work-life balance and flexibility through our Hybrid Work Model.

Job Description

Position Purpose

Our ambition is to support the growth of Brambles Digital by laying the foundations for DataOps, to support the provision of high performing, cost-effective and reliable data pipelines in our Data & Analytics ecosystem.

As a DataOps Engineer, you will undertake packages of work (Jira Align epics) which address our use of Infrastructure as Code tools and processes, particularly assisting in the management and availability of the Databricks platform and resources to internal analytics teams (Data Science, Data Engineering, Data Analytics).

In the role, you will act as direct support for our Databricks Admin team as they develop and implement the user, cluster and unity catalog governance scheme and processes. The DataOps Engineer will implement the various environment management CI/CD and IaC processes on behalf of the Databricks Admin team. This includes, but is not limited to, supporting user adoption of Databricks, implementing and maintaining security and resource provisioning best practices, disaster recovery processes, CI/CD processes and code repos, under the direction of the Databricks Admin team. As a DataOps Engineer, you will be expected to apply best practices for IaC, Enforcing Policies as Code, and Injecting Secrets into Terraform.

The role will collaborate closely with our Cloud Engineering team to ensure a joined-up approach to our environment management. Some of this work may be performed under the direction of the Cloud Engineering team.

Key Accountabilities
• Provide 2nd and 3rd line support for users of the Databricks Platform.
• Collaborate with our Data Science, Cloud Engineering & Data Engineering teams to align the Databricks environment with application requirements via IaC
• Work with Data Scientists & Machine Learning Engineers to ensure optimal performance of data models and pipelines following restoration of Databricks environment via IaC.
• Implement and maintain infrastructure as code (IaC) using Terraform for our Databricks environment and associated systems.
• Collaborate with data security teams to ensure our recovery strategies adhere to Brambles’ security standards.
• Support the implementation of a cluster policy governance framework for Databricks compute via Terraform in collaboration with the Databricks Admin team.
• Support & maintain implementation of a comprehensive application tagging process for workloads in Databricks via Terraform, under the direction of the Databricks Admin team.

Qualifications
• Bachelor’s degree in computer science, Engineering, or a related field; or equivalent work experience in Data Engineering, MLOps, or platform administration.

Experience
• At least three years’ experience in Data Engineering, IaC or MLOps.
• Experience of Databricks Administration and Terraform. Using Databricks as a Data Scientist or Data Engineer is useful experience but we’re really looking Databricks Administration experience.
• Proven experience building applications and programming using Python.
• Experience of using IaC, disaster recovery techniques and processes, or Databricks.
• Familiarity with cloud-based services and engineering.

Remote Type

Hybrid Remote

We are an Equal Opportunity Employer, and we are committed to developing a diverse workforce in which everyone is treated fairly, with respect, and has the opportunity to contribute to business success while realizing his or her potential. This means harnessing the unique skills and experience that each individual brings and we do not discriminate against any employee or applicant for employment because of race, color, sex, age, national origin, religion, sexual orientation, gender identity, status as a veteran, and basis of disability or any other federal, state, or local protected class.

Individuals fraudulently misrepresenting themselves as Brambles or CHEP representatives have scheduled interviews and offered fraudulent employment opportunities with the intent to commit identity theft or solicit money. Brambles and CHEP never conduct interviews via online chat or request money as a term of employment. If you have a question as to the legitimacy of an interview or job offer, please contact us at recruitment@brambles.com.",recruitment@brambles.com,,True,,,fulltime,https://uk.linkedin.com/jobs/view/dataops-enginner-at-chep-4117164771?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Weybridge,,,DataOps Enginner
Central England Coop,,1736294400000,"What will you be doing?

In this exciting role as Data Engineer, you’ll be playing a pivotal role in enabling our colleagues to make the best choices for our customers and members, by using data driven insight.

You’ll be managing a range of data sources (API, on-premise, cloud, flat file) and making sure the data platform to analytics is robust, and data is being ingested and structured correctly.

You’ll help design, develop, build unit tests and deliver pipelines that extract data from sources, transforming data to implement business reason and populate the D&A data store.

Applying data cleansing actions in ETL as well as adapting ETL processes in response to changes in business needs or source systems.

You will demonstrate a knowledge of the structure and meaning of data in both internal and external sources, and help in creating logical and physical operational data stores, staging areas, models, analytical datasets and data products.

As well as helping to shape the data and analytics strategy, you’ll apply your technical skills and knowledge to design, deliver and implement data solutions, applying industry and team best practices and governance

How will I know if I am right for this role?

Due to the nature of the role, you’ll need to bring a strong working knowledge of Microsoft Azure (Data Factory, Azure Data Lake, Synapse, Databricks, Azure Functions).

We are looking for someone who is a problem solver and who can demonstrate:

• An understanding of data concepts and data modelling principles

• Experience of building Azure functions.

• A broad understanding of BI information exploitation methods

• Practical experience of using Microsoft Azure Dev Ops and CI/CD

• Expert SQL knowledge

• Proficiency in Python, PySpark

Desirable, but not a requirement:

• Experience of building data pipelines in Fabric.

• Experience of developing solutions using the wider Microsoft Power Platform (Power BI, PowerApps, Power Automate)

• Data modelling and transformations using dbt

What is in it for me?

In addition to our competitive salaries, our colleagues also benefit from:

· Fantastic colleague discount- including a discount of up to 20% on our products.

· Retail discounts- our hub offers colleagues access to hundreds of exclusive retail discounts, savings on days out and holiday discounts.

· Holiday buy- colleagues can buy up to a week extra of annual leave each year

· Colleague recognition- we celebrate our colleague’s achievements both personally and professionally

· Enhanced family friendly policies- to help you feel fully supported during any significant life events.

· Colleague Dividend- We pay a share of our profits to eligible colleagues as a thank you for their contribution to our success.

· Paid time for volunteering- we encourage our colleagues to spend three days per year taking part in volunteering, fully paid for by us.

· Give as you earn- helping you support charities which mean something to you.

· Healthcare Cashplan- your wellbeing is important, so you’ve got the opportunity to contribute into a voluntary plan that helps pay towards a range of healthcare expenses.

· Company Pension- you can access a company pension scheme with us as well as access to Pension wellbeing information.

· Life Assurance- after an initial qualifying period, you’ll get free life assurance cover, that pays your nominated beneficiary if you die while you’re working for us.

· Personalised learning and development- with easy access to a wide range of training programmes

· We’ve got you – our new colleague wellbeing campaign, making wellbeing benefits and resources accessible and relevant to the role that you do.

· iTrent Financial Wellbeing (Wagestream)- offers something for all our colleagues, whether you want to track your finances, save some money, or access up to 50% of your earned pay flexibly in a way that suits you.

· Workflex- all of our flexible working options in one place, including our 4 day working week / 9 day fortnight and hybrid working options.

To find out more about all of these plus many more reasons to join us at Central Co-op, please visit Rewards and benefits - Central Coop (careers.coop)

Everyone is welcome here We’re happy to make reasonable adjustments so that all our candidates can show us how they’ll perform their role. There is a section in the application form where you can provide any additional information. Please use this section to include any reasonable adjustments you need, and we’ll do our best to support you through our recruitment process

Who are we?

We’re Central Co-op, a Member-owned and Member-led co-operative Society.

And with us, you’re not just a colleague, you’re a Member. You’ll own a share of the business.

You’ll be able to make a positive impact in your community, joining us in our mission to create a sustainable Society, and working alongside a team of passionate people who’ll help you grow. To find out more about working for us, visit our website www.careers.coop",,,False,,,fulltime,https://www.careers.coop/vacancies/7201/data-engineer.html?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Lichfield,,,Data Engineer
RemoteStar,,1736294400000,"DATA ENGINEER (Real Time)

About client:

At RemoteStar we are currently hiring for a client who is a world-class iGaming operator offering various online gaming products across multiple markets, both through their proprietary gaming sites and partner brands.

Their iGaming platform is central to their strategy, supporting over 25 online brands and growing, and it's used by hundreds of thousands of users worldwide. Our client embraces a Hybrid work-from-home model, with the flexibility of working three days in the office and two days from home.

About the Data Engineer role:

In this role, you will contribute to the design and development of Real-Time Data Processing applications to fulfil business needs.

For any Technical Data wiz out there, This is the perfect environment to put your skills to the test by building a consolidated Data Platform with innovative features and most importantly joining a bunch of talented and fun group of people.

What you will be involved in:
• Development and Maintenance of Real-Time Data Processing Applications by using frameworks and libraries such as: Spark Streaming, Spark Structured Streaming, Kafka Streams and Kafka Connect.
• Manipulation of Streaming Data: Ingestion, Transformation and Aggregation.
• Keeping up to date on Research and Development of new Technologies and Techniques to enhance our applications.
• Collaborating closely with the Data DevOps, Data-Oriented streams and other multi-disciplined teams.
• Comfortable working in an Agile Environment involving SDLC.
• Familiar with the Change and Release Management Process.
• Have an investigative mindset to be able to troubleshoot - thinking outside the box when it comes to troubleshooting problems and incident management.
• Full ownership of Projects and Tasks assigned together with being able to work within a team.
• Able to document well processes and perform Knowledge Sharing sessions with the rest of the team.

You're good with:
• Have strong knowledge in Scala.
• Knowledge or familiarity of Distributed Computing like Spark/KStreams/Kafka
• Connect and Streaming Frameworks such as Kafka.
• Knowledge on Monolithic versus Microserivce Architecture concepts for building large-scale applications.
• Familiar with the Apache suite including Hadoop modules such as HDFS, Yarn, HBase, Hive, Spark as well as Apache NiFi.
• Familiar with containerization and orchestration technologies such as Docker, Kubernetes.
• Familiar with Time-series or Analytics Databases such as Elasticsearch.
• Experience with Amazon Web Services using services such as S3, EC2, EMR, Redshift.
• Familiar with Data Monitoring and Visualisation tools such as Prometheus and Grafana.
• Familiar with software versioning tools like Git.
• Comfortable working in an Agile environment involving SDLC.
• Have a decent understanding of Data Warehouse and ETL concepts - familiarity with Snowflake is preferred
• Have strong analytical and problem-solving skills.
• Good learning mindset.
• Can effectively prioritize and handle multiple tasks and projects.",,,True,,,fulltime,https://www.remoteworker.co.uk/jobs/357454133-data-engineer-real-time-remote-at-remotestar?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Cambourne,,,Data Engineer (Real Time) (Remote)
Harnham,,1736208000000,"Role: Lead Data Engineer

Location: Burnley, Lancashire

Hybrid working: go into office 1x day a week

Salary: £50,000 - £70,000 (dependent on experience)

Insight into the Company:

A large retail organisation - market leaders in their industry – are looking for a Senior Data Engineer to enter their team. You will be working in a small team of 3 (including you!) and they are looking to build up the team over the next year. You will work closely with a junior data engineer, supporting and mentoring them.

The ideal candidate will have experience with managing data warehouses from start to finish and liaise with IT teams regularly. The role will involve stakeholder management, working with diverse roles, such as software engineers, sales and marketing professionals and more. Therefore, communicating your projects needs and understanding others is an essential part of this role.

Role and Responsibilities:
• You will design, build and upgrade data pipelines
• You will work in CI/CD and with Software/ DevOps teams in the organisation
• You will have expertise in azure – from collecting, to transforming to loading!

Skills and Experience:
• Essential to have experience with:
• Azure
• SQL
• Regular stakeholder management
• Data warehouse management
• Desirable to have experience with:
• Bachelors in STEM subject – ideally computer science or engineering
• CI/CD methods
• Python

Interview Process:
• There are 3 stages to the process:
• Introductory conversation with the Head of Business Insights
• In person interview, focussing on techstacks
• Sign off conversation!",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/lead-data-engineer-at-harnham-4088122310?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Skipton,,,Lead Data Engineer
AlphaSights,,1736208000000,"The Role

We are looking for a highly talented and driven Data Engineer who takes pride in their work, to expand our Engineering team in London. Successful candidates will join a cross functional team including product managers and designers working closely with the rest of our business to deliver working code that solves real problems for both internal and external customers. You will take ownership of the services managed by your team, ensuring that their development aligns with the higher level AlphaSights Engineering strategy, while mentoring more junior Engineers. If you're passionate about solving complex data challenges with code, and enjoy collaborating with talented colleagues in a high-performance environment, this role is a perfect fit for you.

What You’ll Do
• Design solutions: Design, develop, deploy and support data infrastructure, pipelines and architectures, contributing to an architectural vision that will scale up to be the world's leading research platform.
• Ship working code: Write clean, efficient, and maintainable code that powers data pipelines, workflows, and data operations in a production environment. Implement reliable, scalable, and well-tested solutions to automate data ingestion, transformation, and orchestration across systems.
• Own data operations infrastructure: Manage and optimise key data infrastructure components within AWS, including Amazon Redshift, Apache Airflow for workflow orchestration and other analytical tools. You will be responsible for ensuring the performance, reliability, and scalability of these systems to meet the growing demands of data pipelines and analytics workloads.
• Build your competency: You will learn quickly by building market-leading technology with experienced colleagues in a high performance environment. Engineers can also use our L&D budget to fast-track development of specific technical competencies.
• Maintenance and troubleshooting: Your role will include overseeing configuration, monitoring, troubleshooting, and continuous improvement of our infrastructure to support delivering high-quality insights and analytics.

Who You Are
• You have a degree in a STEM subject, but we’re happy to work with people who perfected their craft via a different route.
• 5+ years of hands-on data engineering development experience, with deep expertise in Python, SQL, and working with SQL/NoSQL databases. Skilled in designing, building, and maintaining data pipelines, data warehouses, and leveraging AWS data services.
• Strong proficiency in DataOps methodologies and tools, including experience with CI/CD pipelines, containerized applications, and workflow orchestration using Apache Airflow. Familiar with ETL frameworks, and bonus experience with Big Data processing (Spark, Hive, Trino), and data streaming.
• Proven track record – You’ve made a demonstrable impact in your previous roles, standing out from your peers. We’re looking for people who have incredible potential.
• Highly driven and proactive – you relentlessly and independently push through hurdles and drive towards excellent outcomes.
• Meticulous – you hold high standards and have an obsessive attention to detail.

Learn more about our tech organization here!

Don't worry if your experience or background doesn't match all of these areas, we believe a broad spectrum of experience provides great perspective on solving problems in new and innovative ways and we’d love to hear from you.

Please note that unfortunately, we are unable to sponsor visas for this position. AlphaSights is an equal opportunity employer.",,,False,,,fulltime,https://uk.linkedin.com/jobs/view/senior-data-engineer-remote-uk-at-alphasights-4062782594?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Senior Data Engineer (Remote) - UK
Razor,,1736121600000,"Are you a wiz with data, capable of transforming raw chaos into meaningful insights? Do you possess the superpower of making databases dance to your tune?

What You’ll Do

In this dynamic role, you’ll bridge the gap between technical expertise and business strategy, working directly with clients to uncover their biggest challenges and craft solutions that transform their data into actionable insights.

As a Data Engineer Consultant at Razor, you’ll design and deploy robust data pipelines on Azure, develop data warehouse schemas and prepare data for advanced analytics and machine learning. You’ll use your expertise to deploy machine learning models as APIs, optimise data workflows and uncover opportunities for reporting, analytics, and predictive modeling. Leveraging tools like Azure Data Factory, Databricks, and Power BI, you’ll turn complex datasets into strategic assets.

On the commercial side, you’ll balance delivering client value with ensuring project profitability, estimating timelines and budgets. You’ll also take ownership of data projects: providing clarity, mentorship and leadership to ensure alignment across stakeholders and successful outcomes.

What We’re Looking For

You have a strong foundation in database design, data architecture and pipeline implementation, particularly within Azure. Proficiency in Python, SQL/T-SQL, and data visualisation tools like Power BI are a “must”. You’re skilled at designing data warehouse schemas, optimising databases and deploying machine learning models in live environments.

Your ability to translate client requirements into actionable technical solutions, lead cross functional workshops and provide mentorship sets you apart from others. You thrive in uncovering opportunities for innovation and driving outcomes, with a proactive mindset that balances technical and commercial pressures seamlessly!

Why Razor?

At Razor, we don’t just work; we innovate, we create, and we celebrate our victories, big and small. Our office isn’t just a workplace; it’s a playground for ideas where collaboration is key, and success is a shared experience.

How to Apply:

If you’re ready to dive headfirst into the world of innovation and lead our products to greatness, then don’t hesitate to reach out! Apply now and become a crucial part of our mission to shape the future of technology.

Send your CV, along with an email that showcases your personality and highlights why you’re the perfect fit for Razor, to join@razor.co.uk

Join us at Razor, where every day is a chance to redefine the future and make your mark on the world of innovation. Dare to dream, dare to innovate – come be a part of something extraordinary!",join@razor.co.uk,,False,,,fulltime,https://sheffield.digital/job/razor-sheffield-full-time-data-engineer-consultant/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Sheffield,,,Data Engineer Consultant
Harnham - Data & Analytics Recruitment,,1736121600000,"SENIOR DATA ENGINEER

£55,000-£65,000 + BENEFITS

LANCASHIRE (Hybrid)

A leading company in the retail industry is seeking a proactive Data Engineer to join their innovative team.

THE COMPANY:

This is a well-established brand driven by an ambitious vision. They are currently investing in their data team, and are looking for a Data Engineer to help gather requirements and build solutions.

THE ROLE:

A Data Engineer will need to:
• Work closely with stakeholders across the business
• Manage data warehouse end-to-end (gathering requirements and building solutions)
• Helping to build data models

YOUR SKILLS AND EXPERIENCE:

A successful Data Engineer will have the following skills and experience:
• Ability and experience interacting with key stakeholders
• Strong experience in SQL/Python
• Experience with Azure/ADF
• Background in CI/CD

THE BENEFITS:

You will receive a salary, dependent on experience. Salary is up to £65,000 On top of the salary there are some fantastic extra benefits.

HOW TO APPLY

Please register your interest by sending your CV to Molly Bird via the apply link on this page.",,,False,,,fulltime,https://www.reed.co.uk/jobs/senior-azure-data-engineer/54260332?source=searchResults&filter=/jobs/azure-data-engineer-jobs&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Preston,,,Senior Azure Data Engineer
Scrumconnect Consulting,,1736121600000,"Lead Data Engineer Senior Level - SFIA5 Salary: 350- 400 Inside IR 35(dependent on experience) Location: Coventry/Hybrid About Scrumconnect: Scrumconnect is a leading force in technology consultancy, proudly contributing to over 20% of the UK’s most significant citizen-facing public services. Our award-winning team has made a substantial impact, delivering more than 64 services in the past two years alone. This work has not only reached over 50 million citizens but also achieved considerable savings for the taxpayer, amounting to over £25 million. At Scrumconnect, we foster a community of talented consultants who thrive on collaboration, sharing knowledge, and continuous learning to address and solve complex challenges. Our mission is to combine advanced software engineering, human-focused design, and data-driven insights to deliver unparalleled service to our clients. About the role: We are seeking a highly skilled and experienced Lead Data Engineer to lead a critical data warehouse migration project from an on-premises environment to a cloud-native Databricks Data Lake on Azure. This role will be instrumental in designing, developing and implementing robust data solutions that will power critical decision-making processes within the public sector. This role requires a proactive individual who thrives in an agile environment and can drive the product process from research to execution. Key Responsibilities Technical Leadership: Provide technical leadership and guidance to a team of data engineers and analysts. Define and enforce data engineering best practices, standards, and methodologies. Oversee the design, development, and implementation of data pipelines, ETL processes, and data models. Data Warehouse Migration: Lead the migration of the existing data warehouse to a cloud-native Databricks Data Lake on Azure. Assess the current data warehouse infrastructure and identify migration strategies. Design and implement data migration plans, including data extraction, transformation, and loading (ETL) processes. Optimize data pipelines for performance and scalability. Data Lake Design and Implementation: Design and implement a robust data lake architecture on Azure Databricks. Define data ingestion, storage, and processing strategies. Ensure data quality, security, and privacy standards are met. Data Engineering and Development: Develop and maintain data pipelines using Databricks, Azure Data Factory, and other relevant tools. Write efficient and scalable data processing code in Python, or SQL (PySpark and SparkSQL). Collaborate with data analysts and business stakeholders to understand data requirements and translate them into technical solutions. Data Governance and Security: Implement data governance policies and procedures to ensure data quality and integrity. Enforce data security best practices, including access controls, encryption, and data masking. Monitor data pipelines and systems for performance and security issues. Power BI Integration: Integrate Databricks with Power BI to enable advanced analytics and reporting. Develop custom visualizations and dashboards to provide actionable insights. Stakeholder Management: Communicate effectively with technical and non-technical stakeholders. Present complex technical concepts in a clear and concise manner. Manage project timelines and deliverables. Skills needed for this role: Skills needed for an SFIA Level 5 Lead Data Engineer in the UK public sector typically include: Technical Skills: Expert-level: Data development process, Data integration design, Data modelling Practitioner-level: Data analysis and synthesis, Data innovation, Metadata management, Problem resolution (data), Programming and build (data engineering), Technical understanding Communicating between the technical and non-technical: Practitioner level Soft Skills: Leadership and Collaboration Team Collaboration: Ability to work effectively with multidisciplinary teams, including developers, designers, delivery managers, and stakeholders. Stakeholder Management: Strong skills in communicating technical concepts to non-technical audiences and influencing decisions. Mentorship: Capability to guide and support less experienced team members, fostering knowledge sharing and skill development. Agile and Delivery Focus Agile Working: Experience working in agile teams, contributing to ceremonies, and integrating technical goals into iterative delivery cycles. Delivery Management: Ability to prioritise tasks, manage technical risks, and ensure timely delivery of high-quality solutions. Analytical and Problem-Solving Skills Requirements Analysis: Proficiency in translating business and user needs into technical requirements. Problem Solving: Skilled in diagnosing complex technical issues and implementing effective solutions. Data-Driven Decisions: Ability to use data, analytics, and performance insights to guide architectural decisions. Knowledge of Public Sector Standards Government Digital Service (GDS): Familiarity with GDS service standards and the Technology Code of Practice. These skills reflect the need for both technical depth and the ability to navigate the unique demands of the UK public sector environment. Desired Qualifications Certifications in Azure, Databricks, or related technologies. Example https://www.databricks.com/learn/certification/data-engineer-professional Experience with public sector data initiatives and compliance requirements. Knowledge of machine learning and artificial intelligence concepts. What our offer includes 28 days holiday inc. bank holidays 1 day Birthday leave after 1 year service 2 additional days after 2 years service Pension: 4% employee, 3% employer BUPA Health Cover AIG Life Cover Rewards Gateway On job training Where you’ll work Your working time at Scrumconnect will be split between multiple locations, including from our HQ and hub locations, client site or home. Travel requirements vary in frequency and take into account requirements of your work, our clients and the team. We welcome candidates from all identities, attributes and backgrounds to thrive with us. The diversity of our people should be reflected in the impact we deliver. Join us at Scrumconnect, where your highly demonstrable skills and expertise will drive the future of user-centred design in public services.",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/scrumconnect-consulting/lead-data-engineer-535343/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Coventry,,,Lead Data Engineer
G.Digital,,1736121600000,"Data Engineer | £50-55k | Hybrid onsite in the North East 3 days per week

If you're a Data Engineer who wants to work for one of THE best and fastest growing Data functions in this sector then you'll want to check this out...

About the business 🚀

G.Digital has partnered with this organisation who are revolutionising the game playing experience! From being one of the only cloud native operators, to creating all of their products in house they're incredibly focused on the user experience end to end

They've grown from 10 to over 400 employees and expanded into a handful of countries and now they're looking to building a data engineer and science capacity to deliver high-impact work around the UK and Europe!

Why did we choose to work with them?

✅ Investing heavily in their Tech and Product teams

✅ Remote first and great work life balance

✅ Working on a number of new Greenfield projects

✅ Big on L&D

About the role 👩💻

You’ll be working on a customer facing Data platform built using Python in an AWS serverless environment, building and maintaining ETL pipelines

You’ll work closely with the Data Science team to integrate recommender models that increase net revenue per user and also gain exposure to Kafka / Kinesis to analyse streaming data in real time at scale

What you need 😎
• A minimum of 3 years commercial experience using Python and SQL
• Any exposure to cloud data platforms would be great - specifically AWS would be ideal
• Experience in ETL, Orchestrator tools like Airflow, Glue etc
• Previous experience with Streaming frameworks like Kafka, Kinesis
• Strong communication and stakeholder engagement

And outside of the day-to-day projects:
• Staying on top of industry developments within the business and the Data Science community
• Establishing and implementing best practice
• Mentoring and coaching other team members

What’s on offer? 💰
• £50-55k
• Bonus of up to 10%
• Flexible working (core hours)
• Private health
• 8% Pension
• Life Assurance

No sponsorship offered, you must be UK based and willing to travel onsite for this role.

If you have any questions or drop me an email on s.robinson@g-digital.co.uk

Data Engineer | £50-55k | Hybrid onsite in the North east 2 days per week",s.robinson@g-digital.co.uk,,True,,,fulltime,https://uk.linkedin.com/jobs/view/data-engineer-at-g-digital-4117265296?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Newcastle upon Tyne,,,Data Engineer
Electronic Arts (EA),,1736121600000,"The Security Data Engineer position is the subject matter expert for our Security Information and Event Management (SIEM) system and leads efforts to aggregate and enrich data for to support our security efforts. Reporting into the Enterprise Security Engineering team, you will engineer new features for our SIEM and detections platform and works with security analysts to understand their needs and builds solutions to enhance their ability to find data and build security detections.

You will onboard new data sources into our SIEM to support security detections. This will encompass, analyzing new data, mapping to a common information model, and optimizing storage. You will inspire creativity in data analytics and data visualizations, explore cloud federated data models, and explore the use of AI to mine data from large data lakes. You will maintain complex data flows that support the SIEM, detections, and automations platforms. Likewise, it will build monitoring systems for the data flows and respond to and troubleshoot problems. You will work with operations staff from across the enterprise to ensure the flow of critical data.

The Security Data Engineer will work on the the security and safety of EA by building the systems that forms the ""eyes and ears"" of our security. You will solve challenging and complex problems like searching for security anomalies amongst extremely large data sets and correlating them across sources from every corner of the enterprise. You'll work in a dynamic team with a very clear vision and purpose to make a difference in security.

This role is a hybrid role. We would like you to work in our EA office in Guildford 2 days per week

Skillsets:

• At least 5 years experience with basics of security

• Proficient with Splunk Enterprise Security

• Understanding of other SIEM platforms a plus

• The ability to write optimized SPL code

• Understanding of security detections a plus

• Proficient with Linux from an administration standpoint

• Proficient with cloud platforms (AWS, Azure, etc.)

• Familiarity with PowerShell and Python for data transformations • Experience with ETL tools

• Experience with Ruby/Chef is optional

• Experience with awscli or terraform equivalent is helpful

• SOAR experience is beneficial

• Understanding of computer networks",,,False,,,fulltime,https://uk.jobrapido.com/jobpreview/7961492735276351488?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Surrey,,,Data Engineer - Security (SIEM)
Capital One - UK,,,"Nottingham Trent House (95002), United Kingdom, Nottingham, Nottinghamshire

Distinguished Engineer (Director) - Data Engineering

Distinguished Engineers are Director-level individual contributors (IC) who strive to be diverse in thought so we visualise the problem space. You will work alongside our talented team of developers, machine learning experts, product managers and people leaders. Our Distinguished Engineers are leading experts in their domains, helping devise practical and reusable solutions to complex problems. You will drive innovation at multiple levels, helping optimise business outcomes while driving towards strong technology solutions.

Distinguished Engineers are expected to lead through technical contribution. You will operate as a trusted advisor for our key technologies, platforms and capability domains, creating clear and concise communications, code samples, blog posts and other material to share knowledge both inside and outside the organisation. You will specialise in a particular subject area, but your input and impact will be sought and expected throughout the organisation.

Distinguished Engineers are:
• Deep technical experts and thought leaders that help accelerate adoption of the very best engineering practices, while maintaining knowledge on industry innovations, trends and practices
• Visionaries, collaborating on Capital One’s toughest issues, to deliver on business needs that directly impact the lives of our customers and associates
• Evangelists, both internally and externally, helping to elevate the Distinguished Engineering community and establish themselves as a go-to resource on given technologies and technology-enabled capabilities
• Communicators, working across technology and business teams, bringing together the right senior stakeholders and fostering collaboration to drive decision making that helps solve some of our most complex technical challenges
• Role models and mentors, helping to coach and strengthen the technical expertise and know-how of our engineering and product community

About the team:

It’s an exciting time at Capital One UK!

We’re on a mission to create our next generation, cloud-based data ecosystem, to unlock the power of data, increase financial inclusion and deliver transformative, real-time, intelligent experiences to our customers.

Capital One’s Data team is responsible for the data ecosystem, which covers the holistic data lifecycle, from the capture of high-quality customer data in real-time, the structuring, storage and processing of that data for insight, to the usage of the data in event driven applications and ML driven models that help our customers.

As a Distinguished Data Engineer you will be a highly experienced technical leader, accountable for driving innovation and engineering excellence through data solutions across the Data team and wider Engineering organisation. With core accountability for the technical vision of our data ecosystem, servicing an organisation of over 400+ Engineers and ~200 Analysts (including Data Scientists, Data Analysts and Business Analysts), the role requires deep Data Technology experience, including working experience of ML and GenAI.

You will also play a wider role as one of the most senior leaders in our vibrant Technology organisation, fostering a culture of curiosity and innovation. Come and help us shape the future of financial services in the Cloud.

You are…
• Recognised as a leading expert in Data Technology, including ML and AI, with deep understanding of industry trends and how they can be leveraged by the business to inform our strategic direction
• A technology expert with deep expertise in Streaming Data, Event Driven Architectures, Data LakeHouse (inc. Data Products, ELT, Distributed Data Processing, Snowflake), Data Governance, Python, Spark, Java, AWS Cloud technologies (e.g. Serverless, DynamoDB etc…) and working experience of ML and GenAI
• Proficient in software development principles, patterns, and practices. Able to drive the adoption of modern software engineering methodologies and tools, ensuring consistency and quality across teams
• An effortless communicator across tech, architecture, product and other senior stakeholders, both within the UK and across the wider Enterprise
• An inspirational leader, coach and mentor for a broad engineering group
• Able to set and deliver a strategy for the data ecosystem in partnership with our product team
• Experienced in the full life cycle of software delivery, including operational ownership (SRE)
• Able to shape the adoption of modern Data Technology and support the evolution of a Data driven culture, across a scaled, cross functional organisation

What you’ll do:
• Serve as an authoritative engineering expert across functional and non-functional requirements, and a problem solver to our engineering teams across Data Engineering
• Be a role model for engineers at all levels looking to grow in the Individual Contributor career track
• Articulate and evangelise a bold technical vision, develop and execute our Data, ML and AI technology strategy
• Be an advocate for modern technologies and patterns, sharing customer and engineering benefits to gain buy-in (working closely with leaders, other SMEs, and engineers)
• Champion a culture of engineering excellence, continuous improvement, and being well managed, using opportunities to reuse and innersource solutions where possible
• Strike the right balance between lending expertise and providing an inclusive environment where others’ ideas can be heard and championed; leverage expertise to grow skills in the broader Capital One team
• Part of your role can be actively hands-on, building POC’s, investing in key data capabilities, or pairing/teaching other engineers, decomposing complex problems into practical and operational solutions
• As a naturally curious leader, stay abreast of advances in Data, ML and AI technologies
• Lead the way in creating next-generation talent for Tech, mentoring internal talent and actively recruiting external talent to bolster Capital One’s Tech talent
• Operate as a trusted advisor across Data Engineering, helping to shape use cases and implementation in an unified manner
• Build strong relationships across the UK and into the Enterprise to influence and drive adoption of best practices
• Ensure the data ecosystem remains scalable, resilient, and delivers a best-in-class customer experience
• Exhibit a deep understanding of security best practices, compliance requirements, and emerging threats. Ensures the development and operation of secure and compliant systems, influencing security standards and practices across multiple teams
• Design and implement comprehensive observability solutions across the data ecosystem that provide deep insight into the behaviour, performance, and health of complex distributed systems

Basic Qualifications:

We do not have a checklist of qualifications you must have, but this is a senior role and we are seeking applicants with significant experience in software development / architecture / Data / ML and AI, with specific experience in platform focused data ecosystems

Where and how you'll work

This is a permanent position based in either our Nottingham or London offices.

We have a hybrid working model which gives you flexibility to work from our offices and from home.

We’re big on collaboration and connection, so you’ll be based in our Nottingham or London office 3 days a week on Tuesdays, Wednesdays and Thursdays.

What’s in it for you
• Bring us all this - and you’ll be well rewarded with a role contributing to the roadmap of an organisation committed to transformation
• We offer high performers strong and diverse career progression, investing heavily in developing great people through our Capital One University training programmes (and appropriate external providers)
• Immediate access to our core benefits including pension scheme, bonus, generous holiday entitlement and private medical insurance – with flexible benefits available including season-ticket loans, cycle to work scheme and enhanced parental leave
• Open-plan workspaces and accessible facilities designed to inspire and support you. Our Nottingham head-office has a fully-serviced gym, subsidised restaurant, mindfulness and music rooms. In London, you can heighten your mood with a run on our rooftop running track or an espresso at the Workshop Coffee café

What you should know about how we recruit

We pride ourselves on hiring the best people, not the same people. Building diverse and inclusive teams is the right thing to do and the smart thing to do. We want to work with top talent: whoever you are, whatever you look like, wherever you come from. We know it’s about what you do, not just what you say. That’s why we make our recruitment process fair and accessible. And we offer benefits that attract people at all ages and stages.

We also partner with organisations including the Women in Finance and Race At Work Charters, Stonewall and upReach to find people from every walk of life and help them thrive with us. We have a whole host of internal networks and support groups you could be involved in, to name a few:
• REACH – Race Equality and Culture Heritage group focuses on representation, retention and engagement for associates from minority ethnic groups and allies
• OutFront – to provide LGBTQ+ support for all associates
• Mind Your Mind – signposting support and promoting positive mental wellbeing for all
• Women in Tech – promoting an inclusive environment in tech
• EmpowHER - network of female associates and allies focusing on developing future leaders, particularly for female talent in our industry
• Enabled - focused on supporting associates with disabilities and neurodiversity

Capital One is committed to diversity in the workplace.

If you require a reasonable adjustment, please contact ukrecruitment@capitalone.com All information will be kept confidential and will only be used for the purpose of applying a reasonable adjustment.

For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com

Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.

Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).

Who We Are

At Capital One, we're building a leading information-based technology company. Still founder-led by Chairman and Chief Executive Officer Richard Fairbank, Capital One is on a mission to help our customers succeed by bringing ingenuity, simplicity, and humanity to banking. We measure our efforts by the success our customers enjoy and the advocacy they exhibit. We are succeeding because they are succeeding.

Guided by our shared values, we thrive in an environment where collaboration and openness are valued. We believe that innovation is powered by perspective and that teamwork and respect for each other lead to superior results. We elevate each other and obsess about doing the right thing. Our associates serve with humility and a deep respect for their responsibility in helping our customers achieve their goals and realize their dreams. Together, we are on a quest to change banking for good.","ukrecruitment@capitalone.com, Careers@capitalone.com",,False,,,fulltime,https://jobs.capitalone.co.uk/job/nottingham/distinguished-engineer-director-data-engineering/1734/69082027648?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Distinguished Engineer (Director) - Data Engineering
Aker Systems,,,"A UK Government Security Check (SC) clearance is required for this role. If you don’t hold SC clearance, we will support you to apply assuming you have lived and worked in the UK for a minimum of 5 years.

As a Principal Data Engineer, you will assist in the development of a secure batch/real-time data platform for a government client leveraging the latest commercial and open-source technologies. This involves getting data from a variety of different sources, getting it into the right format, assuring alignment to target models, and ensuring that data can be made available to downstream consumers.

You will:
• Code, test, and document new or modified data pipelines that meet functional / non- functional business requirements
• Conduct logical and physical database design
• Expand and grows data platform capabilities to solve new data and analytics problems
• Conduct data analysis, identifying feasible solutions and enhancements to data
processing challenges
• Ensure that data models are consistent with the data architecture (e.g. entity names,
relationships and definitions)
• Perform root cause analysis on internal and external data and processes to answer
specific business questions and identify opportunities for improvement

Core Competencies

The successful candidate will have a Bachelor's degree and meet all of the following essential criteria and additionally have some experience (or a genuine interest in learning) from the nice to have criteria.

Essential
• Data pipeline development using data processing technologies and frameworks
• Agile or other rapid application development methods
• Data modelling and understanding of different data structures and their benefits and limitations under particular use cases
• Experience in Public Cloud services, such as AWS. Practical experience with core services such as EC2, RDS, Lambda, Athena & Glue would be even better!
• Configuring and tuning Relational and NoSQL databases, including both query processing and query planning, or other data processing infrastructure
• Programming or scripting languages, such as Python
• Test Driven Development with appropriate tools and frameworks

Nice to have
• Familiar with CI tools such as Jenkins/Drone
• Knowledge of configuration tools such as Ansible & Packer
• Use / Knowledge of Terraform for IaC deployments
• Experience in Linux and Windows",,,False,,,fulltime,https://www.akersystems.com/careers/browse-vacancies?gh_jid=4418128101&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Principal Data Engineer
Information Tech Consultants,,,"Job Title: Junior Big Data Developer

What are we looking for?

Here at Information Tech Consultants Ltd (ITC) we are providing a unique opportunity for Junior Big Data to utilize your skills and expertise to become successful experienced Big Data Developers, working with several highly recognized UK and International companies including multiple Fortune 500 and FTSE 100 Clients.

You will provide professional consulting services working onsite for start-ups, medium and large sized companies. You will be working on large complex projects so you should be comfortable dealing with demanding stakeholders and providing time driven results. Innovation, Collaboration and Passion are the three core values that we look for in all our personnel.

Who are we looking for:

Applicants must be experienced working with the following:

Essential Skills:

· Python, SQL and ETL

· Java, Hadoop and C#

· Knowledge of Data analysis/Mining/Warehousing

· Statistical Analysis

· Linear Regression

· Databases

· R language

Desired skills :

· Cloud Integration knowledge with platforms like AWS, Azure.

· Knowledge on Scala, Spark, Kafka

· Data visualization

Qualifications and Attitude:
• Bachelor’s degree in Data Science, Mathematics, Statistics, Economics, IT related fields and 1-2 years of experience in software development.
• You should be entitled to work in the UK with legal work authorization status.
• Must be willing to travel within the UK as per project/client requirements.

· Excellent communication skills and team work skills.

What do we offer:

While we offer an unrivalled salary, you will also have the opportunity to earn a 5-15% increase each year on top (national average is 2.5%, source- the guardian). In addition, you will also gain access to our excellent management support network. You will obtain the capabilities to think creatively, design solutions and gain vital work experience.

Job Title: Junior Data Scientist

Information Tech Consultants Ltd (ITC) is a London-based mobile app development consultancy, specializing in Android, iOS and Data Scientist solutions. With over 35,000 hours accumulated and clients across the UK and Europe, it’s safe to say we know apps well! Each of our practice areas leverages specialized expertise, methodologies, and software to ensure that we deliver the most beneficial solutions to our clients.

What are we looking for?

Here at Information Tech Consultants Ltd (ITC) we are providing a unique opportunity for Junior Data Scientists to utilize your skills and expertise to become successful experienced Data Scientist, working with several highly recognized UK and International companies including multiple Fortune 500 and FTSE 100 Clients.

You will provide professional consulting services working onsite for start-ups, medium and large sized companies. You will be working on large complex projects so you should be comfortable dealing with demanding stakeholders and providing time driven results. Innovation, Collaboration and Passion are the three core values that we look for in all our personnel.

Who are we looking for:

Applicants must have basic experience working the following :

Required skills :

· Machine Learning

· SQL Server

· Data analysis/Mining/ Science/Wearhouse

· Statistical Analysis

· Linear Regression

· Databases

Desirable Skills :

· SQL

· Python

· Hadoop

· R

· Java/C++

Qualifications and Attitude:
• Master’s degree in Data Science, Mathematics, Statistics, Economics, IT and background experience in software development.
• You should be entitled to work in the UK with legal work authorization status.
• Must be willing to travel within the UK as per project/client demands.
• Excellent communication skills and team work skills.

What do we offer:

While we offer an unrivalled salary, you will also have the opportunity to earn a 5-15% increase each year on top (national average is 2.5%, source- the guardian). In addition, you will also gain access to our excellent management support network. You will obtain the capabilities to think creatively, design solutions and gain vital work experience.

Job Type: Full-time

Pay: £30,000.00-£40,000.00 per year

Additional pay:
• Performance bonus

Schedule:
• 8 hour shift

Application question(s):
• What's your Visa Status? Kindly mention if any kind of dependent visa?
• Are you comfortable working in an onsite setting?
• Will you be interested in consulting-based jobs?

Education:
• Bachelor's (required)

Work authorisation:
• United Kingdom (required)

Work Location: On the road",,,False,,,fulltime,https://uk.indeed.com/viewjob?jk=81e60f5164915d16&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Junior Big Data Engineer
Xpertise,,,"Senior Data Engineer | Northamptonshire | Hybrid (1 day a week in) | £60-70k + bonus +_ benefits

We are thrilled to be recruiting for a Senior Data Engineer on behalf of our client, an innovative and ambitious company making strides in the financial services sector. This is a fantastic opportunity for an experienced data engineer to join a forward-thinking business at a pivotal time, taking the lead on transforming their data infrastructure and playing a crucial role in shaping the future of the company’s data strategy.

The Role

As Senior Data Engineer, you’ll be at the heart of a major project to rebuild and modernise the company’s data infrastructure from the ground up. This role offers a unique chance to have a lasting impact, moving the organisation away from legacy systems and into the future with a cutting-edge data platform.

Your core responsibility will be to design, build, and maintain data pipelines and infrastructure that can support the company’s current and future data needs. You will work with modern data warehouse technologies such as Snowflake, BigQuery, or Redshift, selecting the right tools to meet the organisation's needs. You’ll establish standards for data quality and integrity, ensuring the business has access to reliable, high-quality data at all times.

Key responsibilities include:
• Designing and developing modern data architecture from scratch.
• Implementing data pipelines and warehouse solutions to support analytics, reporting, and machine learning.
• Ensuring the highest standards of data quality, integrity, and availability across the organisation.
• Collaborating with various teams to translate business requirements into technical solutions.
• Creating comprehensive documentation of data processes and systems.

What We're Looking For

The ideal candidate will have substantial experience in data engineering within cloud environments and a solid understanding of ETL/ELT processes, data modelling, and CI/CD pipelines. You should be well-versed in working with cloud-native architectures and have hands-on experience with one or more data warehouse solutions like Snowflake, BigQuery, or Redshift.

Experience in workflow automation tools such as Airflow, Luigi, or DBT is highly desirable, alongside expertise in infrastructure-as-code tools like Terraform or Pulumi. Strong communication skills are essential, as you will be working closely with non-technical stakeholders, translating complex technical concepts into understandable terms.

For more information on this role or other similar roles please contact Phil Brindley

Xpertise are acting as an employment agency and business",,,False,,,fulltime,https://www.xpertise-recruitment.com/jobs/view/senior-data-engineer-mf--13550?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Derby,,,Senior Data Engineer
Barclays,,,"Apply Here

Barclays is one of the world’s largest and most respected financial institutions, established in 1690, with a legacy of success, quality, and innovation. We offer careers that provide endless opportunity – helping millions of individuals and businesses thrive and creating financial and digital solutions that the world now takes for granted.

Our Technology locations:

UK

Radbroke (Knutsford)

Glasgow

Northampton

London

Europe:

Prague

Americas:

New York

Whippany

Asia Pacific:

Pune

Chennai

Noida

Data Engineer

Purpose of role

To build and maintain the systems that collect, store, process, and analyse data, such as data pipelines, data warehouses and data lakes to ensure that all data is accurate, accessible, and secure.

Key skills
• Machine learning, DevOps, Secure Coding Practices
• Requirements Analysis
• Data Warehousing (DW)
• Database Structures, SQL,
• Data Mining

Accountabilities
• Build and maintenance of data architectures pipelines that enable the transfer and processing of durable, complete and consistent data.
• Design and implementation of data warehoused and data lakes that manage the appropriate data volumes and velocity and adhere to the required security measures.
• Development of processing and analysis algorithms fit for the intended data complexity and volumes.
• Collaboration with data scientist to build and deploy machine learning models.

Example Roles: Platform Engineering (Database, Software and Test Engineers), Enterprise Data Services (Data scientists; Big Data Developers), Data Architect.

Barclays Values and Mindset

You may be assessed on the key critical skills relevant for success in role, such as risk and controls, change and transformation, business acumen strategic thinking and digital and technology, as well as job-specific technical skills

All colleagues will be expected to demonstrate the Barclays Values of Respect, Integrity, Service, Excellence and Stewardship – our moral compass, helping us do what we believe is right. They will also be expected to demonstrate the Barclays Mindset – to Empower, Challenge and Drive – the operating manual for how we behave.

Take a look here to find out more about our Mindset and Values.

[video width=""1280"" height=""720"" mp4=""https://theblackwomenintech.com/wp-content/uploads/2024/12/mindset-video-1-1.mp4"" autoplay=""true""][/video]

Working Flexibly

At Barclays, we offer a hybrid working experience that blends the positives of working alongside colleagues at our onsite locations, together with working from home. We have a structured approach where colleagues work at an onsite location on fixed, ‘anchor’, days of the week, for a minimum of two days a week or more, as set by the business area (or nearest equivalent if working part-time hours).

Apply Here or Explore other opportunities in Barclays Technology",,,False,,,fulltime,https://theblackwomenintech.com/job/barclays-data-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Southall,,,Data Engineer
Harnham - Data & Analytics Recruitment,,,"DATA ENGINEER (experienced in C#)

£45,000-50,000 + BENEFITS

LIVERPOOL (Hybrid)

This is great company for an ambitious Data Engineer looking to be able to take real ownership and manage and optimise the data infrastructure.

THE COMPANY:

Working with this Martech company, you will be able to work on finding customers at the early stage of the cycle, and turn them into leads.

THE ROLE:

A Data Engineer will need to:
• Work closely with stakeholders across the business
• Design and implement ETL pipelines
• Managing data infrastructure

YOUR SKILLS AND EXPERIENCE:

A successful Data Engineer will have the following skills and experience:
• Ability and experience interacting with key stakeholders
• Experience with C#
• Strong experience in SQL/Python
• Experience with Azure/ADF
• Data modelling/warehousing experience

THE BENEFITS:

You will receive a salary, dependent on experience. Salary is up to £45,000 On top of the salary there are some fantastic extra benefits.

HOW TO APPLY

Please register your interest by sending your CV to Molly Bird via the apply link on this page.",,,False,,,fulltime,https://www.reed.co.uk/jobs/c-data-engineer/54224417?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Liverpool,,,C# Data Engineer
Roke Manor Research Limited,,,"As a Data Engineer, you’ll be actively involved in development of mission critical technical solutions that focus on data services for our National Security customers.

Roke are a leading technology & engineering company with clients spanning National Security, Defence and Industry . You will work alongside our customers to solve their complex and unique challenges.

As our next Data Engineer, you’ll be managing and developing data pipelines that transform raw data into valuable insights for Roke’s National Security customers, enabling downstream analytics and reporting. You’ll be working with diverse data sources (batch, streaming, real-time and unstructured), applying distributed compute techniques to handle large datasets.

The Key Requirements...
• Able to develop Extract, Transform, Load (ETL) or Extract, Load, Transform (ELT) workflows to move data from source systems to date stores
• You will have used one or more supporting technologies i.e. Apache, Kafka, NiFi, Spark, Flink or Airflow etc.
• A history working with SQL and NoSQL type databases (PostgreSQL, Mongo, ElasticSearch, Accumulo or Neo4j etc.)
• You will be able to code using a modern software language such as Python, Java or Go
• Experience of distributed computing techniques.

Built over a 60-year heritage, Roke offers specialist knowledge in sensors, communications, cyber, and AI and ML, and Data Science. We change the way organisations think and act through dynamic insights from the analysis of multiple layers of data. We take care of the innovative, technical stuff that keeps everyone safe that’s our mission, passion, and motivation.

Joining a team united by purpose and ambition, you’ll be at the heart of an exciting growth journey: having doubled in size over the last 4 years, we intend to double our headcount by 2027. At Roke, every individual counts. We push technical boundaries, together. We re-invest in product innovation, and we empower our people to make a difference.

Where you’ll work
You’ll find our Manchester site located in the heart of Manchester ; Europe’s fastest growing tech hub. You’ll become a key part of Roke’s growing local tech community as we support the Government levelling up agenda. There is easy, local access to our client community with great transport links.

Why you should join us...
We are one Roke. We believe we all have a responsibility to create an environment where we all have the time, trust and freedom to succeed and where we are encouraged to bring our whole self to work. We are committed to a policy of Equal Opportunity, Diversity and Inclusion, enabled by our employee led resource groups of Women In Roke, Neurodiversity, Inspire (LGBT+) and ME (Majority Ethnic), which each contribute to making Roke a great place for people from all backgrounds to work.

Mental health and wellbeing is important to us, and we have a group of supportive Mental Health First Aiders to lend a listening ear for anyone who needs it. We also have a team of Mental Health First Aid Champions who help build a mentally healthy workplace, challenge stigma and support positive wellbeing.

The Benefits and Perks...
• Flexi-time: Working hours to suit you and your life
• Annual bonus: Based on profit share and personal performance
• Private medical insurance: Includes cover for existing conditions
• Holiday: You'll receive competitive annual leave plus bank holidays. We also offer the opportunity to buy and sell annual leave
• Chemring Share Save: Monthly savings into a 3 or 5 year plan.

Clearances
Due to the nature of this role, we require you to be eligible to achieve DV clearance. As a result, you should be a British Citizen and have resided in the U.K. for the last 10 years.

The Next Step...
Click apply, submitting an up-to-date CV. We look forward to hearing from you.",,,False,,,fulltime,https://uk.indeed.com/viewjob?jk=66e37fc1dfd05a7d&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Manchester,,,Data Engineer
Acquirz Ltd,,,"Leckhampton, Gloucestershire

Acquirz Ltd

Data Engineer/Data Analyst Cheltenham Hybrid Working Available Full Time £25,000-£40,000 Dependent on Experience

Are you a talented professional with a passion for both Data Engineering and Data Analysis?

Acquirz is seeking a versatile individual to join our innovative team. This hybrid role is your chance to manage and optimise data systems while extracting actionable insights that drive strategic decision-making.

At Acquirz, we use cutting-edge email marketing techniques to generate leads and build demand for some of the UK s largest enterprises and national brands. We re more than just market leaders; we re a team that values collaboration, innovation, and a fun, balanced work culture.

Are you the right person for the job?
• Bachelor s degree in Data Science, Computer Science, or a related field
• Experience in both Data Engineering and Analysis roles
• Proficiency in SQL, Python, and data visualisation tools
• Familiarity with cloud platforms is a plus
• Strong analytical and problem-solving skills
• Excellent communication to bridge technical and non-technical teams
• Proactive mindset and ability to manage multiple priorities

What will your role look like?

Data Engineering Responsibilities
• Oversee data collection, storage, and integration across platforms
• Optimise and automate data systems and pipelines for maximum efficiency
• Ensure data integrity, security, and compliance with regulations
• Work with programming languages like Python and SQL and cloud platforms such as AWS, Azure, or Google Cloud

Data Analysis Responsibilities
• Extract trends and insights from large datasets to support business strategies
• Create dashboards and visualisations using Tableau, Power BI, or QlikView
• Present actionable findings to stakeholders to inform key decisions

What can you expect in return?
• A chance to make an impact on diverse projects in a fast-growing industry
• Opportunities for professional growth and career advancement
• A competitive salary and comprehensive benefits package
• Free onsite parking
• Hybrid working options
• Annual Company Performance Bonus – £10,000
• Pension scheme & medical cover
• Training, development, & progression opportunities
• Equity opportunities for long-term employees
• Company laptop provided

Due to high application volumes, if you have not heard from us within five working days, please assume your application was unsuccessful at this time.

What s next? It s easy! Click APPLY now! We can t wait to hear from you!

Your data will be handled in line with GDPR.",,,False,,,fulltime,https://www.dataanalystjobs.co.uk/job/data-engineer-data-analyst/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,,,,Data Engineer/Data Analyst
RVU,,,"Staff Data Engineer

Department: Engineering

Employment Type: Full Time

Location: Cardiff

Description
Confused.com is the UK’s first comparison platform for car insurance. We’ve been helping customers since 2002 by empowering them to make better decisions around insurance and financial services. Our mission is simple: take away the confusion when comparing financial products and services to help you save time and money.

We’re part of RVU, a group of online brands (including Uswitch, Tempcover, and Money.co.uk) that empowers people to make confident decisions across a range of household services.

RVU’s purpose is to simplify complex marketplaces with intuitive and accessible applications that genuinely improve people’s lives. Saving a few hundred pounds a year on bills makes a fundamental difference to vulnerable people who sometimes have to choose between paying for utilities or groceries.

Our platforms serve millions of users a month, process thousands of comparisons a day, and drive hundreds of complex integrations with vastly different partners. We’re a tech- driven business that focuses on agile delivery and cross functional product teams.

We are creating the next generation of comparison platforms, and as we scale we are looking for passionate, empathetic engineers to build highly performant, accessible, and beautiful consumer experiences to facilitate switching and comparisons on the web.

What you will be responsible for
Excellence: Work alongside established & experienced engineering teams, whilst supporting and growing the organisation’s understanding & utilisation of modern technology

Collaboration: Work with various cross-functional disciplines across the organisation to make ideas a reality, whilst taking an active role in shaping and delivering the ongoing technical vision of the organisation alongside your peers

Autonomy: Authority over technical strategy, decisions and implementation approach, so you can deliver using practices that align with your preferred ways of working

Data Driven: Utilise rich logs, metrics, and data to monitor and improve system performance & reliability

Culture: Enhancing a diverse engineering culture by taking part in various technical catch ups, working groups and All Hands

Experience: Enrich RVU’s perspective by sharing your experience, knowledge & expertise in a continuous learning environment.
• Proactively identify opportunities for improvement across the organisation
• Manage your time effectively between team and org level contributions
• Rotate around the business to build relationships and act as a multiplier

What we look for in you
Experience working in large and small agile teams of engineers, and eager to collaborate with other disciplines, such as Marketing, Data Analytics & Product Owners

Good understanding of Cloud technologies, and their application to solve problems such as Event/Data Ingestion and 3rd Party API Integrations. As well as a strong appreciation of A/B Testing, Monitoring and DevOps principles

A breadth of knowledge about all aspects of software development and familiarity with procedural & functional languages, preferably having experience with Databricks, Python and SQL.

Pragmatic approach to deliver effective solutions to address business & consumer challenges

Committed to your own development and excited to make a direct, substantial impact within a company that provides you with full autonomy to release changes daily

High level of proficiency developing applications using most of the following:
• Python
• HTML, CSS, JavaScript
• SOLID Principles
• Web API
• React/Typescript
• C# ASP.NET, .Net Core
• Familiarity working within a SCRUM agile development environment.
• A good understanding of development methodologies and design patterns.
• The ability to investigate issues and both define and follow through on their resolution.
• Experience working in a Cloud computing environment.
• Experience in containerisation.
• Experience using IaC.

What we offer
We want to give you a great work environment; contribute back to both your personal and professional development; and give you great benefits to make your time at RVU even more enjoyable. Some of these benefits include:
• Employer matching pension up to 7.5%
• Hybrid approach of in-office and remote working, and a “Work from Home” budget to help contribute towards a great work environment at home
• Excellent maternity, paternity and adoption leave policy, for those key moments in your life
• 25 days holiday (increasing to 30 days) + 2 days “My Time” per year
• Up to 30 days per year “working from anywhere”
• A healthy learning and training budget
• Electric vehicles scheme
• Health insurance
• Access to the Calm and Peppy app for physical and mental health
• Regular events - from team socials to company-wide events with insightful external speakers, we want to make sure our colleagues continue to feel connected",,,True,,,fulltime,https://careers.rvu.co.uk/en/postings/49646499-7839-4d3d-a8c7-fa2288505376?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Cardiff,,,Staff Data Engineer
Nigel Frank,,,"A rapidly growing Microsoft Partner Consultancy are looking for a number of skilled Senior Data Engineers to join their expanding Data Engineering team.

They've developed a cutting-edge Microsoft-aligned Data Platform to help their customers better manage their data, expand their data capabilities, and uncover new insights.

With clients spread across the UK and Europe, this role is remote, and therefore open to candidates across the UK. Every other month there is a company-wide event in London, allowing you to celebrate success and socialise with your colleagues.

As a Senior Data Engineer, you'll work on the end-to-end development and implementation of enterprise-level data solutions for their clients. This may involve working on data and systems integration, through to data visualisation. You can expect to work on a varied tech stack including SQL, Azure Data Factory, Azure Data Lake, Azure Synapse, Power BI and Fabric.

This role would be well-suited to an ambitious Data professional, who likes the idea of joining a highly-successful Consultancy with excellent opportunities for progression.

Requirements:
• Strong SQL development skills including high-performance stored procedures
• Strong ETL experience using Azure Data Factory
• Experience working with Azure Synapse
• Experience developing reporting solutions in Power BI
• Any experience with Microsoft Fabric would be a real bonus but not essential
• Strong communication and stakeholder management skills

Benefits:
• Salary up to £60,000 depending on level of experience
• Bonus
• Company pension - 5% matched
• Life insurance
• Private medical insurance

Please Note: This is a permanent role for UK residents only. This role does not offer Sponsorship. You must have the right to work in the UK with no restrictions. Some of our roles may be subject to successful background checks including a DBS and Credit Check.

Tenth Revolution Group / Nigel Frank are the go-to recruiter for Power BI and Azure Data Platform roles in the UK, offering more opportunities across the country than any other. We're the proud sponsor and supporter of SQLBits, and the London Power BI User Group. To find out more and speak confidentially about your job search or hiring needs, please contact me directly at v.simpson@tenthrevolution.com",v.simpson@tenthrevolution.com,,True,,,fulltime,https://www.nigelfrank.com/nl/job/a0MaA000000RzQn.4_1732307362/senior-azure-data-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Birmingham,,,Senior Azure Data Engineer
Trainline,,,"Company Description

We are champions of rail, inspired to build a greener, more sustainable future of travel. Trainline enables millions of travellers to find and book the best value tickets across carriers, fares, and journey options through our highly rated mobile app, website, and B2B partner channels.

Great journeys start with Trainline 🚄

Now Europe’s number 1 downloaded rail app, with over 125 million monthly visits and £5.3 billion in annual ticket sales, we collaborate with 270+ rail and coach companies in over 40 countries. We want to create a world where travel is as simple, seamless, and affordable as it should be.

Today, we're a FTSE 250 company driven by our incredible team of over 1,000 Trainliners from 50+ nationalities, based across London, Paris, Barcelona, Milan, Edinburgh, Berlin, Madrid, and Brussels. With our focus on growth in the UK and Europe, now is the perfect time to join us on this high-speed journey!

Job Description

💻 Senior Data Engineer 📍London (Hybrid, 40% in office) 💸 £Salary + Benefits

Introducing Data Engineering at Trainline 👋

Data Engineering is essential to how we unlock the value of data at Trainline. Our mission is to liberate Trainline data and delight customers with great data products built on a frictionless, modern data platform. Our data products include machine learning models that add real value to the customer journey, streaming data applications that personalize the customer experience in real time, dashboards that drive deep business and customer insight and intuitive and efficient data marts and metrics built on our modern data lakehouse.

As a Senior Data Engineer (Scala), you will be part of a cross-functional data product team working alongside data scientists, machine learning engineers and BI engineers. Our data product teams are deeply embedded in the business so your work will have high impact by either drive key business decisions, provide deep customer insights or by adding intelligent machine learning experiences right in the core of our customer journeys.

We use an agile delivery playbook that encourages incremental and iterative delivery, aims to release value early and often, measure the impact of work and using hypotheses to ensure we are solving real customer problems. Our data platform is a modern, cloud-native, lake house using best-of-breed technologies and partners, all based on the AWS public cloud.

We empower our Data teams and give engineers high levels of autonomy and freedom to innovate. We encourage continuous learning with clear career progression plans, innovation/hack days and training opportunities such as DataCamp.

As a Senior Scala Data Engineer at Trainline, you will...
• Use cutting-edge Data technology to deliver world-class data products using a combination of streaming technologies, machine learning and automated data pipelines.
• Work in self-organised, cross-functional data teams alongside machine learning engineers, BI engineers and product managers.
• Drive continuous improvement to the software engineering and agile working practices of the team.
• Contribute to the Technical / Architecture direction of the team.

Qualifications

We'd love to hear from you if you...🔍
• Thrive in a diverse, open and collaborative environment where impact is as valuable as technical skill
• Have excellent knowledge of Scala and the JVM ecosystem
• Possess strong understanding of functional programming paradigms and a willingness to adopt other languages (not only JVM languages)
• Have consistent background in software development in high volume environments
• Have a pragmatic and open-minded approach to achieving outcomes in the simplest way possible
• Have worked with stream processing technologies (Kafka, Storm, AWS Kinesis, etc)
• Have experience with AWS services especially EMR, ECS, EKS.
• Have an obsession with software quality, Dev Ops and automation
• Work well in lean, agile, cross-functional product teams using Scrum and Kanban practices
• Are a good communicator and comfortable with presenting ideas and outputs to technical and non-technical stakeholders

Our technology stack 💻
• Python
• Scala and the JVM
• Kafka, Kafka Streams and KSQL
• AWS, S3, Parquet, Iceberg, Glue and EMR for our Data Lake
• Terraform and Docker
• Elasticsearch and Dynamodb
• Spark and Airflow
• Trinio (Starburst) and Presto (Athena)
• ML Flow and popular Python machine learning and analysis libraries

The interview process 🚉
• Recruiter Call (30 mins)
• Meet the manager (30 mins)
• Technical discussion with x2 Engineers (60 mins)
• Meeting a cross-functional team member (30 mins)

Additional Information

Enjoy fantastic perks like private healthcare & dental insurance, a generous work from abroad policy, 2-for-1 share purchase plans, extra festive time off, and excellent family-friendly benefits.

We prioritise career growth with clear career paths, transparent pay bands, personal learning budgets, and regular learning days. Jump on board and supercharge your career from day one!

Our values represent the things that matter most to us and what we live and breathe every day, in everything we do:
• 💭 Think Big - We're building the future of rail
• ✔️ Own It - We focus on every customer, partner and journey
• 🤝 \u200bTravel Together - We're one team
• ♻️ Do Good - We make a positive impact

Interested in finding out more about what it's like to work at Trainline? Why not check us out on LinkedIn, Instagram and Glassdoor.",,,False,,,fulltime,https://www.theround.com/trainline-jobs/senior-data-engineer---scala/3a0f84ae-5e4b-41d8-8921-6a6088d07f59?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Senior Data Engineer - Scala
Checkout.com,,,"Company Description

Checkout.com is one of the most exciting fintechs in the world. Our mission is to enable businesses and their communities to thrive in the digital economy. We’re the strategic payments partner for some of the best known fast-moving brands globally such as Wise, Hut Group, Sony Electronics, Homebase, Henkel, Klarna and many others. Purpose-built with performance and scalability in mind, our flexible cloud-based payments platform helps global enterprises launch new products and create experiences customers love. And it's not just what we build that makes us different. It's how.

We empower passionate problem-solvers to collaborate, innovate and do their best work. That’s why we’re on the Forbes Cloud 100 list and a Great Place to Work accredited company. And we’re just getting started. We’re building diverse and inclusive teams around the world — because that’s how we create even better experiences for our merchants and our partners. And we need your help. Join us to build the digital economy of tomorrow.

Job Description

The role

By joining the Product Analytics team, you will be responsible for enabling key insights on how products are performing and establishing a single source of truth for North Star and tracking metrics. You will work closely with product managers and product data scientists to shape the product’s evolution at Checkout.

You'll have the opportunity to build new data products and introduce step changes in how we view analytics for these critical areas. You'll have end-to-end ownership of multiple data products from design to implementation and operationalizing them

Hybrid Working Model: All of our offices globally are onsite 3 times per week (Tuesday, Wednesday, and Thursday). We’ve worked towards enabling teams to work collaboratively in the same space, while also being able to partner with colleagues globally. During your days at the office, we offer amazing snacks, breakfast, and lunch options in all of our locations.

How you’ll make an impact
• Design and implement high-performance, reusable, and scalable data models for our data warehouse using dbt and Snowflake
• Design and implement Looker structures (explores, views, etc) which will enable users across the organization to self-serve analytics
• Work closely with data analysts and business teams to understand business requirements and provide data ready for analysis and reporting
• Continuously discover, transform, test, deploy and document data sources and data models
• Apply, help define, and champion data warehouse governance: data quality, testing, documentation, coding best practices and peer reviews
• Take initiative to improve and optimise analytics engineering workflows and platforms

Qualifications

What we’re looking for
• Proven delivery experience as a data, business intelligence or analytics engineer
• Hands-on proven data modeling and data warehousing skills demonstrated in large-scale data environments
• Proven experience in software development lifecycle in analytics (e.g. version control, testing, and CI/CD)
• Excellent SQL and data transformation skills (e.g. ideally proficient in dbt or similar)
• Familiarity with at least one of these Cloud technologies: Snowflake, AWS, Google Cloud, Microsoft Azure
• Passionate about sales, finance, customer, marketing and/or product analytics data
• Good attention to detail to highlight and address data quality issues
• Excellent time management and proactive problem-solving skills

Additional Information

Apply without meeting all requirements statement

If you don't meet all the requirements but think you might still be right for the role, please apply anyway. We're always keen to speak to people who connect with our mission and values.

We believe in equal opportunities

We work as one team. Wherever you come from. However you identify. And whichever payment method you use.

Our clients come from all over the world — and so do we. Hiring hard-working people and giving them a community to thrive in is critical to our success.

When you join our team, we’ll empower you to unlock your potential so you can do your best work. We’d love to hear how you think you could make a difference here with us.

We want to set you up for success and make our process as accessible as possible. So let us know in your application, or tell your recruiter directly, if you need anything to make your experience or working environment more comfortable. We’ll be happy to support you.

Take a peek inside life at Checkout.com via
• Our Culture video https://youtu.be/BEwnpHuadSw
• Our careers page https://www.checkout.com/careers
• Our LinkedIn Life pages bit.ly/3OaoN1U
• Our Instagram https://www.instagram.com/checkout_com/",,,False,,,fulltime,https://jobs.smartrecruiters.com/Checkoutcom1/744000031055562-senior-data-analytics-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Senior Data Analytics Engineer
Getting In Limited,,,"Level 5 Data Engineer Apprenticeship

Apply From: 22/12/2024

Learning Provider

Delivered by QA LIMITED

Employer

GREENWOOD ACADEMIES TRUST

Vacancy Description
• Assisting in data integration projects by extracting data from various sources (e.g., databases, APIs, flat files) and transforming it into a usable format for analysis and reporting.
• Performing data cleansing and transformation activities, including identifying and correcting errors, standardising formats, and enriching data using various techniques.
• Supporting the development of data models by creating and maintaining documentation, assisting with data mapping, and contributing to the design of database schemas.
• Collaborating with the data engineering team on projects related to migrating data to a cloud-based platform.
• Contributing to the creation of data visualisations and reports to present insights to stakeholders.

Key Details
Vacancy Title

Level 5 Data Engineer Apprenticeship

Employer Description

The Greenwood Academies Trust (GAT) currently has 39 open academies educating approximately 17,000 pupils across seven local authority areas.

Vacancy Location

17 Brunel Way PO15 5TX

Wage Frequency

Custom

Number of Vacancies

1

Vacancy Reference Number

1000292516

Key Dates
Apply From

22/12/2024

Closing Date For Applications

2025-01-10 23:59:59

Interview Begin From
Possible Start Date

2025-01-30 00:00:00

Training
Training to be Provided

Data Engineer Level 5.

Whilst working for Greenwood Academies Trust (GAT) you will be undertaking a significant amount of your apprenticeship training at Medhurst Communications, who are an education-focused Managed Service Provider (MSP) and technology provider, and will provide the professional development and support, in addition to your line management within GAT.

Learning Provider

QA LIMITED

Skills Required

Communication skills, IT skills, Attention to detail, Organisation skills, Problem solving skills, Number skills, Analytical skills, Logical, Team working, Creative, Initiative.

Apply Now

#J-18808-Ljbffr",,,False,,,fulltime,https://uk.jora.com/job/Data-Engineer-d1f16b7bbc9d33a05b4f2065d1fd29e4?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Slough,,,level 5 Data Engineer Apprenticeship
Nigel Frank,,,"Senior Azure Data Engineer - Remote - £60,000

I am working with a data driven Microsoft partnered consultancy who are looking for a Senior Data Engineer to join their growing team. You will have the opportunity to work with some of the latest Microsoft technologies such as Microsoft Fabric and Databricks.

You will join a team at the centre of a number of data-driven projects where you will be responsible for the design, development and creation of data solutions. You will work on the full end-to-end product lifecycle from platform design to insights creation.

As part of this role, you will be responsible for some of the following areas
• Design, develop and maintain data pipelines that are responsible for the ingestion and transformation of data between different sources
• Create and develop data models
• The creation of insightful and accurate data visuals/reports/dashboards
• Work closely with stakeholders from different departments to ensure their data needs can be met

To be successful in the role you will have
• Strong ETL experience with tools such as ADF or SSIS
• Strong experience with Python/PySpark
• Experience working with Azure technologies - Synapse, Fabric, Data Lake
• Data visualisation experience with Power BI

This is just a brief overview of the role. For the full information, simply apply to the role with your CV, and I will call you to discuss further. My client is looking to begin the interview process ASAP, so don't miss out, APPLY now! To do so please email me at a.pinkerton@nigelfrank.com or call me on 0191 3387487.

Nigel Frank International are the go-to recruiter for Power BI and Azure Data Platform roles in the UK offering more opportunities across the country than any other recruitment agency. We're the proud sponsor and supporter of SQLBits, Power Platform World Tour, the London Power BI User Group, Newcastle Power BI User Group and Newcastle Data Platform and Cloud User Group. We are the global leaders in Microsoft recruitment.",a.pinkerton@nigelfrank.com,,True,,,fulltime,https://www.nigelfrank.com/job/a0MaA000000Qo7d.5_1731954128/senior-azure-data-engineer-remote-gbp60000?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,"Senior Azure Data Engineer - Remote - GBP60,000"
HashiCorp,,,"P3

US - Remote

JR103862

About the team

We're looking for talented Data Engineers to join our Threat Detection and Response Team (TDR). This team will help defend HashiCorp by enhancing strategic detection, response, and prevention patterns across all of our products and the enterprise. This person will be responsible for expanding and maturing our approach to delivering visibility across all major cloud providers to ensure we have an accurate record of actions performed across each layer of our technology stacks.

About Us

HashiCorp is a fast-growing organization that solves development, operations, and security challenges in infrastructure so organizations can focus on business-critical tasks. We build tools to ease these decisions by presenting solutions that span the gaps. Our tools manage both physical machines and virtual machines, Windows, and Linux, SaaS and IaaS, etc. Our open source software is used by millions of users to provision, secure, connect, and run any infrastructure for any application. The Global 2000 uses our enterprise software to accelerate application delivery and drive innovation through software.

What you'll do (responsibilities)

As a member of our Security team, you'll be responsible for ensuring we have the best practices implemented across our multi-cloud environment. You will partner with engineering and other stakeholders to define and drive secure by default environments supporting our products and the enterprise. We're heavily invested in tooling and automation, and the ability to continually improve these areas will be key to success as we scale our environments to meet customer demand.

Engineering at HashiCorp is largely a remote team. While prior experience working remotely isn't required, we are looking for team members who perform well given a high level of independence and autonomy.

HashiCorp embraces diversity and equal opportunity. We are committed to building a team that represents a variety of backgrounds, perspectives, and skills. We believe the more inclusive we are, the better our company will be.

What you'll need (basic qualifications)
• 2+ years in an engineering role focused on large scale data collection in the cloud, using cloud-native tooling
• Working knowledge of batch or streaming data processing pipelines
• * Collect, Normalize, Tag, Enrich
• Windowing and time series transformation
• Working knowledge of patterns of information retrieval and optimizing query workload
• * Developing aggregates, views, summaries, and indices to accelerate access to data
• Profiling query workloads using query planner output or other diagnostic tooling to identify performance bottlenecks
• Profiling resource consumption to optimize expenditure on storage and transit
• Planning, dispatching, and monitoring query workload to ensure on-time delivery of information with optimal use of resources
• Experience working with multiple data query models
• * Relational, key-value, graph, document, full-text search
• Maintaining and evolving shared query content through source code management practices
• Natural curiosity and an interest in Threat Detection, Incident Response, Fraud, and/or Threat Intel problem space and the desire to be exposed to and develop these skill areas while serving in a development-focused role
• You have experience taking a periodic on-call rotation in a distributed team
• Publicly released tools or modules or open source contributions

You have experience with some or all of these :
• Strong programming skills in one or more general-purpose languages (Python, Go, Rust, etc.) and familiarity with one or more infrastructure as code languages (Terraform, AWS CDK) in a production capacity
• Experience with git based code review workflows
• AWS, GCP, Azure
• AWS EC2, Lambda, Step Functions, ECR/ECS/EKS, S3
• Logging Infrastructure and ETL Pipelines - fluentd, logstash, vector, kafka, kinesis or similar
• CI/CD - Building pipelines involving Jenkins, CircleCI, GH Actions, etc...
• Solid foundation of Linux and exposure linux in cloud provider environments

#LI-Remote",,,True,,,fulltime,https://uk.indeed.com/viewjob?jk=4ff8b7c5b3ade025&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Security Data Engineer (UK)
Gresham Hunt,,,"Data Engineering Team Lead

Financial Services

London, UK – Hybrid, 2 days/week in office

Salary: £70-75,000 + DOE

Gresham Hunt is currently partnered with a leading financial services provider who are seeking an experienced Data Engineering Team Lead to join their London-based team. This is an exciting opportunity to play a lead role in the development of the cloud migration strategy as well as maintaining the firms existing legacy on-prem database infrastructure.

Responsibilities:
• Oversee the establishment of a framework, processes, and systems for a central data view to run and improve the business with strategy and governance.
• Lead the migration of on-premise legacy databases to the cloud, including developing a strategy, plan, and implementation with other teams.
• Oversee the engineering processes to build data pipelines, integrate data sources, clean and transform data.
• Coach the team on techniques for building code to extract raw data and ensure data quality across the pipeline.
• Provide expertise on transforming raw data for downstream data sources.
• Guide the development of data tools for data transformation, management, and access.
• Advise the team on writing and validating code to test data platform storage and availability for improved resilience.
• Oversee the implementation of performance monitoring protocols across data pipelines.
• Coach the team on building visualizations and aggregations to monitor pipeline health.
• Implement solutions to minimize points of failure across environments.
• Oversee the design of data modelling and handling procedures to ensure compliance with all applicable laws and policies.
• Work with stakeholders across directorates to address data concerns.
• Support assessment of data costs, access, usage, use cases, dependencies across products, and data availability for internal and external stakeholders.
• Build cross-functional relationships with IT, Security, and Architecture to support data requirement delivery to business stakeholders.

The Successful Candidate will have experience in:
• Team Leadership: Previous experience managing a team of Data Engineers and Analysts.
• Database Management: Extensive knowledge of MS SQL databases, both Azure cloud and on-premises, including design, modelling, and architecture.
• Cloud Migration: Experience in migrating legacy applications to the cloud.
• Data Tools and Programming: Proficiency in data tools and programming languages like Python, DAX, R, M, VBA, and the SQL Stack (SSMS, SSIS, SSAS, SSRS).
• Data Visualization: Experience with data visualization tools such as Power BI, Qlik, and Tableau.
• Data Engineering and Analytics: Proven ability to establish, develop, and implement a data engineering and data analytics practice area or function.
• Stakeholder Management: Effectively understanding and addressing stakeholder needs.
• Graphical Development Tools: Experience with tools like Data Flows, Ab Initio, and Power Apps (desirable).

For a confidential conversation please forward your CV to: tom.haussrer@greshamhunt.com

All candidates must currently be based in the UK with full right to work.",tom.haussrer@greshamhunt.com,,False,,,fulltime,https://www.greshamhunt.com/job/data-engineering-team-lead?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineering Team Lead
Zebra People,,,"Do you have a robust background in software and data engineering with extensive experience using GCP? Based in Bristol, this forward-thinking financial services company is looking for a talented Data Engineer to join their Consumer Servicing and Engagement Platform team. This role is pivotal in developing innovative financial tools and insights that empower millions of customers to take control of their finances. Ready to make a significant impact and drive change in the industry?

The client

About them

This innovative financial services firm is on a mission to redefine how they serve their extensive customer base through strategic investments in technology, data, and people. They are committed to fostering an inclusive workplace that mirrors the diversity of their customers. The company emphasizes personal and professional growth, encouraging continuous learning and development. With a strong focus on work-life balance, they offer flexible working arrangements and a supportive environment where employees can thrive.

By joining this team, you will be part of a transformative journey, working on cutting-edge projects that impact millions of users. The immediate focus will be on enhancing their money management tools and adding exciting new features, making a significant difference in the financial wellbeing of their customers.

The role

What will I be doing?

You will play a critical role in the design, development, and deployment of new features within the Consumer Servicing and Engagement Platform. Collaborating closely with Business Analysts, Product Owners, Architects, and Engineering Leads, you will drive the development process within an agile framework. Your contributions will focus on creating, supporting, and enhancing financial management tools, ensuring high-quality engineering practices are upheld.

The candidate

What’s in it for me?

You’ll receive a competitive salary of up to £80K, and hybrid working along with a robust benefits package. Benefits include a substantial pension contribution of up to 15%, an annual performance-based bonus, and participation in share schemes, including free shares. You’ll also get 30 days of holiday plus bank holidays, access to various well-being initiatives, generous parental leave policies, and adaptable lifestyle benefits such as discounted shopping.

What experience do I need?

You will have a strong software engineering background and extensive experience with GCP cloud. With proficiency in Java and Golang (preferably both), experience in real-time data processing and application streaming using Kafka, and proficiency with Docker and container orchestration tools like Kubernetes. A solid understanding of how system design impacts scalability, resilience, and supportability is crucial. While a background in software engineering rather than pure data engineering is preferred here, experience with machine learning algorithms would also be advantageous here.",,,False,,,fulltime,https://zebrapeople.com/job/data-engineer-gcp/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Bristol,,,Data Engineer (GCP)
RKY Careers,,,"£45k - £55k per annum

Snowflake Data Engineer - £60,000 - London - Visa Sponsorship available

Do you like working with the latest technology and are interested in enhancing your tech abilities? Our client has an exciting opportunity for a highly skilled Data Engineer with significant experience of Snowflake. As well as being an expert in the Snowflake cloud platform, you'll have a strong background in Data Ingestion and Integration, designing and implementing ETL pipelines on various technologies, Data Modelling and a rounded understanding of data warehousing.

What you will have experience with:
• Experience of delivering end to end solutions with different databases technologies focusing on Snowflake but also Dynamo, Oracle, SQL Server, Postgres.
• Experience of managing data using the Data Vault architecture and managing it through DBT.
• Strong understanding of data manipulation/wrangling techniques in SQL along with at least one of the following Python, Scala, Snowpark or PySpark.
• Experience in designing structure to support reporting solutions optimised for use from tools like Qlik, Tableau etc. Good understanding of modern code development practices including DevOps/DataOps but also Agile.
• Strong interpersonal skills with the ability to work with customer to establish requirements and then design and deliver the solution. Taking the customer on the end-2-end journey with you.

What you'll get for this role:
• Salary up to £60,000 London
• Generous pension (starting level client contributes 8% when you contribute 2%)
• Part of the Sales Bonus Scheme
• Family friendly parental and carer's leave
• 29 days holiday per year plus bank holidays and the option to buy/sell up to 5 additional days
• Up to 40% discount for products
• Brilliant flexible benefits
• Matching Share Plan and Save As You Earn scheme
• 21 volunteering hours per yearIf this is something you'd like to hear more baout please apply or reach me directly on [ Email address blocked ]

Recommended Skills
• Agile Methodology
• Architecture
• Cloud Platform System
• Data Ingestion
• Data Modeling
• Data Processing

Apply to this job.Think you're the perfect candidate?

Job ID: DCJFISF001

APPLY HERE",,,False,,,fulltime,https://rkycareers.com/jobs/snowflake-data-engineer-london-salary-to-55000-2/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,"Snowflake Data Engineer – London – Salary to £55,000"
Atom bank,,,"We’re Atom bank The bank that’s leading the fintech charge! We’re not like the rest. We’re true innovators, and we’re redefining what a bank…",,,False,,,fulltime,https://www.atombank.co.uk/careers/technology/bi-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Durham,,,BI Engineer
CTI Digital,,,"We are seeking an experienced and detail-oriented Data Systems Engineer. The ideal candidate will have experience with cloud-based data storage/manipulation systems and strong analytical skills, with the ability to turn complex data into actionable insights. The Data Systems Engineer will play an instrumental role in the data transformation process at CTI to drive data-driven decision-making and enhance our understanding of business performance.
A bit about the job.
• Maintain, improve and extend our data warehouse, Tableau reporting suite and other related tools/platforms
• Work with dbt and Tableau to reliably combine data from multiple systems/platforms into a fully related, normalised structure suitable for efficient tracking and reporting
• Liaise with internal stakeholders from around the business to ensure management systems and reporting outputs meet business requirements
• Identify and suggest potential improvements to systems and data structures which would delivery enhanced insight and operational efficiencies, based on a comprehensive understanding of business processes
• Work with a programme coordinator to maintain a roadmap of improvements, work with business stakeholders to prioritise items and ensure they are delivered accordingly
• Implement rigorous data quality assurance processes to ensure data accuracy, completeness and integrity
• Ensure all company data remains secure, with access provided to relevant members of the team
• Maintain full documentation of the systems and structures in place.

Qualities and Skills
• dbt
• Tableau Cloud development and management
• Fivetran or similar ELT systems
• Advanced relational database (PostgreSQL or similar) schema development/maintenance and querying skills
• AWS infrastructure and Bitbucket pipelines (desirable)
• Proven experience as a Data Analyst, Data Systems Engineer or similar role
• Exceptional attention to detail and accuracy in work
• Strong analytical and problem-solving skills
• Excellent communication (written and verbal), organisational and interpersonal skills
• Ability to work autonomously but also as part of a team
• A constant desire to improve efficiency and usefulness of management systems and reporting outputs

Location: Our head office is Manchester city centre (Ancoats) - we adopt a hybrid working model (2 days in the office per week)

Salary: DOE

Why CTI Digital?

Having recently received a £25 million investment, CTI is now on an accelerated path with growth in several areas across the business and its other brands. We are committed to ensuring our employees have the best possible opportunities to learn and develop along the way, offering continued professional development days for all levels of the business with a dedicated budget. We pride ourselves on providing high-quality services to clients and recognise the hard work that our staff do that's why we also offer many other benefits including:
• 28 days annual leave, in addition to the bank holidays
• Six days per year for your continuing professional development (CPD)
• Personal training and development fund
• Workplace nursery scheme
• Health cash plan
• Cycle-to-work scheme
• Life assurance scheme
• Flexible working hours
• Employee Assistance Programme
• Annual subscription to Leafyard, a mental wellbeing platform
• Pension 4% matched
• Free breakfast on a Monday (if in the office)
• Company socials

At CTI Digital, we are committed to fostering an inclusive, equal and diverse workplace. We encourage candidates from all backgrounds & communities to apply. If you are a skilled professional with a passion for digital transformation to help businesses succeed, we would love to hear from you. You can also find out more about our work with equality, diversity and inclusion here.",,,False,,,fulltime,https://careers.ctidigital.com/jobs/5388193-data-systems-engineer?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Manchester,,,Data Systems Engineer
Maxwell Bond,,,"I'm searching for a Data Engineer

Manchester based: Hybrid

Up to £55,000 salary(plus bonus)

Are you a Data Engineer who is passionate about Data and looking for a new challenge?

I am working with a utilities provider who are currently looking to bring on a Data Engineer to play a vital role in developing and maintaining data pipelines, infrastructure and systems.

What's in it for the successful Data Engineer:
• Joining a company at an exciting time as they transition from on-premises to a cloud base data lake.
• Working for a data driven organisation.
• Hybrid working for a better work/life balance.

The successful Data Engineer will have:
• 2+ years of experience in a Data role.
• Excellent communication skills and ability to communicate with technical and non-technical stakeholders.
• Proven working experience with Azure, Python and SQL.

This position does not offer Visa Sponsorship, please refrain from applying if you require sponsorship at any stage.

If this sounds like you, please contact myself or apply directly with your CV!

“By applying for this role, you provide us with consent to process your data in line with our Privacy Policy, full details can be found on our website.""",,,False,,,fulltime,https://www.maxwellbond.co.uk/jobs/Data-Engineer-6045?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Greater Manchester,,,Data Engineer
Attis Global,,,"Job Description

Senior Data Engineer required to join a household name brand with core ESG values which focus on climate action, decarbonisation, and ED&I, based in the Southampton area (Hybrid).

On offer is a competitive package of £90k+, made up of a £70k salary, bonus and:
• A very large benefits package (20+ benefits)
• Training in skills gaps such as architecture, or tools like Snowpark / SnowDDL etc
• A fun environment! The manager is particularly friendly, encouraging, and welcoming.
• Support from a diverse team of industry experts and enthusiasts
• A flexible and hybrid working environment
• A chance to really make a mark on the data team,

Your responsibilities will include
• Technical Leadership of small team of Data Engineers
• Designing, Developing and Maintaining scalable, reliable, and secure data pipelines that power their BI, analytics, and data applications, using dbt and Snowflake.
• Support the development of the Data Architecture
• Write high-quality code, perform data cleansing, transformation, and validation, and implement best practices for data quality and governance.

To be successful in this role, you should have:
• At least 3 years of experience as a data engineer or a similar role, working with large-scale data systems and pipelines
• Expertise with Snowflake and DBT
• Proficient in Python
• Github code repository experience,
• CI pipeline knowledge
• Data Warehousing expertise, SSIS beneficial
• Excellent communication, collaboration, and problem-solving skills
• A positive outlook on life!

PLEASE NOTE: the company doesn’t currently have a sponsorship licence. You must be security clearable, meaning you have lived in the UK consistently for the last 5 years.

If you are interested in this role, please apply with your CV through this site.

DISCLAIMER: No terminology in this advert is intended to discriminate on the grounds of age, sex, race, religion or belief, disability, pregnancy and maternity, marriage and civil partnership, visa status, nationality, sexual orientation, gender, and/or gender reassignment, and we confirm that we are happy to accept applications from anyone for this role. Attis Global Ltd operates as an employment agency and employment business. More information can be found at attisglobal.com.",,,False,,,fulltime,https://www.adzuna.co.uk/jobs/details/4989219954?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Southampton,,,"Senior Data Engineer - Snowflake, dbt"
Digital Pursuit Limited,,,"```html

About the role

Full job description

Data Engineer | Python | SQL | ETL | AWS | Airflow | CI/CD

Senior Data Engineer - Up to £85,000

Birmingham / London - Hybrid-working

Data consultancy scale-up

Are you an experienced Data Engineer? Do you want to have the opportunity...

```",,,False,,,fulltime,https://java.works-hub.com/jobs/senior-data-engineer-afc?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Birmingham,,,Senior Data Engineer in Birmingham - Digital Pursuit Limited
Nigel Frank,,,"A rapidly growing Microsoft Partner Consultancy are looking for a number of skilled Senior Data Engineers to join their expanding Data Engineering team.

They've developed a cutting-edge Microsoft-aligned Data Platform to help their customers better manage their data, expand their data capabilities, and uncover new insights.

With clients spread across the UK and Europe, this role is remote, and therefore open to candidates across the UK. Every other month there is a company-wide event in London, allowing you to celebrate success and socialise with your colleagues.

As a Senior Data Engineer, you'll work on the end-to-end development and implementation of enterprise-level data solutions for their clients. This may involve working on data and systems integration, through to data visualisation. You can expect to work on a varied tech stack including SQL, Azure Data Factory, Azure Data Lake, Azure Synapse, Power BI and Fabric.

This role would be well-suited to an ambitious Data professional, who likes the idea of joining a highly-successful Consultancy with excellent opportunities for progression.

Requirements:
• Strong SQL development skills including high-performance stored procedures
• Strong ETL experience using Azure Data Factory
• Experience working with Azure Synapse
• Experience developing reporting solutions in Power BI
• Any experience with Microsoft Fabric would be a real bonus but not essential
• Strong communication and stakeholder management skills

Benefits:
• Salary up to £60,000 depending on level of experience
• Bonus
• Company pension - 5% matched
• Life insurance
• Private medical insurance

Please Note: This is a permanent role for UK residents only. This role does not offer Sponsorship. You must have the right to work in the UK with no restrictions. Some of our roles may be subject to successful background checks including a DBS and Credit Check.

Tenth Revolution Group / Nigel Frank are the go-to recruiter for Power BI and Azure Data Platform roles in the UK, offering more opportunities across the country than any other. We're the proud sponsor and supporter of SQLBits, and the London Power BI User Group. To find out more and speak confidentially about your job search or hiring needs, please contact me directly at v.simpson@tenthrevolution.com",v.simpson@tenthrevolution.com,,True,,,fulltime,https://www.nigelfrank.com/job/a0MaA000000RzQn.9_1732532803/senior-data-engineer-remote?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Blackburn,,,Senior Data Engineer - Remote
CosmoTrace,,,"As a CosmoTrace DataOps Engineer, you will reduce the end-to-end time per cycle to get maximum value from data. You are also the best software and data engineering practices champion.

Your typical work will contain:
• Building and orchestrating data pipelines for ingesting, storing, and processing large datasets using a public cloud provider.
• Processing large datasets using Python or Scala on Dataflow, Spark, or similar batch or stream processing platforms.
• Continuous delivery in a public cloud environment.
• Enabling Data Scientists and Analysts to work with data in their sandbox environment.
• Data and pipeline validation, since trustworthy and qualitative data, is important to you.
• Automating as much as possible using CI/CD best practices.
• Democratizing data, working with IAM to make data easily available and accessible for teams.
• Researching and evaluating new tools and methodologies to see how we might work better with data.
• Working alongside developers, designers, and data scientists in teams.

As we are helping our customers understand the importance of using data, the need for DataOps Engineers is growing. You will be able to shape what working with data should be like.

Skill Set:
• Agile delivery methodologies and use of DevOps delivery infrastructure.
• Experience with SQL and working with databases, like Athena, BigQuery or Snowflake.
• Experience with Infrastructure-as-Code tools, e.g. CloudFormation, Azure ARM, Terraform.

Location – London",,,False,,,fulltime,https://uk.indeed.com/viewjob?jk=44e667d406857e26&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Ops Engineer
Ampstek,,,"Hi,

I hope you and your family are in good Health!!!

Role: Data Engineer

Location: Knutsford, UK (Hybrid)

Overview

A leading UK bank is seeking a skilled Data Engineer to support the Product Lifecycle Catalogue (hardware and software) underpinning IT Asset Management (ITAM) in ServiceNow. This role is driven by regulatory requirements and involves close collaboration with the Solution Architect and Data Analytics teams. The Data Engineer will be responsible for building and maintaining data systems that ensure data accuracy, accessibility, and security.

Key Responsibilities
• Data System Development: Design, build, and maintain robust data systems, including data pipelines, data warehouses, and data lakes, to efficiently collect, store, process, and analyze large volumes of data.
• Data Governance: Implement and enforce data governance practices, ensuring data integrity, compliance with regulatory standards, and adherence to the bank's data policies.
• Collaboration: Work closely with the Solution Architect and Data Analytics teams to align data engineering efforts with broader IT and business objectives.
• Machine Learning & Data Mining: Apply machine learning techniques and data mining processes to enhance data processing capabilities and extract valuable insights.
• Secure Coding Practices: Ensure that all data systems are developed with secure coding practices to protect sensitive information and comply with security protocols.
• Change & Transformation: Support change and transformation initiatives by developing scalable and adaptable data solutions that can evolve with the bank's needs.
• Database Management: Design and manage database structures that support efficient data storage, retrieval, and analysis.
• Strategic Thinking: Contribute to the development of data strategies that align with the bank’s long-term goals and digital transformation efforts.
• Risk & Controls: Identify potential risks in data processes and implement controls to mitigate these risks, ensuring compliance with internal and external regulations.
• Professional Collaboration: Engage with cross-functional teams to ensure that data solutions are fully integrated and support business processes effectively.

Mandatory Requirements
• DevOps: Experience with DevOps practices to support continuous integration and deployment of data systems.
• Data Governance: Strong knowledge of data governance frameworks and their application in a financial environment.
• Requirements Analysis: Ability to conduct detailed requirements analysis to inform data system design and development.
• Machine Learning: Proficiency in applying machine learning techniques to data processing and analysis.
• Data Mining: Experience with data mining techniques to extract valuable insights from large datasets.
• Strategic Thinking: Ability to align data engineering efforts with the bank’s strategic objectives.
• Data Warehousing (DW): Expertise in designing and managing data warehouses that support large-scale data analysis.
• Change & Transformation: Experience in supporting change initiatives through the development of flexible and scalable data solutions.
• Database Structures: Strong skills in designing and managing database structures that ensure efficient data storage and retrieval.
• Secure Coding Practices: Proficiency in secure coding practices to protect sensitive data.
• Risk & Controls: Knowledge of risk management and control measures specific to data systems in a financial context.
• Data Engineering: Proven experience in data engineering, with a focus on building and maintaining data systems in a complex, regulated environment.

Thanks & Regards,

Durga Prasad M | Technical Recruiter

UK/EU AmpsTek Services Limited

Mail ID: prasad.m@ampstek.com

Direct: 48 (22) 1857586

LinkedIn ID: https://www.linkedin.com/in/durga-prasad-m-a93170246/",prasad.m@ampstek.com,,False,,,fulltime,https://www.salary.com/uk-job/ampstek/data-engineer-knutsford-uk-hybrid/j202409112131077569935?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Knutsford,,,"Data Engineer @ Knutsford, UK (Hybrid)"
Acorn insurance & Financial Services LTD,,,"Due to continued growth throughout the business our tech team is levelling up to meet demands. Because of this exciting time, we are looking to recruit a Lead Cloud Data Engineer to join our tech team.

Sitting alongside the Data science Director and Head of Database Administration & Development this role will require you to perform cloud based database engineering architecture, implementation and optimisations.

Role: Lead Cloud Data Engineer

Location: Liverpool City Centre

Salary: up to £80,000 depending on experience

Working Hours: 37.5 Hours per week, Monday to Friday, 9am to 5:30pm

What you will be doing:
• Lead the design, development, and optimization of scalable data and pipelines in a cloud-based environment
• Implement, and manage data warehouses using Azure Synapse, ensuring data integrity and security
• Build, deploy, and manage ETL processes to support real-time and batch data processing using tooling across the Azure estate, Databricks, PySpark, and SQL
• Oversee data storage across both relational and non-relational databases, ensuring efficient data retrieval
• Design and implement data security protocols to safeguard sensitive information
• Collaborate with dba’s, the cloud architect, and end users to ensure seamless integration between data platforms and business needs
• Manage the ingestion, transformation, and processing of large datasets utilizing big data tooling
• Ensure optimal performance of data pipelines and infrastructure using cloud services such as Azure and AWS S3
• Lead a team of data engineers, providing technical guidance and fostering a culture of continuous learning and improvement

What we are looking for:
• 5+ years of experience in data engineering
• Expertise in Azure DWH and AWS Databricks
• Strong programming skills in Python/PySpark or other relevant languages for data manipulation and ETL workflows
• Proficiency in SQL and experience with both relational (e.g., SQL Server, MySQL) and non-relational databases (e.g., MongoDB, Cassandra)
• Experience with AWS S3 and other AWS services related to big data solutions
• Hands-on experience with big data tooling (Hadoop, Spark, etc.) for processing large datasets
• In-depth understanding of data security best practices, including encryption, access controls, and compliance standards
• Familiarity with ETL frameworks and the ability to build automated, scalable data pipelines
• Strong problem-solving skills and the ability to translate business requirements into technical solutions
• Excellent communication and skills, and the ability to document processes
• Experience with data streaming technologies (Kafka, Flink, etc.) would be preferred
• Experience with graph/vector databases would be advantageous
• Relevant certifications in Azure or AWS cloud technologies could be beneficial

About Acorn Insurance

We are a growing business with great opportunities to build your knowledge of the financial services industry. As a specialist insurance provider, we have 40 years of experience helping people secure motor insurance across all of the UK. We help more than 50,000 customers to find a policy that meets their needs and gives them the peace of mind that comes with high-quality insurance.

At Acorn Insurance we provide full training and continuous coaching inhouse you will be given full in-depth FCA regulated industry knowledge and have all the tools necessary to help you personally grow your career with the business.

We celebrate difference and it’s important to us that we have a culture where our people feel respected and valued for who they are. We pride ourselves on being accessible and encourage inclusive environments where our people can always give and show the very best of themselves.

Why Acorn Insurance?

Acorn Insurance want to give you more than a job, we want to give you a purpose and a career. So, what can we offer you as an employer? Some of the ""your tomorrow"" benefits you will receive include:
• Enhanced Annual Leave entitlement starting at 31 days and potentially increasing to 35 days per year depending on grade & length of service (including bank holidays)
• Additional Buy & Sell Holidays
• Company Sick Pay Scheme
• Company Paid Maternity & Paternity Leave
• Generous Company Pension Scheme
• A comprehensive Mental Health support system via the health assured Employee Assistance Programme (EAP)
• A wide network of mental health first aiders.
• Our very own reward and discount platform ""Your tomorrow""
• Fresh fruit Deliveries twice a week
• £250 Refer a friend bonus
• Cycle to work scheme
• Free eye test vouchers and a contribution towards the frames
• Regular Employment Engagement including ongoing competitions with fantastic prizes
• Charity fundraising events

'The Acorn Group is a Great Place to Work 2024/5.

A record number of Acorn employees completed the survey. The results overwhelmingly revealed that the group is welcoming, supportive and a great place to forge a career.

There is always room for improvement though. We have big plans to improve even further in 2025.'

All roles are subject to DBS and Financial checks, any offer made will be conditional until checks are completed to a satisfactory standard.
Unfortunately, due to the length of training and complexity",,,False,,,fulltime,https://www.reed.co.uk/jobs/lead-cloud-data-engineer/54056309?source=searchResults&filter=/jobs/it-jobs-in-liverpool&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Liverpool,,,Lead Cloud Data Engineer
Norton Blake,,,"Slough, Berkshire

Norton Blake

My client a leader in their field are on the lookout for an Audio Machine Learning Data Engineer to join their expanding team! In this role, you will leverage your expertise in audio processing, acoustics, and Python programming to develop innovative audio solutions. Working closely with machine learning engineers, manage third-party vendors, and contribute to building new, disruptive AI-driven audio technologies.

Key Responsibilities:
• Apply advanced audio processing techniques, including FIR/IIR filtering and convolution.
• Develop Python-based tools for manipulating audio files, building functions, and creating classes.
• Interpret and communicate audio specifications (eg, sample rate, bit-depth, and acoustic environment) to third-party vendors.
• Collaborate with machine learning engineers to define and meet data needs for diverse audio datasets.

Key Qualifications:
• Expertise in digital audio processing and Python programming.
• Strong understanding of acoustics, including RT60, Clarity, STI, and DRR.
• Hands-on experience with audio recording, hardware, and microphone types.
• Familiarity with machine learning concepts and their application in audio processing.
• Knowledge of open-source audio repositories (eg, TIMIT, MUSAN).

Education:
• A BSc, MSc, or PhD in Audio Engineering, Acoustics, or equivalent expertise.

If you are an Audio Machine Learning Data Engineer looking for a new opportunity, please do get in touch ASAP for a confidential discussion!

Audio Machine Learning Engineer – Permanent – Hybrid – Slough – £65-95k",,,False,,,fulltime,https://www.engineerjobboard.co.uk/job/audio-machine-learning-data-engineer/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Slough,,,Audio Machine Learning Data Engineer
Barclays,,,"Join us as a Database Engineer at Barclays where you'll build and maintain infrastructure platforms and products that support applications and data systems, using hardware, software, networks, and cloud computing platforms as required with the aim of ensuring that the infrastructure is reliable, scalable, and secure.

To be successful as a Database Engineer you should have experience with ​
• Database Administrator for PostgreSQL, serving as the highest level of technical escalation for complex database issues
• Implementing modern SRE practices in enterprise environments for databases.
• Extensive hands-on experience on Kubernetes
• Data migrations across different database technologies

Some other highly valued skills may include
• Recognized expertise in designing and implementing CI/CD processes for enterprise-scale operations.
• Proven experience in designing and executing database migration strategies in large, containerized environments.
• Experience in system configuration management tools such as Chef, Ansible for database server configurations
• Experience with scripting languages (e.g. PowerShell, Python, Bash) for automation/migration tasks

You may be assessed on the key critical skills relevant for success in role, such as risk and controls, change and transformation, business acumen strategic thinking and digital and technology, as well as job-specific technical skills

This role can be based in any of the following locations Knutsford and Glasgow

Purpose of the role

To design, develop and improve software, utilising various engineering methodologies, that provides business, platform, and technology capabilities for our customers and colleagues.

Accountabilities
• Development and delivery of high-quality software solutions by using industry aligned programming languages, frameworks, and tools. Ensuring that code is scalable, maintainable, and optimized for performance.
• Cross-functional collaboration with product managers, designers, and other engineers to define software requirements, devise solution strategies, and ensure seamless integration and alignment with business objectives.
• Collaboration with peers, participate in code reviews, and promote a culture of code quality and knowledge sharing.
• Stay informed of industry technology trends and innovations and actively contribute to the organization’s technology communities to foster a culture of technical excellence and growth.
• Adherence to secure coding practices to mitigate vulnerabilities, protect sensitive data, and ensure secure software solutions.
• Implementation of effective unit testing practices to ensure proper code design, readability, and reliability.

Assistant Vice President Expectations
• To advise and influence decision making, contribute to policy development and take responsibility for operational effectiveness. Collaborate closely with other functions/ business divisions.
• Lead a team performing complex tasks, using well developed professional knowledge and skills to deliver on work that impacts the whole business function. Set objectives and coach employees in pursuit of those objectives, appraisal of performance relative to objectives and determination of reward outcomes
• If the position has leadership responsibilities, People Leaders are expected to demonstrate a clear set of leadership behaviours to create an environment for colleagues to thrive and deliver to a consistently excellent standard. The four LEAD behaviours are: L – Listen and be authentic, E – Energise and inspire, A – Align across the enterprise, D – Develop others.
• OR for an individual contributor, they will lead collaborative assignments and guide team members through structured assignments, identify the need for the inclusion of other areas of specialisation to complete assignments. They will identify new directions for assignments and/ or projects, identifying a combination of cross functional methodologies or practices to meet required outcomes.
• Consult on complex issues; providing advice to People Leaders to support the resolution of escalated issues.
• Identify ways to mitigate risk and developing new policies/procedures in support of the control and governance agenda.
• Take ownership for managing risk and strengthening controls in relation to the work done.
• Perform work that is closely related to that of other areas, which requires understanding of how areas coordinate and contribute to the achievement of the objectives of the organisation sub-function.
• Collaborate with other areas of work, for business aligned support areas to keep up to speed with business activity and the business strategy.
• Engage in complex analysis of data from multiple sources of information, internal and external sources such as procedures and practises (in other areas, teams, companies, etc).to solve problems creatively and effectively.
• Communicate complex information. 'Complex' information could include sensitive information or information that is difficult to communicate because of its content or its audience.
• Influence or convince stakeholders to achieve outcomes.

All colleagues will be expected to demonstrate the Barclays Values of Respect, Integrity, Service, Excellence and Stewardship – our moral compass, helping us do what we believe is right. They will also be expected to demonstrate the Barclays Mindset – to Empower, Challenge and Drive – the operating manual for how we behave.",,,False,,,fulltime,https://search.jobs.barclays/job/knutsford/database-engineer/13015/72846313920?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Knutsford,,,Database Engineer
RVU,,,"Staff Data Engineer

Department: Engineering

Employment Type: Full Time

Location: Cardiff
Description
Confused.com is the UK’s first comparison platform for car insurance. We’ve been helping customers since 2002 by empowering them to make better decisions around insurance and financial services. Our mission is simple: take away the confusion when comparing financial products and services to help you save time and money.

We’re part of RVU, a group of online brands (including Uswitch, Tempcover, and Money.co.uk) that empowers people to make confident decisions across a range of household services.

RVU’s purpose is to simplify complex marketplaces with intuitive and accessible applications that genuinely improve people’s lives. Saving a few hundred pounds a year on bills makes a fundamental difference to vulnerable people who sometimes have to choose between paying for utilities or groceries.

Our platforms serve millions of users a month, process thousands of comparisons a day, and drive hundreds of complex integrations with vastly different partners. We’re a tech- driven business that focuses on agile delivery and cross functional product teams.

We are creating the next generation of comparison platforms, and as we scale we are looking for passionate, empathetic engineers to build highly performant, accessible, and beautiful consumer experiences to facilitate switching and comparisons on the web.

What you will be responsible for
Excellence: Work alongside established & experienced engineering teams, whilst supporting and growing the organisation’s understanding & utilisation of modern technology

Collaboration: Work with various cross-functional disciplines across the organisation to make ideas a reality, whilst taking an active role in shaping and delivering the ongoing technical vision of the organisation alongside your peers

Autonomy: Authority over technical strategy, decisions and implementation approach, so you can deliver using practices that align with your preferred ways of working

Data Driven: Utilise rich logs, metrics, and data to monitor and improve system performance & reliability

Culture: Enhancing a diverse engineering culture by taking part in various technical catch ups, working groups and All Hands

Experience: Enrich RVU’s perspective by sharing your experience, knowledge & expertise in a continuous learning environment.
• Proactively identify opportunities for improvement across the organisation
• Manage your time effectively between team and org level contributions
• Rotate around the business to build relationships and act as a multiplier

What we look for in you
Experience working in large and small agile teams of engineers, and eager to collaborate with other disciplines, such as Marketing, Data Analytics & Product Owners

Good understanding of Cloud technologies, and their application to solve problems such as Event/Data Ingestion and 3rd Party API Integrations. As well as a strong appreciation of A/B Testing, Monitoring and DevOps principles

A breadth of knowledge about all aspects of software development and familiarity with procedural & functional languages, preferably having experience with Databricks, Python and SQL.

Pragmatic approach to deliver effective solutions to address business & consumer challenges

Committed to your own development and excited to make a direct, substantial impact within a company that provides you with full autonomy to release changes daily

High level of proficiency developing applications using most of the following:
• Python
• HTML, CSS, JavaScript
• SOLID Principles
• Web API
• React/Typescript
• C# ASP.NET, .Net Core
• Familiarity working within a SCRUM agile development environment.
• A good understanding of development methodologies and design patterns.
• The ability to investigate issues and both define and follow through on their resolution.
• Experience working in a Cloud computing environment.
• Experience in containerisation.
• Experience using IaC.

What we offer
We want to give you a great work environment; contribute back to both your personal and professional development; and give you great benefits to make your time at RVU even more enjoyable. Some of these benefits include:
• Employer matching pension up to 7.5%
• Hybrid approach of in-office and remote working, and a “Work from Home” budget to help contribute towards a great work environment at home
• Excellent maternity, paternity and adoption leave policy, for those key moments in your life
• 25 days holiday (increasing to 30 days) + 2 days “My Time” per year
• Up to 30 days per year “working from anywhere”
• A healthy learning and training budget
• Electric vehicles scheme
• Health insurance
• Access to the Calm and Peppy app for physical and mental health
• Regular events - from team socials to company-wide events with insightful external speakers, we want to make sure our colleagues continue to feel connected",,,True,,,fulltime,https://careers.rvu.co.uk/en/jobs/268227/hiring-process?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Cardiff,,,Staff Data Engineer
NBC Universal,,,"Brentford, Middlesex

NBC Universal

Company Description

We create world-class content, which we distribute across our portfolio of film, television, and streaming, and bring to life through our theme parks and consumer experiences. We own and operate leading entertainment and news brands, including NBC, NBC News, MSNBC, CNBC, NBC Sports, Telemundo, NBC Local Stations, Bravo, USA Network, and Peacock, our premium ad-supported streaming service. We produce and distribute premier filmed entertainment and programming through Universal Filmed Entertainment Group and Universal Studio Group, and have world-renowned theme parks and attractions through Universal Destinations & Experiences. NBCUniversal is a subsidiary of Comcast Corporation.

Here you can be your authentic self. As a company uniquely positioned to educate, entertain and empower through our platforms, Comcast NBCUniversal stands for including everyone. Our Diversity, Equity and Inclusion initiatives, coupled with our Corporate Social Responsibility work, is informed by our employees, audiences, park guests and the communities in which we live. We strive to foster a diverse, equitable and inclusive culture where our employees feel supported, embraced and heard. Together, we’ll continue to create and deliver content that reflects the current and ever-changing face of the world.

Job Description

Our Direct-to-Consumer (DTC) portfolio is a powerhouse collection of consumer-first brands, supported by media industry leaders, Comcast, NBCUniversal, and Sky. When you join our team, you’ll work across our dynamic portfolio including Peacock, NOW, Fandango, SkyShowtime, Showmax, and TV Everywhere, powering streaming across more than 70 countries globally. And the evolution doesn’t stop there. With an unequaled scale, our teams make the most out of every opportunity to collaborate and learn from one another. We’re always looking for ways to innovate faster, accelerate our growth, and consistently offer the very best in the consumer experience. But most of all, we’re backed by a culture of respect. We embrace authenticity and inspire people to thrive.

As part of the Direct-to-Consumer Decision Sciences team, the Data Engineer will be responsible for creating a connected data ecosystem that unleashes the power of our streaming data with a focus on international propositions. We gather data from across all customer/prospect journeys in near real-time, to allow fast feedback loops across territories; combined with our strategic data platform, this data ecosystem is at the core of being able to make intelligent customer and business decisions.

In this role, the Data Engineer will share responsibilities in the development and maintenance of optimized and highly available data pipelines that facilitate deeper analysis and reporting by the business, as well as support ongoing operations related to the Direct-to-Consumer data ecosystem.

Responsibilities include, but are not limited to:
• Develop and maintain batch and streaming data pipelines according to business and technical requirements.
• Deliver observable, reliable and secure software, embracing “you build it, you run it” mentality, and focus on automation.
• Continually work on improving the codebase and have active participation in all aspects of the team, including agile ceremonies.
• Take an active role in story definition, assisting business stakeholders with acceptance criteria.
• Work with Principal Engineers and Architects to share and contribute to the broader technical vision.
• Practice and champion best practices, striving towards excellence and raising the bar within the department.
• Operationalize data processing systems (DevOps) and system observability (SRE)

Responsibilities include, but are not limited to:
• Help manage a high-performance team of Data Engineers
• Contribute to and help lead team in design, build, testing, scaling and maintaining data pipelines from a variety of source systems and streams (Internal, third party, cloud based, etc.), according to business and technical requirements.
• Deliver observable, reliable and secure software, embracing “you build it you run it” mentality, and focus on automation and GitOps.
• Continually work on improving the codebase and have active participation and oversight in all aspects of the team, including agile ceremonies.
• Take an active role in story definition, assisting business stakeholders with acceptance criteria.
• Work with Principal Engineers and Architects to share and contribute to the broader technical vision.
• Develop and champion best practices, striving towards excellence and raising the bar within the department.
• Develop solutions combining data blending, profiling, mining, statistical analysis, and machine learning, to better define and curate models, test hypothesis, and deliver key insights
• Operationalize data processing systems (dev ops)

Qualifications
• 3-5 years relevant experience in Data Engineering
• Experience of near Real Time & Batch Data Pipeline development in a similar Big Data Engineering role.
• Programming skills with an OOP language (e.g., Java, C++)
• Proficient with SQL
• Experience working in a cloud environment such as Google Cloud Platform or AWS
• Hands on programming experience of the following (or similar) technologies:
• Kubernetes, Docker
• Apache Beam, Apache Flink, Apache Spark
• Google BigQuery, Snowflake
• Google BigTable
• Google Pub/Sub, Kafka
• Apache Airflow
• Experience implementing observability around data pipelines using SRE best practices.
• Experience in processing structured and unstructured data into a form suitable for analysis and reporting with integration with a variety of data metric providers ranging from advertising, web analytics, and consumer devices.
• Bachelors’ degree with a specialization in Computer Science, Engineering, Physics, other quantitative field or equivalent industry experience.

Desired Characteristics
• Strong Test-Driven Development background, with understanding of levels of testing required to continuously deliver value to production.
• Experience with large-scale video assets
• Ability to work effectively across functions, disciplines, and levels
• Team-oriented and collaborative approach with a demonstrated aptitude, enthusiasm and willingness to learn new methods, tools, practices, and skills
• Ability to recognize discordant views and take part in constructive dialogue to resolve them
• Pride and ownership in your work and confident representation of your team to other parts of

Additional Information

NBCUniversal’s policy is to provide equal employment opportunities to all applicants
and employees without regard to race, color, religion, creed, gender, gender identity
or expression, age, national origin or ancestry, citizenship, disability, sexual
orientation, marital status, pregnancy, veteran status, membership in the uniformed
services, genetic information, or any other basis protected by applicable law.

If you are a qualified individual with a disability or a disabled veteran, you have the
right to request a reasonable accommodation if you are unable or limited in your
ability to use or access as a result of your disability. You can
request reasonable accommodations by emailing email protected .",,,False,,,fulltime,https://www.dataanalystjobs.co.uk/job/senior-data-engineer-global-streaming-4/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Brentford,,,"Senior Data Engineer, Global Streaming"
Starcount,,,"Company Description

Starcount is a new breed of consultancy blending proprietary technology and machine learning with a deep expertise and pedigree in data-based insights.

We partner our clients in navigating the complexities of customer behaviours and passions. We can predict seemingly irrational behaviour.

We will tell you things no one else can. We drive these insights through businesses and we do this at scale and quicker than anyone else.

Job Description

We're creating a SaaS platform that interprets complex data and tells stories about customer passions and behaviour and we're looking for a Data Engineer to push boundaries with what is possible with our data; to design, develop and and automate a data pipeline that will collect data from numerous transactional, social media and geographical data sets as we build the next generation of our product.
• Applying systems architecture and software design skills in the development of data pipelines
• Design and develop new algorithms for extracting insight from social data
• Develop crawlers to extract data from the web or APIs
• Develop infrastructure around existing internal tools to enhance capabilities and improve data flow.
• Implement statistical models and algorithms including clustering on large scale graph data

Qualifications

Some of the skills and technologies you'll need experience of:

Hadoop, PostgreSQL, Spark, SQL, Pig, Python, Pyspark

Additional Information

We work in an open plan office right in the heart of Oxford Circus. We have a fun social culture with regular showcase (lunch and learn) sessions and after-hours social functions, all adding up to a balanced work-life environment with a 4pm finish on Fridays!",,,False,,,fulltime,https://uk.indeed.com/viewjob?jk=2fe98f7e0abfb8de&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Engineer (Hadoop / Postgres / SQL)
JNCC,,,"Job Description

Post Title: Senior Data Engineer

Team: Digital and Data Solutions

Ref No: 2023120

Grade: S (SEO)

Type of appointment: Permanent

Location: Peterborough or Aberdeen

Salary: £38,320 + £5,000 depending on experience.

An additional Recruitment and Retention Allowance (RRA) up to £5,000 per annum, pro rata, may be agreed. This allowance is discretionary and will depend on candidate's qualifications and experience.

This post will have a base in either Peterborough or Aberdeen.

JNCC has adopted a hybrid working approach, allowing colleagues to benefit from time in the office, with the flexibility also to work from home. Employees are expected to work from our office base for 1 – 2 days a month as a minimum, this will vary by team and the exact balance will depend on the nature of your role. We can provide more details at the interview and offer stages.

Who are JNCC?

Established in 1991, we’re the UK’s statutory advisor on issues affecting the natural environment across the UK and internationally. Our primary role is advising all four Governments of the UK. We also work with private sector organisations to support decision making on the sustainable use of marine waters and natural resources around the UK. JNCC is led by the Joint Committee, which brings together members from the nature conservation bodies for England, Scotland, Wales and Northern Ireland and independent members appointed by the Secretary of State for the Environment, Food and Rural Affairs under an independent Chair. Support is provided to the Committee by approx. 300 people who bring together scientific and technical expertise, extensive knowledge of policy at global, European and national levels, and skills in working with other organisations. Staff are based in two main offices in Peterborough and Aberdeen.

Why JNCC?

We’re small enough (c.300 staff) that your voice is heard by everyone including the CEO, but big enough that we have all the skills, resources and people you’ll need to get the job done. All our staff are passionate about conservation and making a difference to the world we live in. We have a very flexible, inclusive and welcoming organisational culture. Our Executive Management provides employees with the freedom and tools you will need, and our friendly team will assist you in your role.

JNCC is committed to maintaining employee health and wellbeing, whether it is physically, emotionally, financially or socially, and offers a range of benefits to support employees in this. Such benefits include the option to join the Civil Service Pension Scheme, professional and personal development opportunities as well as an exciting job in a unique environment.

Hours of work: Full-time

Normal minimum hours of attendance for the post are 36 hours per week over a 5-day period, Monday to Friday.

Flexi time is available. This post may also be suitable for job share.

Annual Leave:

The annual leave allowance is 25 days per year, rising to 30 days per year after 5 years’ service. There are also 12 days public and privilege leave. Part-time staff will receive this on a pro rata basis.

Post background

Are you an experienced data practitioner who is passionate about the management, design and transformation of data? Are you looking for a role that will allow you to have a positive impact on biodiversity and nature at a UK level?

This exciting post will lead the data engineering function within JNCC’s Digital and Data Solutions Team (DDS). You will explore and lead data innovation opportunities with a focus on process automating data transformation across a range of delivery areas including generation of national reports, UK indicator production, data support on JNCC digital projects, and processing satellite imagery data to inform policy and operations. There will also be opportunities to enhance our scientific and corporate data processes and products. To deliver this work, applicants should be confident in establishing best practice for new tools and techniques, generating data pipelines, conducting robust quality assurance, and utilising simple and advanced analytical techniques.

You will manage the data engineering teamlet (five people) within DDS, including line management of three of these staff. This will include overseeing the team’s programme of work and identifying opportunities for the teamlet to add value across the organisation. You will champion good data practices and suitable solutions for JNCC and be comfortable coaching and mentoring others, with a keen eye for areas where the organisation could benefit from building additional skills.

Ultimately, we are looking for the post holder to be proactive and influential in establishing a lasting data culture. JNCC has a diverse delivery portfolio and the DDS team work across the organisation, so this post would be well suited to someone with a passion for digging into complex challenges and identifying innovative and tailored solutions.

Does this sound like you but you may need to develop in some areas? Don’t tune out now! Your application and interview (if selected) will be assessed on evidence you provide from your previous experiences. We understand that it can be tough to meet all the job specification criteria, so please don't be discouraged from applying if there are some knowledge gaps - JNCC is committed to being a learning organisation that supports staff development. We value diversity at JNCC and want to hear about the unique thing(s) you can bring to the role.

Post Duties

Your main responsibilities will include, but are not limited to:
• Technical leadership – Initiate, plan and lead DDS’ data activities. You will work with data specialists across the organisation to deliver on our reporting responsibilities, build lasting solutions for data processing, and identify and champion data services, technologies, and standards with internal and external stakeholders.
• Innovation - Support the organisation in identifying area for improvement and advising on appropriate solutions, including automation and productionising.
• Problem solving - This post will support in investigating data issues, developing improvement plans and ensuring our data is fit for purpose and delivered effectively;
• Programme oversight – oversee and manage delivery plans for the data engineering teamlet, who contribute to a range of programmes of work across the organisation. This role will focus on scheduling existing programmes of work, scoping new work areas, and identifying opportunities for the data engineering function to add value to JNCC’s portfolio;
• Team leadership – the lead data engineer will lead a teamlet of five data engineers, with direct line management of three staff. You should be comfortable coaching and developing staff and identifying opportunities to build skills and knowledge in themselves and others.

Technical

To be a successful candidate you will be/have:
• Strong coding background in Python or R and strong SQL skills
• Experience in building data pipelines (ETL and/or analytical pipelines)
• Knowledge of or experience in working with spatial data and GIS Software applications.

While not a requirement, if you have experience in data management (lifecycle and governance) or experience with any particular data tools or systems, we would love to hear about it in your application.

Experience

To be a successful candidate you will have:
• Experience in handling and manipulating data from multiple sources, with proven programming skills.
• Excellent communication and presentation skills, with the ability to present to technical and non-technical audiences and lead discussions on data.
• Experience in identifying opportunities/challenges and working with technical and non-technical experts to define and prioritise user requirements (business analysis).
• While not a requirement, if you have experience of leading a team or individuals, including wellbeing, workload management, objective setting, performance review and staff development tell us about this.
• Managing a Quality Service
• Leadership
• Making Effective Decisions
• Changing and Improving

Behaviours

In the event that we receive a large volume of applications we reserve the right to conduct the sift based on the Lead Behaviour of Managing a Quality Service

Please see the CS Behaviours framework for more details at this grade:

https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/717275/CS_Behaviours_2018.pdf

Nationality requirements

This job is broadly open to the following groups:
• UK nationals
• nationals of Commonwealth countries who have the right to work in the UK
• nationals of the Republic of Ireland
• nationals from the EU, EEA or Switzerland with settled or pre-settled status or who apply for either status by the deadline of the European Union Settlement Scheme (EUSS)
• relevant EU, EEA, Swiss or Turkish nationals working in the Civil Service
• relevant EU, EEA, Swiss or Turkish nationals who have built up the right to work in the Civil Service
• certain family members of the relevant EU, EEA, Swiss or Turkish nationals

JNCC do not provide sponsorship.

Apply Here",,,False,,,fulltime,https://www.environmentjobs.co.uk/green-jobs/senior-data-engineer.70970.htm?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,,,,Senior Data Engineer
REAL Technical Solutions Limited,,,"Dorking, Surrey

REAL Technical Solutions Limited

Senior Azure Data Engineer – Hybrid/Surrey/Hampshire

£70,000 plus bonus excellent benefits & growth potential (fantastic employer)/Surrey (Dorking) or Hampshire (Basingstoke) – 2 days per week in the office

The overall package is worth around £80-95k.

My client a leading financial services company with amazing company benefits, seek an experienced Senior Data Engineer to take on the role of Azure Tech Lead. In this role, you will be responsible for owning and improving their existing Azure data infrastructure.

Notes:

They will consider someone with a general Azure skill set, who could be used for DevOps and improving the cloud set up and structure. If you don’t have the specific data engineering skill set on the cloud, you must be capable and willing to pick these up. An ideal person for this role is a Cloud engineer who is interested in or has come from the data side of things.

As the Senior Azure Data Engineer, you will:
• Guide developments and enhancements, ensuring robust support and maintenance practices are in place, and adopting industry standards throughout their data journey.
• Your expertise will be essential in guiding data projects and changes, ensuring best practices in Azure data processing and management are adopted.
• As the Lead Azure Data Engineer, you will oversee and improve the current Azure data setup, ensuring it is robust, scalable, and secure.
• You will lead the development and enhancement of our cloud infrastructure, providing expert guidance and support to the team.
• Implementing and managing robust support and maintenance approaches to ensure the reliability and performance of their Azure environment will be a key part of your role.
• Additionally, you will ensure the adoption of industry standards and best practices throughout the data journey.
• You will guide data projects and changes, ensuring they follow good practices and align with business objectives.
• Continuously increasing business knowledge with a consultative approach will be crucial, focusing on improving business outcomes.
• You will support and guide team members in their delivery, owning pieces of work and projects from design through to release.
• Interacting with business partners with a high degree of professionalism, providing reliable judgement and decision-making, will also be a significant aspect of your role.

Core Data Engineer Capabilities for the Senior Azure Data Engineer:

Deep expertise in at least two of the following, with basic capabilities in all others:
• Software Engineering: Expertise in at least one relevant object-oriented programming language (ie Java/Scala, Python). Experience in DevOps best practice including CI/CD, process automation and optimization.
• Data Architecture and Infrastructure: Good understanding of data architecture principles and related infrastructure requirements, covering on-prem and Cloud platforms.
• Holistic Data Preparation: The ability to understand and present data in the appropriate context, including a good understanding how the data will build towards a business solution.
• Data Extraction, Transform & Load: Preferred skills include: Expertise in writing complex SQL queries that join multiple tables/databases.
• Independently explore databases/tables or other Legacy data content to identify best data sources to solve business problems.
• Demonstrates ability to troubleshoot complex SQL queries with little guidance.
• Demonstrates ability to create logical data models by combining data from multiple sources including internal and external data.

Core business capabilities for the Senior Azure Data Engineer:
• Demonstrated communication skills, leadership experience working with senior management and executive leadership, and attention to detail while effectively and independently prioritizing work and managing multiple projects simultaneously.
• Leadership Capabilities: Actively coaches, mentors and delivers support to team members, especially within areas of expertise. Responds quickly and positively to change and is viewed as a promoter of change management. Provides technical leadership and direction for data and analytics initiatives, ensuring output conforms to agreed upon quality attributes.
• Preferred characteristics: Entrepreneurial self-starter. A thorough, results-oriented problem-solver, and a lifelong learner with voracious curiosity. Ability to conduct independent research and development.
• Bachelor’s degree in quantitative field is preferred, otherwise addition technical profession experience is required.

Senior Azure Data Engineer – Hybrid/Surrey

£70,000 plus bonus excellent benefits & growth potential (fantastic employer)/Surrey (or Hampshire) – 2 days per week in the office

The overall package is worth around £80-95k.",,,False,,,fulltime,https://www.engineerjobboard.co.uk/job/senior-azure-data-engineer-hybrid-surrey-hampshire/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Dorking,,,Senior Azure Data Engineer – Hybrid/Surrey/Hampshire
Harnham - Data & Analytics Recruitment,,,"SENIOR DATA ENGINEER

£55,000-£65,000 + BENEFITS

LEEDS (Hybrid)

A leading company in the retail industry is seeking a proactive Data Engineer to join their innovative team.

THE COMPANY:

This is a well-established brand driven by an ambitious vision. They are currently investing in their data team, and are looking for a Data Engineer to help gather requirements and build solutions.

THE ROLE:

A Data Engineer will need to:
• Work closely with stakeholders across the business
• Manage data warehouse end-to-end (gathering requirements and building solutions)
• Helping to build data models

YOUR SKILLS AND EXPERIENCE:

A successful Data Engineer will have the following skills and experience:
• Ability and experience interacting with key stakeholders
• Strong experience in SQL/Python
• Experience with Azure/ADF
• Background in CI/CD

THE BENEFITS:

You will receive a salary, dependent on experience. Salary is up to £65,000 On top of the salary there are some fantastic extra benefits.

HOW TO APPLY

Please register your interest by sending your CV to Molly Bird via the apply link on this page.",,,False,,,fulltime,https://www.reed.co.uk/jobs/senior-azure-data-engineer/54226863?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Burnley,,,Senior Azure Data Engineer
CV Library,,,"Senior Azure Data Engineer - Remote - £60,000

I am working with a data-driven Microsoft partnered consultancy who are looking for a Senior Data Engineer to join their growing team. You will have the opportunity to work with some of the latest Microsoft technologies such as Microsoft Fabric and Databricks.

You will join a team at the center of a number of data-driven projects where you will be responsible for the design, development, and creation of data solutions. You will work on the full end-to-end product lifecycle from platform design to insights creation.

Responsibilities:
• Design, develop and maintain data pipelines that are responsible for the ingestion and transformation of data between different sources.
• Create and develop data models.
• The creation of insightful and accurate data visuals/reports/dashboards.
• Work closely with stakeholders from different departments to ensure their data needs can be met.

To be successful in the role you will have:
• Strong ETL experience with tools such as ADF or SSIS.
• Strong experience with Python/PySpark.
• Experience working with Azure technologies - Synapse, Fabric, Data Lake.
• Data visualization experience with Power BI.

This is just a brief overview of the role. For the full information, simply apply to the role with your CV, and I will call you to discuss further. My client is looking to begin the interview process ASAP, so don't miss out, APPLY now!
#J-18808-Ljbffr",,,True,,,fulltime,https://talents.studysmarter.co.uk/companies/cv-library/senior-azure-data-engineer-remote-60000-272089/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Southampton,,,"Senior Azure Data Engineer – Remote – £60,000"
Collinson,,,"Collinson is the global, privately-owned company dedicated to helping the world to travel with ease and confidence. The group offers a unique blend of industry and sector specialists who together provide market-leading airport experiences, loyalty and customer engagement, and insurance solutions for over 400 million consumers.

Collinson is the operator of Priority Pass, the world’s original and leading airport experiences programme. Travellers can access a network of 1,500+ lounges and travel experiences, including dining, retail, sleep and spa, in over 650 airports in 148 countries, helping to elevate the journey into something special. We work with the world’s leading payment networks, over 1,400 banks, 90 airlines and 20 hotel groups worldwide.

We have been bringing innovation to the market since inception – from launching the first independent global VIP lounge access Programme, Priority Pass to being the first to sell direct travel insurance in the UK through Columbus Direct and creating the first loyalty agency of its kind in the travel sector with ICLP. Today we still invest heavily in innovation to ensure that we continue to deliver superior customer experiences.

Key clients include Visa, Mastercard, American Express, Cathay Pacific, British Airways, LATAM, Flying Blue, Accor, EasyJet, HSBC, Chase, HDFC.

Our mission is focused on doing good beyond profit, which for us means we seek out opportunities for our people to share in our success and that we give back to the communities and people within which we work.

Never short of ambition, the success of our business is delivered through the diverse and talented team of over 1,800 global colleagues.

Purpose of the job

Working within the Technical Delivery Team, you will be responsible for data collection, validation and loading of the core business data for Travel Experiences. You will be the quality gate that ensures accurate data is loaded into our Billing and Reporting databases, which reconciles back to a combination of source systems and Excel data sets. You will be required to understand our business and the complexity behind our data and systems and have the ability to improve existing processes that are in place.

A key responsibility will be to support the monthly Billing processes, working alongside the Operations and Finance teams to ensure billing data is collected, prepared and loaded and then check that it reconciles against the varying sources. As well as supporting the existing SQL Server data solutions, the Business knowledge you gain will support the design and development of a new data platform that will enhance the reporting and analytic capabilities of the business. You will be skilled in using the Microsoft BI stack and be comfortable with SQL, SSRS and Excel.

You are joining a growing team who are tasked with revolutionising the way we capture and use data.

Key Responsibilities

· Work alongside stakeholders to develop and roll out business critical reporting functions

· Maintain data quality in operational databases

· Follow established change control processes to ensure integrity of code

· Translate business needs into technical requirements

· Generate and deliver quality reports to SLA

· Conduct quality assurance checks on all deliverables

· Perform regular reviews of operational tasks and suggest automation wherever possible

· Acquire expert knowledge of Operational systems and processes

· Provide bespoke and regular insight/reports to Operations, Commercial and Finance teams through analysis of data

· Contribute to the overall programme of business change

· Create and maintain documentation

Knowledge, skills and experience required

· Strong data analysis and data profiling skills with key emphasis on data quality

· Strong analytical and problem solving skills

· Good understanding of relational databases and the ability to query data

· Previous Billing or Operational experience in an analytical or reporting role

· Excellent knowledge of BI Technologies:

o Alteryx development and Gallery job execution essential

o Snaplogic desirable

o Tableau desirable

· Experience of:

o Microsoft SQL server

o SQL Server Reporting Services (SSRS)

o SQL Server Integration Services (SSIS)

· Experience with Microsoft Access DB desirable

· MYSQL experience desirable

· Knowledge of the Payment Card Industry and PCI DSS

· Technical writing and documentation skills

· Attention to detail and accuracy

· A methodical and structured approach to work

· Ability to recommend and suggest data and process improvements based on knowledge gained

· Excellent communicator and aptitude to be internal client facing

· Be able to demonstrate creative thinking to develop innovative solutions

· Able to work independently and multi task effectively

· Organised and able to manage individual workload and operate within the context of a team

· Demonstrate flexibility in thinking and attitude with the ability to manage changing priorities

Collinson is an equal opportunity employer and welcomes differences in all their forms including: colour, race, ethnicity, gender identity, sexual orientation, neurodivergence, family status, age, individuals with disabilities and people from all backgrounds, cultures and experiences as we strongly believe this contributes to our on-going success.

We are focused on continually evolving our purpose driven, high performing culture, providing an environment where our people have the opportunity to achieve their full potential and do interesting and meaningful work. Our company values are: Act smarter, Do the right thing, One team and Be insight led. These help guide everything we do internally in terms of how we think, act and interact, right through to how we deliver value to our customers and clients.

In your application, please feel free to note which pronouns you use (For example - she/her/hers, he/him/his, they/them/theirs, etc).

If you need any extra support throughout the interview process, then please email us at ukrecruitment@collinsongroup.com",ukrecruitment@collinsongroup.com,,False,,,fulltime,https://www.adzuna.co.uk/jobs/details/4910711388?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,,,,Operations BI Developer/Data Engineer
Harnham - Data & Analytics Recruitment,,,"ANALYTICS ENGINEER

£65,000-£70,000 + BENEFITS

PIMARILY REMOTE

An opportunity to join a popular telecoms company expanding into new markets!

THE COMPANY:

Over the past few years, this telecoms company has expanded and focused on a product technology led approach. With a rich data set, they have lots of data to work with and are keen to bring in an Analytics Engineer to help with data modelling and transformation.

THE ROLE:

A remote working Analytics Engineer will need to:
• Design and build data models
• Support implementation and maintenance of ELT pipelines
• Ingest data into Snowflake
• Transform data using DBT
• Empower teams to make data driven teams

YOUR SKILLS AND EXPERIENCE:

A successful Analytics Engineer will have the following skills and experience:
• Ability and experience interacting with key stakeholders
• Strong experience in SQL/Python
• Data Cloud Tech experience - e.g. Snowflake/BigQuery/Databricks
• Data transformation experience using DBT

THE BENEFITS:

You will receive a salary, dependent on experience. Salary is up to £65,000 On top of the salary there are some fantastic extra benefits.

HOW TO APPLY

Please register your interest by sending your CV to Molly Bird via the apply link on this page.",,,True,,,fulltime,https://www.reed.co.uk/jobs/analytics-engineer/54227794?source=searchResults&filter=/jobs/it-jobs&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Manchester,,,Analytics Engineer
Fusion Network Cabling,,,"Engineers should be based in the East Midlands, with a full UK driving licence and access to their own vehicle. Accommodation, milage and food allowance will be provided for projects outside travelling expectancy.

The ideal candidate must have a valid CSCS/ECS card. Ipaf is desirable but not essential. Having your own tools and drills is expected.

The ideal engineer should be professional, reliable, efficient and able to communicate well with customers. You will be required to manage a small team of engineers and work closely with project management to deliver high quality installations, on time and on budget.

Essential experience and skills:
• Installation, testing and termination of Cat5e – Cat6a
• Fibre Optic installation – not essential
• Cabinet upgrades and tidies
• Installation of trunking and containment
• Voice cabling and troubleshooting
• Wifi access point installation
• Ability to read drawings
• Knowledge of the latest Health & Safety infrastructure construction guidelines, standards and fire safety
• Excellent time management and organisation

Within your application, please summarise training courses attended, certificates gained and any security clearances obtained.

Please email CV’s to the following:
• •

Job Type: Full-time

Pay: £150.00-£200.00 per day

Schedule:
• 8 hour shift

Work Location: Hybrid remote in Belper

Reference ID: FUSIONNC",,,True,,,fulltime,https://uk.indeed.com/viewjob?jk=0db79207de337e79&utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Belper,,,Senior Data Cabling Engineer
Quant Capital,,,"ETL Data Engineer – Fintech

To £75,000 + 10% no-cont pension, bonus and shares

Remote with occasional travel to the London Office.

Quant Capital is urgently looking for a Data Engineer to join our well-known Fintech50 client who produces software disrupting the wealth management market.

My client has dominated the domestic market with their SaaS offering and they are looking to replicate this success internationally, to do this they are investing heavily in technologists from software developers to Technical operations.

The development team works in a very agile fashion on two week sprints. Most of the business is now focussed around AWS. We are looking for someone who has a passion for real-time data,

Day to Day the Data Engineer will:
• Design, build, monitor, and manage large scale batch and streaming data pipelines in AWS cloud environment
• Data Analysis
• Data modeling

The Data Engineer Must have:
• Comp Sci or Engineering Degree
• Experience in building complex data pipelines/ETL/ELT scripts
• Extensive experience with SQL
• Excellent knowledge of AWS and components such as S3, Kinesis, DMS, SNS, Glue, Athena, RDS
• Experience with Data Warehouse databases like Snowflake/Redshift/ BigQuery
• Experience with Python/PySpark
• Experience with implementing Rest APIs.
• Business Intelligence (BI) knowledge/experience
• Knowledge on tools like Terraform, Airflow, DBT and Harness
• Modern data engineering practices

The environment is that of Facebook or Google, relaxed open with time to think and make the right decisions. The atmosphere is calm and relaxed with an open dress code. This is a role for technologists, those who are motivated by the sharp end of technology and the possibility of making serious money doing something you are passionate about.

My client is based in Central London but the role is remote for the immediate future.

ETL, DATA,, EC2, DevOps, Linux, AWS, Java, CLoudwatch",,,True,,,fulltime,https://uk.jooble.org/jdp/5578945927483122551?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,ETL Data Engineer
Nigel Frank,,,"Data Engineer - London - GBP70,000

a0MaA000000TxpV.3_1734081923

Data Engineer - London - £70,000

An established financial services organisation based in Central London are looking to expand their data function with the addition of an experienced Data Engineer to their team. You will join them at the beginning of a data warehouse integration project follow the acquisition of another business. You will be responsible for the re-design and development on the current data warehouse architecture that will be suitable for use of both businesses.

You will work to optimise and re-develop ETL processes ensure that data is ingested into the new-look data warehouse ready for analysis and reporting. You will ensure that the data warehouse is fit for purpose and is fully scalable based on future project plans. You will work as part of a wider data team, collaborating closely with other developers and speak with members of non-technical teams acting as subject matter expert.

To be successful in this role you will have.
• Excellent T-SQL programming experience - writing complex queries and developing/opimising stored procedures, tables, views, functions etc
• Strong ETL experience using SSIS
• Strong SQL Data Warehouse development experience
• Scripting experiences with languages such as PowerShell, C# or Python would be beneficial

The organisation operate on a hybrid basis from their Central London hub where you would work on a hybrid basis three times per week. These will be team days where you will work alongside other members of the team. Benefits of the role include -
• Salary up to £70,000 depending on experience
• 25 days annual leave - increasing over time with length of service
• Company pension scheme
• Private medical insurance
• Other optional benefits

This is just a brief overview of the role. For the full information, simply apply to the role with your CV, and I will call you to discuss further. My client is looking to begin the interview process ASAP, so don't miss out, APPLY now!

Nigel Frank International are the go-to recruiter for Power BI and Azure Data Platform roles in the UK offering more opportunities across the country than any other recruitment agency. We're the proud sponsor and supporter of SQLBits, Power Platform World Tour, the London Power BI User Group, Newcastle Power BI User Group and Newcastle Data Platform and Cloud User Group. We are the global leaders in Microsoft recruitment.",,,False,,,fulltime,https://uk.jooble.org/jdp/-2414168062731392303?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,England,,,"Data Engineer - London - GBP70,000"
Michael Page,,,"Design, Build, Support and Develop the client's Golden Source data platform (Microsoft Fabric).

Ingest data with shortcuts, pipelines or dataflows to support Power BI and AI analytical use cases.

Establish both curated and semantic layers within the Golden Source data platform, aligned to company Data Architecture and using Microsoft Fabric capabilities.

Actively contribute to all stages of the data platform lifecycle as required (including design, development, testing & delivery phases) in line with agreed architecture and design standards.

Optimise table design, data models and semantic models for onward data consumption by content creators across the organisation.

Ingest third party data using Microsoft Fabric capabilities and prepare third party data for both standalone and combined analysis with other company data sets.

Ensure data platform delivers to non-functional requirements.

Performance optimisation and troubleshooting of data technologies

Curate an unstructured data (documents, reports, lists etc.) ecosystem within Microsoft Fabric tools

Champion Cloud Operations & DevOps principles, approaches and best practices

Document knowledge of environments and individual systems as they are acquired over time, creating runbooks and ensuring critical system information is readily available to colleagues.",,,False,,,fulltime,https://uk.jooble.org/rjdp/-60264122726342149?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Leeds,,,Analytical Data Engineer
Nigel Frank,,,"Data Engineer/Warehouse Developer - GBP55 - GBP70,000 - London

a0MaA000000T4DD.13_1733138498

Data Engineer / Data Warehouse Developer - £55,000 - £70,000 - Hybrid - London

Company Overview:

My client, an established wealth management company is currently hiring for a Data Engineer / Data Warehouse Developer. They are a multinational cooperation who have been experts in their field for over 60 years, with the UK branch is currently managing over £18 billion in assets.

Despite their size they still pride themselves on being a close-knit, collaborative business where everyone helps everyone. This business model means they always try and promote from within and push their own talents as far as they can go - as can be proven by many company success stories!

Role Overview:

Business developments and growth within my clients company has lead to a lot of new work becoming available with a few big projects on the cards, including a large-scale integration. In this role you'll be uplifting and developing ETL processes to ingest source data from different systems into a unified warehouse. This will be on-prem work for security reasons so it will include a lot of T-SQL and SSIS work. Additional responsibilities will include performance optimisation, ensuring scalability and testing and validation of processes.

My client has no plans to move to a cloud platform.

Essential
• Solid, recent experience in SQL & T-SQL programming, and SSIS for ETL
• Scripting experience in C#, PowerShell and/or Python
• Strong Data Warehousing experience including designing, developing, and implementing Data Warehouse solutions with a focus on data integration
• Data mapping experience

Desirable
• Financial Services experience

Interviews ongoing don't miss your chance to secure a role working with cutting edge technology while maintaining exceptional work-life balance.

Contact me @ View email address on nigelfrank.com or on Show phone number.

Data Warehousing, Data Warehouse, SQL, ssIS, on-prem, ETL, C#, Python, fintech,",,,False,,,fulltime,https://uk.jooble.org/jdp/-1170567854841285143?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,England,,,"Data Engineer/Warehouse Developer - GBP55 - GBP70,000 - London"
Hexegic,,,"Hexegic is a leading technical consultancy providing agile multi-disciplinary teams to high performing organisations. The company promises exciting, engaging and rewarding projects for those that are keen to develop and build a successful career. The Role As a data support engineer you will support users across the platform userbase, facilitating seamless integration of data thus enabling applications that drive superior decision-making within organisations. Core Responsibilities Resolve user queries and distill observed trends into future requests Serve as technical liaison for Data Engineers, providing second-line support and guidance Cultivate in-depth understanding of the system application to efficiently address user inquiries Work with product engineers to diagnose and resolve bugs Contribute to documentation and clarifying complex concepts where and when needed What we are looking for Background in computer science, engineering, information systems or other data related technical fields Experience in python and pyspark is essential, with additional skills in SQL and Java useful Knowledge of APIs, RESTful services and development best practices What we offer ~ Base salary of £50,000 to £60,000 ~£5,000 per year professional development allowance ~ Private medical scheme",,,False,,,fulltime,https://talents.studysmarter.co.uk/companies/hexegic/data-support-engineer-permanent-104936/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,London,,,Data Support Engineer (Permanent)
Datatech Analytics,,,"Data Engineering Lead - AWS & Snowflake, Hybrid working: 3 days inTW6, Middlesex offices & 2 days homer/remote, Salary: Negotiable to £70.,000 DOE plus 40 % bonus potential, Job Reference: J12869 Full UK working rights required/no sponsorship available The role Looking for a challenge in one of the worlds largest airfreight logistics organisation and a FTSE 100 company? Within the Digital and Information function, the Data Engineering Lead will play a pivotal role in delivering and operating data products. Reporting to the Head of Data, Insights & Operational Research, this position holds significant responsibility within the data leadership team, ensuring our data solutions and business processes are fully aligned and contribute to the vision and strategic direction of the organisation. The successful candidate will join the team at an exciting time. They are in the early stages of a major programme of work to modernise their data infrastructure, tooling and processes to migrate from an on-premise to a cloud native environment and the Data Engineering Lead will be essential to the success of the transformation. Using your strong communication skills combined with a determined attitude you will be responsible for managing and developing a team of data engineers to develop effective and innovative solutions aligning to our architectural principles and the business need. You will ensure the team adheres to best practices in data engineering and contributes to the continuous improvement of our data systems. Duties Key responsibilities for this role include: Lead the design, development, and deployment of scalable and efficient data pipelines and architectures. Manage and mentor a team of data engineers, ensuring a culture of collaboration and excellence. Manage demand for data engineering resources, prioritising tasks and projects based on business needs and strategic goals. Monitor and report on the progress of data engineering projects, addressing any issues or risks that may arise. Collaborate closely with Analytics Leads, Data Architects, and the wider Digital and Information team to ensure seamless integration and operation of data solutions. Develop and implement a robust data operations capability to ensure the smooth running and reliability of our data estate. Drive the adoption of cloud technologies and modern data engineering practices within the team. Ensure data governance and compliance with relevant regulations and standards. Work with the team to define and implement best practices for data engineering, including coding standards, documentation, version control. Skills Expert in SQL and database concepts including performance tuning and optimisation Solid understanding of data warehousing principles and data modelling practice Strong engineering skills, preferably in the following toolsets - AWS services (S3, EC2, Lambda, Glue) - ETL Tools (e.g. Apache Airflow) - Streaming processing tools (e.g. Kinesis) - Snowflake - Python Excellent knowledge of creation and maintenance of data pipelines Strong problem-solving and analytical skills, with the ability to troubleshoot and resolve complex data-related issues Proficient in data integration techniques including APIs and real-time ingestion Excellent communication and collaboration skills to work effectively with cross-functional teams Capable of building, leading, and developing a team of data engineers Strong project management skills and an ability to manage multiple projects and priorities Experience Experienced and confident leadership of data engineering activities (essential) Expert in data engineering practise on cloud data platforms (essential) Background in data analysis and preparation, including experience with large data sets and unstructured data (desirable) Knowledge of AI/Data Science principles (desirable) If you would like to hear more, please do get in touch. Alternatively, you can refer a friend or colleague by taking part in our fantastic referral schemes! If you have a friend or colleague who would be interested in this role, please refer them to us. For each relevant candidate that you introduce to us (there is no limit) and we place, you will be entitled to our general gift/voucher scheme. Datatech is one of the UK's leading recruitment agencies in the field of analytics and host of the critically acclaimed event, Women in Data. For more information, visit our website: www.datatech.org.uk JBRP1_UKTJ",,,True,,,fulltime,https://talents.studysmarter.co.uk/companies/datatech-analytics/datatech-analytics-data-engineering-lead-aws-snowflake-470520/?utm_campaign=google_jobs_apply&utm_source=google_jobs_apply&utm_medium=organic,,,Leeds,,,Datatech Analytics | Data Engineering Lead – AWS & Snowflake
